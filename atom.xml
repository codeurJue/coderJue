<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Jue&#39;s Blog</title>
  
  <subtitle>MSCS@ZJU | IngÃ©nieur CentraleSupÃ©lec</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://juewang.me/"/>
  <updated>2020-02-10T04:02:01.642Z</updated>
  <id>https://juewang.me/</id>
  
  <author>
    <name>Jue Wang</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>ğŸ” Hi there!</title>
    <link href="https://juewang.me/posts/welcome/"/>
    <id>https://juewang.me/posts/welcome/</id>
    <published>2020-02-10T03:25:09.000Z</published>
    <updated>2020-02-10T04:02:01.642Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>Iâ€™m <a href="/about">Jue</a>, welcome here.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;Iâ€™m &lt;a href=&quot;/about&quot;&gt;Jue&lt;/a&gt;, welcome 
      
    
    </summary>
    
      <category term="other" scheme="https://juewang.me/categories/other/"/>
    
    
  </entry>
  
  <entry>
    <title>CheatSheet for Setting up New VPS</title>
    <link href="https://juewang.me/posts/vps-cheatsheet/"/>
    <id>https://juewang.me/posts/vps-cheatsheet/</id>
    <published>2020-02-09T08:18:11.000Z</published>
    <updated>2020-02-09T13:43:52.811Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="Basics"><a href="#Basics" class="headerlink" title="Basics"></a>Basics</h1><h2 id="Create-New-Users"><a href="#Create-New-Users" class="headerlink" title="Create New Users"></a>Create New Users</h2><p>first login in the root account.</p><p>to add a user:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">adduser [UserName]</span><br></pre></td></tr></table></figure><p>if want it to have sudo privilege, then:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">usermod -aG sudo [UserName]</span><br></pre></td></tr></table></figure><h2 id="Set-Up-SSH-Config"><a href="#Set-Up-SSH-Config" class="headerlink" title="Set Up SSH Config"></a>Set Up SSH Config</h2><p>add these to ~/.ssh/config</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Host [ShortNameForTheVPS]</span><br><span class="line">HostName [ItsIPOrDomain]</span><br><span class="line">User [TheUserToLogin]</span><br><span class="line">IdentitiesOnly yes</span><br></pre></td></tr></table></figure><p>if you want to ssh via proxy, for MacOS users:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Host [ShortNameForTheVPS]</span><br><span class="line">HostName [ItsIPOrDomain]</span><br><span class="line">ProxyCommand nc -X 5 -x 127.0.0.1:1082 %h %p</span><br><span class="line">User [TheUserToLogin]</span><br><span class="line">IdentitiesOnly yes</span><br></pre></td></tr></table></figure><p>-X 5 means using socks5; -x specify proxy server ip and port.</p><p>then ssh-copy-id, so we donâ€™t have to type password every time we ssh:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-copy-id [ShortNameForTheVPS]</span><br></pre></td></tr></table></figure><p>As the result, we only need to type to login:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh [ShortNameForTheVPS]</span><br></pre></td></tr></table></figure><h2 id="Powerful-Vim"><a href="#Powerful-Vim" class="headerlink" title="Powerful Vim"></a>Powerful Vim</h2><p>Life is short, I use spf13.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl https://j.mp/spf13-vim3 -L &gt; spf13-vim.sh &amp;&amp; sh spf13-vim.sh</span><br></pre></td></tr></table></figure><p>if every thing goes fine, it will usually take within 5 minnutes.</p><h2 id="Powerful-Zsh"><a href="#Powerful-Zsh" class="headerlink" title="Powerful Zsh"></a>Powerful Zsh</h2><p>Bash is good but Zsh is better. For ubuntu users:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install zsh</span><br></pre></td></tr></table></figure><p>Again, life is short, I use oh-my-zsh.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sh -c <span class="string">"<span class="variable">$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)</span>"</span></span><br></pre></td></tr></table></figure><p>it is installed instantly.</p><h1 id="Network-Related"><a href="#Network-Related" class="headerlink" title="Network Related"></a>Network Related</h1><p>Usually it is suggested to expose ports as few as possible, and only preserve 80(HTTP) and 443(HTTPS).</p><p>We can use nginx/caddy/â€¦ to do HTTP(S) reverse proxy.</p><h2 id="Caddy"><a href="#Caddy" class="headerlink" title="Caddy"></a>Caddy</h2><p>install go</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install golang</span><br></pre></td></tr></table></figure><p>install caddy. we choose caddy 1 here.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl https://getcaddy.com | bash -s personal</span><br></pre></td></tr></table></figure><p>run caddy, and it should run as a simple server on port 2015. it should return 404 when visit.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">caddy</span><br></pre></td></tr></table></figure><p>to run caddy as server, follow instructions <a href="https://github.com/caddyserver/caddy/tree/master/dist/init/linux-systemd" target="_blank" rel="noopener">here</a>.</p><p>to use CloudFlare CDN, follow instuctions <a href="https://melty.land/blog/caddy-and-cloudflare" target="_blank" rel="noopener">here(chinese)</a></p><h1 id="Scientific-Purpose"><a href="#Scientific-Purpose" class="headerlink" title="Scientific Purpose"></a>Scientific Purpose</h1><p>e.g. interactive demo.</p><h2 id="Python-Environment"><a href="#Python-Environment" class="headerlink" title="Python Environment"></a>Python Environment</h2><p>download anaconda, the latest address can be found <a href="https://www.anaconda.com/distribution/" target="_blank" rel="noopener">here</a>.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://repo.anaconda.com/archive/Anaconda3-2019.10-Linux-x86_64.sh</span><br></pre></td></tr></table></figure><p>install it.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash Anaconda3-2019.10-Linux-x86_64.sh</span><br></pre></td></tr></table></figure><p>if use zsh, the install script wonâ€™t add initialization script to .zshrc, so we need to copy from .bashrc</p><p>re-login, so the initialization script will work.</p><p>install pytorch will be another long story, so we wonâ€™t go in deep here.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;Basics&quot;&gt;&lt;a href=&quot;#Basics&quot; class=&quot;
      
    
    </summary>
    
      <category term="other" scheme="https://juewang.me/categories/other/"/>
    
    
      <category term="vps" scheme="https://juewang.me/tags/vps/"/>
    
  </entry>
  
  <entry>
    <title>nlp short reviews - week 1</title>
    <link href="https://juewang.me/posts/%5B2018.9%5Dnlp-short-reviews-week-1/"/>
    <id>https://juewang.me/posts/[2018.9]nlp-short-reviews-week-1/</id>
    <published>2018-09-18T03:24:29.000Z</published>
    <updated>2018-10-06T02:10:34.775Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2 id="9-21"><a href="#9-21" class="headerlink" title="9.21"></a>9.21</h2><h3 id="Robust-Spoken-Language-Understanding-via-Paraphrasing-arXiv-1809-06444v1-cs-CL"><a href="#Robust-Spoken-Language-Understanding-via-Paraphrasing-arXiv-1809-06444v1-cs-CL" class="headerlink" title="Robust Spoken Language Understanding via Paraphrasing. (arXiv:1809.06444v1 [cs.CL])"></a>Robust Spoken Language Understanding via Paraphrasing. (arXiv:1809.06444v1 [cs.CL])</h3><p><strong><em>Abstract:</em></strong> Learning intents and slot labels from user utterances is a fundamental step in all spoken language understanding (SLU) and dialog systems. State-of-the-art neural network based methods, after deployment, often suffer from performance degradation on encountering paraphrased utterances, and out-of-vocabulary words, rarely observed in their training set. We address this challenging problem by introducing a novel paraphrasing based SLU model which can be integrated with any existing SLU model in order to improve their overall performance. We propose two new paraphrase generators using RNN and sequence-to-sequence based neural networks, which are suitable for our application. Our experiments on existing benchmark and in house datasets demonstrate the robustness of our models to rare and complex paraphrased utterances, even under adversarial test distributions.</p><p><strong><em>Comment:</em></strong>  ä¸€ç¯‡åˆ©ç”¨å¥å­æ”¹å†™ä¼˜åŒ–SLUçš„æ–‡ç« ã€‚ç›®å‰åŸºäºç¥ç»ç½‘ç»œçš„state-of-the-artéœ€è¦å¤§é‡çš„è¯­æ–™ï¼Œå¹¶ä¸”å¯¹è¯­æ–™åº“ä¸­å°‘è§çš„è¯´æ³•æ”¯æŒè¾ƒå·®ï¼Œå› æ­¤æˆ‘ä»¬å¯„å¸Œæœ›äºå¥å­æ”¹å†™ã€‚åœ¨state-of-the-artçš„åŸºç¡€ä¸Šï¼Œå¦‚æœäº§ç”Ÿçš„ç»“æœç½®ä¿¡åº¦ä½äºé˜ˆå€¼ï¼Œåˆ™å°è¯•ä½¿ç”¨å¥å­æ”¹å†™ï¼Œä»è€Œè®©SLUæ¨¡å‹æ›´å¥½åœ°å·¥ä½œã€‚å…·ä½“æ¥è®²ï¼Œè¿™é‡Œæˆ‘ä»¬æŠŠç¬¬ä¸€æ¬¡ç½®ä¿¡åº¦è¾ƒä½çš„â€œOâ€labelæ›¿æ¢æˆã€Š?ã€‹ï¼Œå†å°†ã€Š?ã€‹å¡«å……æˆå¸¸è§çš„è¯­å¥ã€‚ä½†æ˜¯æœ€åçš„è¯•éªŒæœªèƒ½è¡¨ç°å‡ºè¾ƒå¤§çš„è¿›æ­¥ï¼Œæ¨æµ‹å¥å­æ”¹å†™ä»…ä»…åªæ˜¯æ”¹å˜å‡ ä¸ªwordï¼Œå¯¹æ•´å¥çš„åˆ¤æ–­å½±å“å¹¶ä¸å¤§ï¼›å¦ä¸€æ–¹é¢å®ƒä¸èƒ½å¯¹å¥å­ç»“æ„è¿›è¡Œæ”¹å†™ï¼Œå› æ­¤æå‡æœ‰é™ã€‚</p><h2 id="9-20"><a href="#9-20" class="headerlink" title="9.20"></a>9.20</h2><h3 id="User-Information-Augmented-Semantic-Frame-Parsing-using-Coarse-to-Fine-Neural-Networks-arXiv-1809-06559v1-cs-CL"><a href="#User-Information-Augmented-Semantic-Frame-Parsing-using-Coarse-to-Fine-Neural-Networks-arXiv-1809-06559v1-cs-CL" class="headerlink" title="User Information Augmented Semantic Frame Parsing using Coarse-to-Fine Neural Networks. (arXiv:1809.06559v1 [cs.CL])"></a>User Information Augmented Semantic Frame Parsing using Coarse-to-Fine Neural Networks. (arXiv:1809.06559v1 [cs.CL])</h3><p><strong><em>Abstract:</em></strong> Semantic frame parsing is a crucial component in spoken language understanding (SLU) to build spoken dialog systems. It has two main tasks: intent detection and slot filling. Although state-of-the-art approaches showed good results, they require large annotated training data and long training time. In this paper, we aim to alleviate these drawbacks for semantic frame parsing by utilizing the ubiquitous user information. We design a novel coarse-to-fine deep neural network model to incorporate prior knowledge of user information intermediately to better and quickly train a semantic frame parser. Due to the lack of benchmark dataset with real user information, we synthesize the simplest type of user information (location and time) on ATIS benchmark data. The results show that our approach leverages such simple user information to outperform state-of-the-art approaches by 0.25% for intent detection and 0.31% for slot filling using standard training data. When using smaller training data, the performance improvement on intent detection and slot filling reaches up to 1.35% and 1.20% respectively. We also show that our approach can achieve similar performance as state-of-the-art approaches by using less than 80% annotated training data. Moreover, the training time to achieve the similar performance is also reduced by over 60%.</p><p><strong><em>Comment:</em></strong>  å·¥ä½œç›¸å…³ã€‚ç›®å‰intent classificationå’Œslot fillingçš„state-of-the-artæ˜¯attention-based-biLSTMï¼Œè¿™ç¯‡æ–‡ç« çš„åˆ›æ–°ç‚¹åœ¨äºåˆ©ç”¨äº†ç”¨æˆ·çš„ä¿¡æ¯ï¼Œå¹¶å°†å…¶èåˆè¿›ä¸Šä¸‹æ–‡ï¼Œä½¿æ¨¡å‹å¯¹æ•°æ®çš„ä¾èµ–å‡å°‘å¹¶è®©ç»“æœæ›´åŠ å‡†ç¡®ã€‚ä½†æ˜¯ä¼¼ä¹æå‡æ¯”è¾ƒæœ‰é™ï¼Œä¸è¿‡æ€è€ƒçš„æ–¹å‘å¯ä»¥å‚è€ƒã€‚</p><h3 id="Learning-Universal-Sentence-Representations-with-Mean-Max-Attention-Autoencoder-arXiv-1809-06590v1-cs-CL"><a href="#Learning-Universal-Sentence-Representations-with-Mean-Max-Attention-Autoencoder-arXiv-1809-06590v1-cs-CL" class="headerlink" title="Learning Universal Sentence Representations with Mean-Max Attention Autoencoder. (arXiv:1809.06590v1 [cs.CL])"></a>Learning Universal Sentence Representations with Mean-Max Attention Autoencoder. (arXiv:1809.06590v1 [cs.CL])</h3><p><strong><em>Abstract:</em></strong> In order to learn universal sentence representations, previous methods focus on complex recurrent neural networks or supervised learning. In this paper, we propose a mean-max attention autoencoder (mean-max AAE) within the encoder-decoder framework. Our autoencoder rely entirely on the MultiHead self-attention mechanism to reconstruct the input sequence. In the encoding we propose a mean-max strategy that applies both mean and max pooling operations over the hidden vectors to capture diverse information of the input. To enable the information to steer the reconstruction process dynamically, the decoder performs attention over the mean-max representation. By training our model on a large collection of unlabelled data, we obtain high-quality representations of sentences. Experimental results on a broad range of 10 transfer tasks demonstrate that our model outperforms the state-of-the-art unsupervised single methods, including the classical skip-thoughts and the advanced skip-thoughts+LN model. Furthermore, compared with the traditional recurrent neural network, our mean-max AAE greatly reduce the training time.</p><p><strong><em>Comment:</em></strong>  æå‡ºäº†ä¸€ç§mean-max AAEï¼Œç”¨self-attentionå’Œmean-max poolingç»„æˆencoderå’Œdecoderï¼Œæœ€åçš„ç»“æœåœ¨æ— ç›‘ç£å•æ¨¡å‹ä¸­è¾¾åˆ°äº†state-of-the-artï¼Œå¹¶ä¸”èƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨å¹¶è¡Œè®¡ç®—ï¼Œä½¿è®­ç»ƒè¿‡ç¨‹éå¸¸å¿«ã€‚</p><h3 id="Transfer-and-Multi-Task-Learning-for-Noun-Noun-Compound-Interpretation-arXiv-1809-06748v1-cs-CL"><a href="#Transfer-and-Multi-Task-Learning-for-Noun-Noun-Compound-Interpretation-arXiv-1809-06748v1-cs-CL" class="headerlink" title="Transfer and Multi-Task Learning for Noun-Noun Compound Interpretation. (arXiv:1809.06748v1 [cs.CL])"></a>Transfer and Multi-Task Learning for Noun-Noun Compound Interpretation. (arXiv:1809.06748v1 [cs.CL])</h3><p><strong><em>Abstract:</em></strong> In this paper, we empirically evaluate the utility of transfer and multi-task learning on a challenging semantic classification task: semantic interpretation of nounâ€“noun compounds. Through a comprehensive series of experiments and in-depth error analysis, we show that transfer learning via parameter initialization and multi-task learning via parameter sharing can help a neural classification model generalize over a highly skewed distribution of relations. Further, we demonstrate how dual annotation with two distinct sets of relations over the same set of compounds can be exploited to improve the overall accuracy of a neural classifier and its F1 scores on the less frequent, but more difficult relations.</p><p><strong><em>Comment:</em></strong> è¿™æ˜¯ä¸€ç¯‡interpretationï¼Œä¸»è¦åˆ†ætransfer learningå’Œmulti-task learningå¯¹äºnoun-noun compoundã€‚ä¸€èˆ¬æ¥è¯´åƒrelation extractionç­‰ä»»åŠ¡ä¸»è¦ç ”ç©¶çš„ä¹Ÿæ˜¯åè¯ä¸åè¯çš„å…³ç³»ï¼Œæ–‡ä¸­æåˆ°çš„æ–¹æ³•å¯¹äºå¾ˆå¤šä¿¡æ¯æŠ½å–ä»»åŠ¡éƒ½å¯ä»¥å‚è€ƒä¸€ä¸‹ã€‚</p><h2 id="9-18"><a href="#9-18" class="headerlink" title="9.18"></a>9.18</h2><h3 id="Learning-to-Accept-New-Classes-without-Training-arXiv-1809-06004v1-cs-CL"><a href="#Learning-to-Accept-New-Classes-without-Training-arXiv-1809-06004v1-cs-CL" class="headerlink" title="Learning to Accept New Classes without Training. (arXiv:1809.06004v1 [cs.CL])]"></a>Learning to Accept New Classes without Training. (arXiv:1809.06004v1 [cs.CL])]</h3><p><strong><em>Abstract:</em></strong> Classic supervised learning makes the closed-world assumption, meaning that classes seen in testing must have been seen in training. However, in the dynamic world, new or unseen class examples may appear constantly. A model working in such an environment must be able to reject unseen classes (not seen or used in training). If enough data is collected for the unseen classes, the system should incrementally learn to accept/classify them. This learning paradigm is called open-world learning (OWL). Existing OWL methods all need some form of re-training to accept or include the new classes in the overall model. In this paper, we propose a meta-learning approach to the problem. Its key novelty is that it only needs to train a meta-classifier, which can then continually accept new classes when they have enough labeled data for the meta-classifier to use, and also detect/reject future unseen classes. No re-training of the meta-classifier or a new overall classifier covering all old and new classes is needed. In testing, the method only uses the examples of the seen classes (including the newly added classes) on-the-fly for classification and rejection. Experimental results demonstrate the effectiveness of the new approach.</p><p><strong><em>Comment:</em></strong> æƒ³æ³•è¿˜æ˜¯å€¼å¾—å€Ÿé‰´çš„ï¼Œç”¨ä¸€ä¸ªmeta-classifieræ¥é¿å…æ–°ç±»éœ€è¦é‡æ–°è®­ç»ƒã€ç¼ºå°‘æ•°æ®é›†ç­‰é—®é¢˜ã€‚ä½†æ˜¯æœ€åçš„å®ç°æœ‰ç‚¹åƒknnï¼Œè¿™æ ·çº¯ç²¹çš„éç›‘ç£å­¦ä¹ æ€»è§‰å¾—æ•ˆæœå¯èƒ½è¿˜ä¸èƒ½è¾¾åˆ°ç°æœ‰ç›‘ç£å­¦ä¹ ã€‚å¯ä»¥è€ƒè™‘æ€ä¹ˆæŠŠmeta-classifieråŠ åˆ°å¸¸è§çš„æœ‰ç›‘ç£å­¦ä¹ æ¨¡å‹ä¸­ï¼Œä¸é™ä½å‡†ç¡®ç‡çš„æƒ…å†µä¸‹ï¼Œæé«˜æ³›åŒ–æ•ˆæœã€‚</p><h3 id="Events-Beyond-ACE-Curated-Training-for-Events-arXiv-1809-05576v1-cs-CL"><a href="#Events-Beyond-ACE-Curated-Training-for-Events-arXiv-1809-05576v1-cs-CL" class="headerlink" title="Events Beyond ACE: Curated Training for Events. (arXiv:1809.05576v1 [cs.CL])"></a>Events Beyond ACE: Curated Training for Events. (arXiv:1809.05576v1 [cs.CL])</h3><p><strong><em>Abstract:</em></strong> We explore a human-driven approach to annotation, curated training (CT), in which annotation is framed as teaching the system by using interactive search to identify informative snippets of text to annotate, unlike traditional approaches which either annotate preselected text or use active learning. A trained annotator performed 80 hours of CT for the thirty event types of the NIST TAC KBP Event Argument Extraction evaluation. Combining this annotation with ACE results in a 6% reduction in error and the learning curve of CT plateaus more slowly than for full-document annotation. 3 NLP researchers performed CT for one event type and showed much sharper learning curves with all three exceeding ACE performance in less than ninety minutes, suggesting that CT can provide further benefits when the annotator deeply understands the system.</p><p><strong><em>Comment:</em></strong> æ¨¡å‹é©±åŠ¨æ ‡æ³¨ï¼Œä½¿å¾—æ ‡æ³¨æ•ˆç‡æ›´é«˜ï¼Œmarkã€‚</p><h3 id="Extending-Neural-Generative-Conversational-Model-using-External-Knowledge-Sources-arXiv-1809-05524v1-cs-CL"><a href="#Extending-Neural-Generative-Conversational-Model-using-External-Knowledge-Sources-arXiv-1809-05524v1-cs-CL" class="headerlink" title="Extending Neural Generative Conversational Model using External Knowledge Sources. (arXiv:1809.05524v1 [cs.CL])"></a>Extending Neural Generative Conversational Model using External Knowledge Sources. (arXiv:1809.05524v1 [cs.CL])</h3><p><strong><em>Abstract:</em></strong> The use of connectionist approaches in conversational agents has been progressing rapidly due to the availability of large corpora. However current generative dialogue models often lack coherence and are content poor. This work proposes an architecture to incorporate unstructured knowledge sources to enhance the next utterance prediction in chit-chat type of generative dialogue models. We focus on Sequence-to-Sequence (Seq2Seq) conversational agents trained with the Reddit News dataset, and consider incorporating external knowledge from Wikipedia summaries as well as from the NELL knowledge base. Our experiments show faster training time and improved perplexity when leveraging external knowledge.</p><p><strong><em>Comment:</em></strong> è¿‘æœŸè¿™ä¸€ç±»åˆ©ç”¨å¤–éƒ¨çŸ¥è¯†åº“çš„paperæŒºå¤šçš„ï¼Œåˆ°æ—¶å€™éœ€è¦ç”¨åˆ°çŸ¥è¯†å›¾è°±çš„æ—¶å€™éƒ½å¯ä»¥å‚è€ƒä¸€ä¸‹ã€‚</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h2 id=&quot;9-21&quot;&gt;&lt;a href=&quot;#9-21&quot; class=&quot;head
      
    
    </summary>
    
      <category term="research" scheme="https://juewang.me/categories/research/"/>
    
    
      <category term="nlp" scheme="https://juewang.me/tags/nlp/"/>
    
      <category term="review" scheme="https://juewang.me/tags/review/"/>
    
  </entry>
  
  <entry>
    <title>RegEx with NN</title>
    <link href="https://juewang.me/posts/%5B2018.8.22%5DRegEx-with-NN/"/>
    <id>https://juewang.me/posts/[2018.8.22]RegEx-with-NN/</id>
    <published>2018-08-22T05:58:00.000Z</published>
    <updated>2018-10-06T03:04:02.879Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>è¿™ä¸¤å¤©åœ¨å®ä¹ æ²¡æœ‰å¤ªå¤šçš„æ—¶é—´å†™ç¬”è®°orzï¼Œæ­£å¥½è¶ç€å…¬å¸å†…éƒ¨åˆ†äº«çš„æ—¶å€™ç¨å¾®å†™å‡ ç¬”ã€‚ï¼ˆç„¶è€Œä¸€ç›´æ²¡å‘å‡ºæ¥ï¼‰</p><h1 id="Marrying-Up-Regexs-with-Neural-Networks"><a href="#Marrying-Up-Regexs-with-Neural-Networks" class="headerlink" title="Marrying Up Regexs with Neural Networks"></a>Marrying Up Regexs with Neural Networks</h1><h2 id="æ¦‚è¿°"><a href="#æ¦‚è¿°" class="headerlink" title="æ¦‚è¿°"></a>æ¦‚è¿°</h2><ul><li><p>æ­£åˆ™è¡¨è¾¾å¼ </p><ul><li><p>ç®€æ˜ã€æ‰¼è¦ã€å¯è°ƒï¼Œä¸ä¾èµ–å¤§è§„æ¨¡æ ‡æ³¨æ•°æ®</p></li><li><p>æ³›åŒ–æ€§èƒ½å·®ï¼Œæ‰€ä»¥å˜ä½“ã€åŒä¹‰è¯éƒ½éœ€è¦äººä¸ºç¼–å†™</p></li></ul></li><li><p>ç¥ç»ç½‘ç»œ </p><ul><li>æ‹Ÿåˆèƒ½åŠ›å¼ºã€æ³›åŒ–æ€§èƒ½å¼º  </li><li>éœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®ï¼Œè§£é‡Šæ€§å·®</li></ul></li></ul><p>å› æ­¤å·¥ç¨‹ä¸Šå¸¸å¸¸ç»“åˆä¸¤ä¸ªï¼Œæ­£åˆ™è§£å†³éƒ¨åˆ†casesï¼Œå‰©ä¸‹äº¤ç»™ç»Ÿè®¡æ¨¡å‹ï¼Œä¸€èˆ¬æ¥è¯´å°±æ˜¯ç¥ç»ç½‘ç»œäº†ã€‚</p><p>é‚£ä¹ˆæœ‰æ²¡æœ‰å¯èƒ½æ­£åˆ™å’Œç¥ç»ç½‘ç»œç»“åˆèµ·æ¥ï¼ŸBingfeng et al. 2018<sup id="fnref:1"><a href="#fn:1" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="Luo, Bingfeng, et al. Marrying up Regular Expressions with Neural Networks: A Case Study for Spoken Language Understanding. arXiv preprint arXiv:1805.05588 (2018). ">[1]</span></a></sup>ç»™å‡ºäº†ä¸€äº›æ€è·¯ã€‚</p><h2 id="Problem-def-and-the-baselines"><a href="#Problem-def-and-the-baselines" class="headerlink" title="Problem def. and the baselines"></a>Problem def. and the baselines</h2><p>æ–‡ç« ä¸»è¦è§£å†³ä¸¤ä¸ªé—®é¢˜ï¼Œintent detectionå’Œslot fillingï¼Œä¹Ÿå¯ä»¥è®¤ä¸ºæ˜¯classificationå’Œseq2seqçš„ä»»åŠ¡ã€‚è¿™é‡Œçš„baselinesä¸»è¦æœ‰ä¸¤ä¸ªï¼Œæ­£åˆ™è¡¨è¾¾å¼çš„å°è¯•å’ŒLiu, Bing, and Ian Lane. 2016<sup id="fnref:2"><a href="#fn:2" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="Liu, Bing, and Ian Lane. Attention-based recurrent neural network models for joint intent detection and slot filling. arXiv preprint arXiv:1609.01454 (2016). ">[2]</span></a></sup>æå‡ºçš„attention-based rnnã€‚æ€è·¯å¯ä»¥è§ä¸‹å›¾ã€‚</p><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-09-16-063410.png" alt="image-20180916143407395"></p><h2 id="Approaches"><a href="#Approaches" class="headerlink" title="Approaches"></a>Approaches</h2><p>æ–‡ç« ä¸»è¦åœ¨ä¸‰ä¸ªæ–¹é¢è¿›è¡Œå°è¯•ï¼šinput levelã€network levelã€output levelã€‚</p><h3 id="Input-level"><a href="#Input-level" class="headerlink" title="Input level"></a>Input level</h3><ul><li><p>For intent detection, </p><p>two possible approach:</p><ul><li>Append the embedding to all words (deprecated &lt;= ä»ç»“æœä¸Šçœ‹ä¼šå¯¼è‡´ç½‘ç»œè¿‡äºä¾èµ–æ­£åˆ™)</li><li>Append the embedding to the input of softmax layer(â‘  in Fig(a) )</li></ul></li><li><p>For slot filling, </p><p>Embed and average the REtags into a vector fi for each word and append it to the corresponding word embedding wi (â‘  in Fig(b) )</p></li></ul><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-09-16-064101.png" alt="image-20180916144059096"></p><h3 id="Network-level"><a href="#Network-level" class="headerlink" title="Network level"></a>Network level</h3><ul><li><p>For intent detection, </p><p>For each intent label k, use different attention ak , which is used to generate the sentence embedding sk   (â‘¡ in Fig(a) )</p><p>Note that a RE can also indicate that a sentence does not express intent k (negative REs), it is also necessary to set another group of attention. </p></li></ul><p>$$<br>  s_{k} = \sum_i {\alpha_{ki} h_i}, \quad \alpha_{ki} = \frac{\exp(h_i^T W_{a} c_k)}{\sum_i {\exp(h_i^T W_{a} c_k)}}<br>$$</p><ul><li><p>For slot filling, </p><p>The mechanism introduced for intent detection is unsuitable for slot filling.</p><p>A simple version of the two-side attention, where all the slot labels share the same set of positive and negative attention. (â‘¡ in Fig(b) )</p><p>$$<br>s_{pi} = \sum_j {\alpha_{pij} h_j}, \quad \alpha_{pij} = \frac{\exp(h_j^T W_{sp} h_i)}{\sum_j {\exp(h_j^T W_{sp} h_i)}}<br>$$</p></li></ul><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-09-16-064735.png" alt="image-20180916144733081"></p><h3 id="Output-level"><a href="#Output-level" class="headerlink" title="Output level"></a>Output level</h3><p>Let $z_k$ be a 0-1 indicator of whether there is at least one matched RE that leads to target label $k$ (intent or slot label), the final logits of label k for a sentence (or a spefic word for slot filling) is:<br>$$<br>logit_k = logit_kâ€™ + w_k z_k<br>$$<br>where $logitâ€²_k$ is the logit produced by the original NN, and $w_k$ is a trainable weight indicating the overall confidence for REs that lead to target label $k$.</p><h2 id="Experimental-Results"><a href="#Experimental-Results" class="headerlink" title="Experimental Results"></a>Experimental Results</h2><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-09-16-065006.png" alt="image-20180916145004296"> </p><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-09-16-065035.png" alt="image-20180916145033498"></p><h2 id="Bibliography"><a href="#Bibliography" class="headerlink" title="Bibliography"></a>Bibliography</h2><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style: none; padding-left: 0; margin-left: 40px"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">1.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Luo, Bingfeng, et al. Marrying up Regular Expressions with Neural Networks: A Case Study for Spoken Language Understanding. arXiv preprint arXiv:1805.05588 (2018).<a href="#fnref:1" rev="footnote"> â†©</a></span></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">2.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Liu, Bing, and Ian Lane. Attention-based recurrent neural network models for joint intent detection and slot filling. arXiv preprint arXiv:1609.01454 (2016).<a href="#fnref:2" rev="footnote"> â†©</a></span></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;è¿™ä¸¤å¤©åœ¨å®ä¹ æ²¡æœ‰å¤ªå¤šçš„æ—¶é—´å†™ç¬”è®°orzï¼Œæ­£å¥½è¶ç€å…¬å¸å†…éƒ¨åˆ†äº«çš„æ—¶å€™ç¨å¾®å†™å‡ ç¬”
      
    
    </summary>
    
      <category term="research" scheme="https://juewang.me/categories/research/"/>
    
    
      <category term="neural-network" scheme="https://juewang.me/tags/neural-network/"/>
    
      <category term="regular-expression" scheme="https://juewang.me/tags/regular-expression/"/>
    
  </entry>
  
  <entry>
    <title>intro-about-KG</title>
    <link href="https://juewang.me/posts/intro-about-KG/"/>
    <id>https://juewang.me/posts/intro-about-KG/</id>
    <published>2018-07-01T12:59:58.000Z</published>
    <updated>2018-07-01T13:27:45.722Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="çŸ¥è¯†å›¾è°±"><a href="#çŸ¥è¯†å›¾è°±" class="headerlink" title="çŸ¥è¯†å›¾è°±"></a>çŸ¥è¯†å›¾è°±</h1><p>ä¹‹å‰å…¶å®é™†é™†ç»­ç»­åœ°çœ‹äº†ä¸€äº›çŸ¥è¯†å›¾è°±ç›¸å…³çš„è®ºæ–‡ï¼Œå¯¹å…¶çš„ç†è§£å§‹ç»ˆåœç•™åœ¨æ¯”è¾ƒæµ…æ˜¾çš„å±‚é¢ï¼Œæˆ–è€…è¯´ä¸€ä¸ªéå¸¸ä¸å…¨é¢çš„çŠ¶æ€ï¼Œä»¥è‡³äºï¼Œåœ¨å®ä¹ ä¸­çœŸçš„è¦å°è¯•ç€æ‰‹å»ºç«‹ä¸€ä¸ªé€šç”¨çŸ¥è¯†å›¾è°±çš„æ—¶å€™ï¼Œå´ä¸çŸ¥é“å¦‚ä½•ä¸‹æ‰‹ã€‚åœ¨å®ä¹ æœŸé—´æ‰“ç®—å†™è¿™ç¯‡ç»¼è¿°æ¥æ•´ç†ä¸€ä¸‹ä¹‹å‰çœ‹åˆ°çš„ä¸€äº›çç¢çš„çŸ¥è¯†ã€‚</p><h2 id="ä»‹ç»å’Œå®šä¹‰"><a href="#ä»‹ç»å’Œå®šä¹‰" class="headerlink" title="ä»‹ç»å’Œå®šä¹‰"></a>ä»‹ç»å’Œå®šä¹‰</h2><p>çŸ¥è¯†å›¾è°±ï¼ˆknowledge graphï¼‰æœ€åˆæ˜¯åˆGoogleæå‡ºçš„æ¦‚å¿µï¼Œç›®çš„æ˜¯ç¡®å®šä¸€ç§é¢ç›¸çŸ¥è¯†çš„å­˜å‚¨ç»“æ„ã€‚é€šå¸¸æˆ‘ä»¬å°†æ•°æ®å­˜åœ¨ä¸€ä¸ªå…³ç³»å‹æ•°æ®åº“æˆ–æ˜¯key-valueå‹æ•°æ®åº“ï¼Œæ•°æ®å’Œæ•°æ®ä¹‹é—´çš„å…³ç³»æ˜¯é€šè¿‡è¡¨æ¥å®šä¹‰çš„ï¼›å½“æ•°æ®çš„å…³ç³»æ¯”è¾ƒå¤æ‚è€Œä¸”æ¯”è¾ƒçµæ´»çš„æ—¶å€™ï¼Œä¼ ç»Ÿæ•°æ®åº“çš„è¡¨è¾¾èƒ½åŠ›å’Œå“åº”é€Ÿåº¦éƒ½æœ‰è¾ƒå¤§çš„å±€é™æ€§ï¼Œäº‹å®ä¸Šï¼ŒçŸ¥è¯†å°±æ˜¯ä¸€ç§å…³ç³»å¾ˆå¼ºçš„æ•°æ®ï¼Œè€Œä¸”çŸ¥è¯†åƒå˜ä¸‡åŒ–ï¼Œéš¾ä»¥ç”¨ä¸€äº›ç®€å•çš„è§„åˆ™æ¥é¢„å…ˆç¡®å®šè¡¨ã€‚ç”±æ­¤ï¼ŒçŸ¥è¯†å›¾è°±çš„æƒ³æ³•ä¹Ÿå°±å¾ˆè‡ªç„¶äº†ï¼ŒçŸ¥è¯†æ˜¯ä¸€ç§å…³ç³»æ€§å¾ˆå¼ºçš„æ•°æ®ï¼ŒçŸ¥è¯†çš„å­˜å‚¨ç»“æ„å¿…ç„¶åº”è¯¥æ˜¯ç±»ä¼¼äºå›¾çš„ã€‚</p><p>é€šå¸¸æ¥è¯´ï¼Œåœ¨å®é™…åº”ç”¨ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥ç®€å•çš„è®¤ä¸ºçŸ¥è¯†å›¾è°±å°±æ˜¯ä¸€ä¸ªå¤šå…³ç³»å›¾ï¼Œå…¶ä¸­æˆ‘ä»¬ç”¨å®ä½“ï¼ˆentityï¼‰æ¥è¡¨ç¤ºèŠ‚ç‚¹ï¼Œç”¨å…³ç³»ï¼ˆrelationï¼‰æ¥è¡¨ç¤ºè¾¹ï¼Œå› æ­¤çŸ¥è¯†çš„è¡¨è¾¾æ˜¯é€šè¿‡ä¸€ä¸ªä¸‰å…ƒç»„â€”ï¼ˆå®ä½“h-å…³ç³»r-å®ä½“tï¼‰æ¥å®ç°ã€‚</p><p>TODO</p><h2 id="çŸ¥è¯†å›¾è°±æ„å»º"><a href="#çŸ¥è¯†å›¾è°±æ„å»º" class="headerlink" title="çŸ¥è¯†å›¾è°±æ„å»º"></a>çŸ¥è¯†å›¾è°±æ„å»º</h2><p>æŸç§ç¨‹åº¦ä¸Šæ¥è¯´ï¼ŒçŸ¥è¯†å›¾è°±æœ€å›°éš¾ï¼Œæœ€éœ€è¦äººåŠ›çš„éƒ¨åˆ†å°±æ˜¯çŸ¥è¯†å›¾è°±çš„æ„å»ºã€‚æ•°æ®æ¥æºé€šå¸¸æœ‰ä»¥ä¸‹å‡ ç§</p><h3 id="ç»“æ„åŒ–æ•°æ®"><a href="#ç»“æ„åŒ–æ•°æ®" class="headerlink" title="ç»“æ„åŒ–æ•°æ®"></a>ç»“æ„åŒ–æ•°æ®</h3><p>è¿™ä¸ªæ¯”è¾ƒç†æƒ³ï¼Œä½†æ˜¯ä¿¡æ¯ä¸€å®šæ˜¯ä¸å®Œå–„æˆ–æ˜¯æ»åçš„ï¼Œå¯ä»¥ä½œä¸ºåˆæœŸçš„æ„å»ºï¼ŒåæœŸè¿˜æ˜¯è¦è‡ªå·±æ¥ç»´æŠ¤ã€‚è¿™é‡Œç•¥è¿‡ã€‚</p><h3 id="éç»“æ„åŒ–æ•°æ®"><a href="#éç»“æ„åŒ–æ•°æ®" class="headerlink" title="éç»“æ„åŒ–æ•°æ®"></a>éç»“æ„åŒ–æ•°æ®</h3><p>å¤§æ•°æ®æ—¶ä»£æ›´å¤šçš„æ˜¯è¿™æ ·çš„æ•°æ®ï¼Œéœ€è¦ä¸€å®šçš„ä¿¡æ¯æŠ½å–ã€nerç­‰nlpæŠ€æœ¯çš„æ”¯æŒï¼Œå¿…è¦æ—¶éœ€è¦äººå·¥è¿›è¡Œå®¡æ ¸ã€‚åœ¨æ„å»ºç±»ä¼¼çš„å›¾è°±è¿‡ç¨‹å½“ä¸­ï¼Œä¸»è¦æ¶‰åŠä»¥ä¸‹å‡ ä¸ªæ–¹é¢çš„è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯ï¼š  </p><ul><li>å®ä½“å‘½åè¯†åˆ«ï¼ˆName Entity Recognitionï¼‰</li><li>å…³ç³»æŠ½å–ï¼ˆRelation Extractionï¼‰    </li><li>å®ä½“ç»Ÿä¸€ï¼ˆEntity Resolutionï¼‰    </li><li>æŒ‡ä»£æ¶ˆè§£ï¼ˆCoreference Resolutionï¼‰</li></ul><h2 id="çŸ¥è¯†å›¾è°±çš„å­˜å‚¨"><a href="#çŸ¥è¯†å›¾è°±çš„å­˜å‚¨" class="headerlink" title="çŸ¥è¯†å›¾è°±çš„å­˜å‚¨"></a>çŸ¥è¯†å›¾è°±çš„å­˜å‚¨</h2><p>TODOï¼š</p><p>RDFå’Œå›¾æ•°æ®åº“ç­‰</p><h2 id="çŸ¥è¯†å›¾è°±çš„åº”ç”¨"><a href="#çŸ¥è¯†å›¾è°±çš„åº”ç”¨" class="headerlink" title="çŸ¥è¯†å›¾è°±çš„åº”ç”¨"></a>çŸ¥è¯†å›¾è°±çš„åº”ç”¨</h2>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;çŸ¥è¯†å›¾è°±&quot;&gt;&lt;a href=&quot;#çŸ¥è¯†å›¾è°±&quot; class=&quot;head
      
    
    </summary>
    
      <category term="research" scheme="https://juewang.me/categories/research/"/>
    
    
      <category term="machine-learning" scheme="https://juewang.me/tags/machine-learning/"/>
    
      <category term="deep-learning" scheme="https://juewang.me/tags/deep-learning/"/>
    
      <category term="knowledge-graph" scheme="https://juewang.me/tags/knowledge-graph/"/>
    
      <category term="knowledge-reasoning" scheme="https://juewang.me/tags/knowledge-reasoning/"/>
    
  </entry>
  
  <entry>
    <title>Set up the RSS feed</title>
    <link href="https://juewang.me/posts/update-rss/"/>
    <id>https://juewang.me/posts/update-rss/</id>
    <published>2018-05-12T04:57:31.000Z</published>
    <updated>2018-05-12T11:12:31.431Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>This post is both declaration of the update and a test whether the rss works well.</p><p>This RSS feed is generated by <a href="https://github.com/hexojs/hexo-generator-feed" target="_blank" rel="noopener">hexo-generator-feed</a> plugin.</p><ol><li><p>Install the plugin</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> npm install hexo-generator-feed --save</span></span><br></pre></td></tr></table></figure></li><li><p>update the theme configuration (_config.yml).</p><p>Enable the plugin:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">plugins:</span></span><br><span class="line">   <span class="string">...</span></span><br><span class="line"><span class="attr">   hexo-generator-feed:</span> <span class="literal">true</span></span><br><span class="line"></span><br><span class="line"><span class="attr">feed:</span></span><br><span class="line"><span class="attr">type:</span> <span class="string">atom</span>  </span><br><span class="line"><span class="attr">path:</span> <span class="string">atom.xml</span>  </span><br><span class="line"><span class="attr">limit:</span> <span class="number">20</span></span><br></pre></td></tr></table></figure><p>Show the RSS link on the website, this step depends on the theme we use, it should be something like:</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">links:</span></span><br><span class="line"><span class="attr">rss:</span> <span class="string">/atom.xml</span> <span class="comment"># this should be the path you assigned above.</span></span><br></pre></td></tr></table></figure><p>â€‹</p></li><li><p>And voilÃ , now you can subscribe to the RSS feed you created.</p><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-05-12-image-201805121311408.png" width="20%"></p></li></ol>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;This post is both declaration of the u
      
    
    </summary>
    
      <category term="other" scheme="https://juewang.me/categories/other/"/>
    
    
      <category term="hexo" scheme="https://juewang.me/tags/hexo/"/>
    
      <category term="rss" scheme="https://juewang.me/tags/rss/"/>
    
  </entry>
  
  <entry>
    <title>Learning beyond datasets - Knowledge Graph Augmented Neural Networks for Natural language Processing é˜…è¯»ç¬”è®°</title>
    <link href="https://juewang.me/posts/%5B2018.5.10%5DKnowledge-Graph-Augmented-Neural-Networks-for-NLP/"/>
    <id>https://juewang.me/posts/[2018.5.10]Knowledge-Graph-Augmented-Neural-Networks-for-NLP/</id>
    <published>2018-05-10T00:00:00.000Z</published>
    <updated>2018-05-12T13:04:33.158Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2 id="Knowledge-Graph-Augmented-Neural-Networks-for-Natural-language-Processing-é˜…è¯»ç¬”è®°"><a href="#Knowledge-Graph-Augmented-Neural-Networks-for-Natural-language-Processing-é˜…è¯»ç¬”è®°" class="headerlink" title="Knowledge Graph Augmented Neural Networks for Natural language Processing é˜…è¯»ç¬”è®°"></a>Knowledge Graph Augmented Neural Networks for Natural language Processing é˜…è¯»ç¬”è®°</h2><p><strong>æ‘˜è¦</strong>ï¼šæœºå™¨å­¦ä¹ çš„æ•ˆæœä¸€èˆ¬ä¾èµ–äºå…·ä½“çš„è®­ç»ƒæ•°æ®ã€‚ä¸€äº›å­¦ä¹ æ¨¡å‹å¯ä»¥ç»“åˆè´å¶æ–¯ä¸­çš„å…ˆéªŒçŸ¥è¯†ï¼Œä½†æ˜¯è¿™äº›æ¨¡å‹ä¸å…·å¤‡æ ¹æ®éœ€è¦è®¿é—®ä»»ä½•æœ‰ç»„ç»‡çš„çŸ¥è¯†çš„èƒ½åŠ›ã€‚åœ¨è¿™é¡¹å·¥ä½œ<sup id="fnref:1"><a href="#fn:1" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="Annervaz, K. M., Somnath Basu Roy Chowdhury, and Ambedkar Dukkipati. 'Learning beyond datasets: Knowledge Graph Augmented Neural Networks for Natural language Processing.' arXiv preprint arXiv:1802.05930 (2018).">[1]</span></a></sup>ä¸­ï¼Œæˆ‘ä»¬ä»¥çŸ¥è¯†å›¾è°±ï¼ˆKGï¼‰çš„å½¢å¼ä¸ºNLPæ¨¡å‹æä¾›å…ˆéªŒçŸ¥è¯†ï¼Œä½¿å¾—æ¨¡å‹å–å¾—æ›´å¥½çš„æ•ˆæœã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯å¼€å‘ä¸€ç§æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå¯ä»¥æ ¹æ®ä»»åŠ¡ä½¿ç”¨attentionæœºåˆ¶ä»çŸ¥è¯†å›¾è°±ä¸­æå–ç›¸å…³çš„å…ˆéªŒæ”¯æŒäº‹å®ã€‚ä¸ºäº†å‡å°‘attentionç©ºé—´ï¼Œæˆ‘ä»¬å¼•å…¥äº†åŸºäºå·ç§¯çš„æ¨¡å‹æ¥å­¦ä¹ çŸ¥è¯†å›¾è°±å®ä½“å’Œå…³ç³»é›†çš„è¡¨ç¤ºã€‚æå‡ºçš„æ–¹æ³•æ˜¯é«˜åº¦å¯æ‰©å±•çš„ï¼Œå¹¶å¯åº”ç”¨äºå¸¸ç”¨çš„NLPä»»åŠ¡ã€‚ä½¿ç”¨è¿™ç§æ–¹æ³•ï¼Œæˆ‘ä»¬åœ¨å®éªŒä¸­æ˜¾ç¤ºäº†æ–‡æœ¬åˆ†ç±»æ€§èƒ½çš„æ˜¾ç€æé«˜ã€‚æˆ‘ä»¬è¿˜è¯æ˜äº†ï¼Œå½“æ·±åº¦å­¦ä¹ æ¨¡å‹ä½¿ç”¨çŸ¥è¯†å›¾è°±ä»¥è¾…åŠ©æ—¶ï¼Œå¯ä»¥ç”¨è¾ƒä¸ºå°‘é‡çš„æ ‡è®°è®­ç»ƒæ•°æ®è¿›è¡Œè®­ç»ƒã€‚</p><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>ç°åœ¨æœºå™¨å­¦ä¹ ä¸»è¦æ˜¯é’ˆå¯¹ç‰¹å®šä»»åŠ¡ã€ç‰¹å®šè®­ç»ƒæ•°æ®è¿›è¡Œè®­ç»ƒçš„æ¨¡å‹ã€‚è™½ç„¶transfer learningè¯•å›¾å°†å­¦ä¹ ä»ä¸€ä¸ªä»»åŠ¡è¿ç§»åˆ°å¦ä¸€ä¸ªä»»åŠ¡ï¼Œä½†åœ¨å¯æ‰©å±•æ€§æ–¹é¢æœ‰å±€é™æ€§ï¼Œé€šå¸¸æ˜¯å…·ä½“åœ°é’ˆå¯¹æŸä¸ªçš„ä»»åŠ¡ã€‚å¦ä¸€æ–¹é¢ï¼Œæˆ‘ä»¬çŸ¥é“äººç±»å…·æœ‰ä¸€ç§å†…åœ¨çš„èƒ½åŠ›ï¼Œå¯ä»¥æ ¹æ®éœ€æ±‚ä»è„‘ä¸­è·å–æ‰€éœ€çš„çŸ¥è¯†ï¼Œå¹¶ç»“åˆæˆ‘ä»¬æ–°å­¦ä¹ çš„æ¦‚å¿µæ¥è§£å†³é—®é¢˜ã€‚</p><p>è¿™å°±å¼•å‡ºäº†æˆ‘ä»¬è¦åœ¨æœ¬æ–‡ä¸­è®¨è®ºçš„é—®é¢˜ï¼šæ˜¯å¦æœ‰å¯èƒ½è®¾è®¡ä¸€ä¸ªå­¦ä¹ æ¨¡å‹ï¼Œé™¤äº†ä»åŸ¹è®­æ•°æ®é›†ä¸­å­¦ä¹ å¤–ï¼Œè¿˜å¯ä»¥åœ¨é¢„æµ‹æ—¶åˆ©ç”¨å¤§é‡å¤–åœ¨çš„çŸ¥è¯†ï¼Ÿ<img src="http://oi4yiqiop.bkt.clouddn.com/2018-05-03-WX20180503-190446%402x.png" alt="X20180503-190446@2"></p><p>æˆ‘ä»¬æœ‰ä¸€ä¸ªåŸºæœ¬çš„æƒ³æ³•å¦‚ä¸Šå›¾ï¼Œ$\mathcal{X}$æ˜¯åŸæœ¬çš„è¾“å…¥ï¼Œ$\mathcal{Y}$æ˜¯è¾“å‡ºã€‚é€šè¿‡çŸ¥è¯†åº“è¡¥å……ã€å¢å¼º$\mathcal{X}$ï¼Œä»¥å¾—åˆ°$\mathcal{X_w}$ï¼Œå°†ä¸¤è¿™ä¸²è”ï¼Œè·å¾—$\mathcal{Xâ€™}$ä½œä¸ºæ–°çš„è¾“å…¥ã€‚</p><p>è¿™é‡Œæˆ‘ä»¬çŸ¥è¯†åº“ä»¥çŸ¥è¯†å›¾è°±çš„å½¢åŠ¿å‘ˆç°ï¼Œä¸»è¦å°†ä¸€ä¸ªäº‹å®ï¼ˆfactï¼‰è¡¨ç°ä¸ºä¸‰å…ƒç»„ï¼š(subject entity, relation, object entity)ç®€è®°ä¸º(h,r,t)ã€‚å…¶ä»–å…³äºçŸ¥è¯†å›¾è°±çš„ä»‹ç»å¯ä»¥å‚è€ƒä»¥å‰çš„ç¬”è®°å’Œç›¸å…³çš„æ–‡çŒ®ï¼Œè¿™é‡Œä¸å†èµ˜è¿°ã€‚</p><p>é€šå¸¸æˆ‘ä»¬é€šè¿‡è®­ç»ƒé›†æ¥å¾—åˆ°æˆ‘ä»¬æ‰€éœ€çš„æ¨¡å‹ï¼Œä½†æ˜¯å®ƒå¾€å¾€ç¼ºä¹world knowledgeæˆ–è€…å¸¸è¯†ï¼Œç»“æœå¾€å¾€ä¼šæœ‰åå·®ã€‚ä¾‹å¦‚ ï¼šâ€œç‰¹æœ—æ™®æ…°é—®äº†å¾—å…‹è¨æ–¯å·çš„é£“é£å¹¸å­˜è€…å’Œä»–ä»¬çš„å®¶äººâ€ï¼Œæˆ‘ä»¬éœ€è¦çŸ¥é“$\langle \text{ç‰¹æœ—æ™®},\text{æ€»ç»Ÿ},\text{ç¾å›½} \rangle$å’Œ$\langle \text{å¾—å…‹è¨æ–¯å·},\text{å·},\text{ç¾å›½} \rangle$æ‰èƒ½åˆ¤æ–­è¿™æ˜¯ä¸€ä¸ªæ”¿æ²»äº‹ä»¶ã€‚å› æ­¤æˆ‘ä»¬è®¤ä¸ºå¯¹äºæœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œé™¤äº†ä»£è¡¨ground-truthçš„ç”¨äºè®­ç»ƒçš„æ•°æ®é›†ä»¥å¤–ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥ä»ç»“æ„åŒ–çš„çŸ¥è¯†åº“è·å–ç›¸å…³çŸ¥è¯†ï¼Œä»¥æé«˜æ•´ä½“æ€§èƒ½ã€‚</p><p>å› æ­¤æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œå¯ä»¥æ ¹æ®éœ€æ±‚ä»çŸ¥è¯†å›¾è°±ä¸­æå–ç›¸å…³çš„äº‹å®ï¼Œå¹¶å°†å…¶ä¹Ÿä½œä¸ºè¾“å…¥ç‰¹å¾åŠ ä»¥è¡¥å……ã€‚ç‰¹åˆ«çš„ï¼Œå½“çŸ¥è¯†å›¾è°±éå¸¸å¤§çš„æ—¶å€™ï¼Œå³å…¶ä¸­çš„ä¸‰å…ƒç»„æ•°é‡éå¸¸å¤§ï¼Œä»¥è‡³äºæˆ‘ä»¬ä¸å¯èƒ½é€ä¸€æ¯”è¾ƒæ¥æå‡ºç›¸å…³ä¿¡æ¯æ—¶ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§åŸºäºæ·±åº¦å­¦ä¹ çš„æœå¯»æœºåˆ¶ï¼Œæ¥å¤§å¤§æé«˜æœå¯»é€Ÿåº¦ï¼Œæˆ‘ä»¬å°†åœ¨åæ–‡å…·ä½“æè¿°ã€‚</p><h2 id="2-Knowledge-graph-representations"><a href="#2-Knowledge-graph-representations" class="headerlink" title="2. Knowledge graph representations"></a>2. Knowledge graph representations</h2><p>å®ä½“å’Œå…³ç³»éœ€è¦è¿›è¡Œembeddingä»¥è¿›è¡Œåç»­å¤„ç†ï¼Œç›®å‰æœ‰å¾ˆå¤šç§çŸ¥è¯†å›¾è°±çš„è¡¨ç¤ºæ–¹æ³•ï¼Œä¸»è¦å¯ä»¥è¢«åˆ†ä¸ºï¼šstructure-based embeddingï¼Œsemantically-enriched embeddingã€‚</p><h4 id="structure-based-embedding"><a href="#structure-based-embedding" class="headerlink" title="structure-based embedding"></a>structure-based embedding</h4><p>å…¶ä¸­åŒ…æ‹¬ç»å…¸çš„TransEä»¥åŠå…¶å„ç§å˜ä½“ï¼Œå®ƒçš„åŸºæœ¬å‡è®¾å°±æ˜¯$h + r = t$. ä¹‹å‰æœ‰ä¸€ç¯‡ç¬”è®°ä¸»è¦ä»‹ç»çš„å°±æ˜¯è¿™ç±»çŸ¥è¯†å›¾è°±è¡¨ç¤º<a href="https://blog.lorrin.info/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/" target="_blank" rel="noopener">è¿™é‡Œ</a>ã€‚</p><h4 id="semantically-enriched-embedding"><a href="#semantically-enriched-embedding" class="headerlink" title="semantically-enriched embedding"></a>semantically-enriched embedding</h4><p>è¿™äº›embeddingæŠ€æœ¯å­¦ä¹ è¡¨ç¤ºKGçš„å®ä½“/å…³ç³»åŠå…¶è¯­ä¹‰ä¿¡æ¯ã€‚ ç¥ç»å¼ é‡ç½‘ç»œï¼ˆNTNï¼‰Socher et al [2011]æ˜¯è¯¥é¢†åŸŸçš„å…ˆé©±å·¥ä½œï¼Œå®ƒä½¿ç”¨å¹³å‡è¯åµŒå…¥å’ŒåŸºäºå¼ é‡çš„æ“ä½œåˆå§‹åŒ–å®ä½“å‘é‡ã€‚ æœ€è¿‘æ¶‰åŠè¿™ä¸ªæƒ³æ³•çš„ä½œå“æ˜¯â€œè”åˆå¯¹é½â€Zhong et alã€‚ [2015]å’ŒSSP Xiao et alã€‚[2017]ã€‚ DKRL Xie et al [2016]æ˜¯ä¸€ç§KGè¡¨ç¤ºæŠ€æœ¯ï¼Œå®ƒä¹Ÿä¿ç•™äº†TransEæ¨¡å‹ç®€å•ç»“æ„çš„æ–‡æœ¬æè¿°æ€§ã€‚ é¢„è®­è¿‡çš„word2vecè¢«ç”¨æ¥å½¢æˆå®ä½“è¡¨ç¤ºï¼Œé€šè¿‡ä¸€ä¸ªå·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰æ¥çº¦æŸè¦ä¿æŒçš„å…³ç³»ã€‚</p><p>ä½œè€…é‡‡ç”¨äº†DKRLï¼Œå› ä¸ºå®ƒå¼ºè°ƒäº†æ–‡æœ¬çš„è¯­ä¹‰æè¿°ï¼ŒåŒæ—¶ï¼Œå®ƒä¹Ÿç»§æ‰¿äº†TransEçš„æ–¹æ³•ã€‚å› æ­¤æˆ‘ä»¬èƒ½å¤Ÿé€šè¿‡$t = h + r$çš„å…³ç³»æ¥æå–ç›¸å…³å®ä½“æˆ–å…³ç³»ã€‚è¿™å¤§å¤§å‡å°‘äº†æå–factï¼ˆä¸‰å…ƒç»„ï¼‰çš„å¤æ‚åº¦ï¼Œå› ä¸ºå®ä½“å…³ç³»çš„ç»„åˆæ•°è¿œå°äºä¸‰å…ƒç»„çš„æ•°é‡ï¼Œå› æ­¤èƒ½å¤Ÿè®©è¿™ä¸ªè¿‡ç¨‹çš„é€Ÿåº¦æ›´å¿«ã€‚</p><h2 id="3-The-proposed-model"><a href="#3-The-proposed-model" class="headerlink" title="3. The proposed model"></a>3. The proposed model</h2><p>æˆ‘ä»¬ä»¥ä¸€ä¸ªæ–‡æœ¬åˆ†ç±»æ¨¡å‹ä¸ºä¾‹ï¼Œæ¨¡å‹çš„å‚æ•°ä¸º$\Theta$ï¼Œè®­ç»ƒé›†ä¸º$x$ï¼Œæ ‡ç­¾ä¸º$y$ï¼Œæˆ‘ä»¬éœ€è¦æœ€å¤§åŒ–ä¸‹åˆ—æ–¹ç¨‹ï¼š<br>$$<br>\max_{\Theta}{P(y|x, \Theta)}<br>$$</p><p>å› æ­¤ï¼š<br>$$<br>\Theta = \arg\max_{\Theta} {\log{P(y|x, \Theta)}}<br>$$<br>è¿™é‡Œï¼Œæˆ‘ä»¬é€šè¿‡ç»“åˆworld knowledgeç‰¹å¾$x_w$æ¥å¢å¼ºç›‘ç£å­¦ä¹ è¿‡ç¨‹ã€‚ä½¿ç”¨æ•°æ®$x$æ£€ç´¢world knowledgeç‰¹å¾ï¼Œä½¿ç”¨å•ç‹¬çš„æ¨¡å‹ï¼Œå…¶ä¸­$x_w = F(x, \Theta^{(2)})$ã€‚ å› æ­¤ï¼Œæˆ‘ä»¬ä¿®æ”¹çš„ç›®æ ‡å‡½æ•°ä¸ºï¼š<br>$$<br>\max_{\Theta}{P(y|x, x_w, \Theta^{(1)})}<br>$$<br>å…¶ä¸­$\Theta = {\Theta^{(1)}, \Theta^{(2)}}$ã€‚å¯ä»¥è·å¾—ä¼˜åŒ–çš„å‚æ•°ï¼š<br>$$<br>\Theta = \arg\max_{\Theta} {\log{P(y|x,F(x, \Theta^{(2)}), \Theta^{(1)})}}<br>$$<br>åé¢çš„éƒ¨åˆ†ç€é‡äºå‡½æ•°Fçš„è¡¨è¾¾ï¼Œè¯¥å‡½æ•°ä½¿ç”¨æ•°æ®xè¿›è¡Œäº‹å®ä¸‰é‡æ£€ç´¢ã€‚åœ¨å®éªŒä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨ç»è¿‡softmaxçš„è¾“å…¥çš„LSTM Greff et al. [2015]ç¼–ç ä½œä¸ºPçš„å½¢å¼ã€‚å¯¹äºFï¼Œæˆ‘ä»¬ä½¿ç”¨soft attentionã€‚</p><p>åŸºäºæ­¤ï¼Œæˆ‘ä»¬æå‡ºä¸¤ç§æ¨¡å‹ï¼šA. æœ´ç´ æ¨¡å‹ï¼›B. åŸºäºå·ç§¯çš„å®ä½“å’Œå…³ç³»é›†ç¾¤è¡¨ç¤º</p><h4 id="A-æœ´ç´ æ¨¡å‹"><a href="#A-æœ´ç´ æ¨¡å‹" class="headerlink" title="A. æœ´ç´ æ¨¡å‹"></a>A. æœ´ç´ æ¨¡å‹</h4><p>å‰é¢è§£é‡Šè¿‡ï¼ŒKGçš„å®ä½“å’Œå…³ç³»ä½¿ç”¨DKRLè¿›è¡Œç¼–ç ã€‚ ä»¤$e_i \in \mathbb{R}^m$ä»£è¡¨å®ä½“içš„ç¼–ç ï¼Œ$r_j\in \mathbb R^m$ä»£è¡¨KGä¸­ç¬¬jä¸ªå…³ç³»ã€‚ è¾“å…¥æ–‡æœ¬ä»¥ä¸²è”çš„å•è¯å‘é‡$x =(x_1,x_2,â€¦,x_T)$çš„å½¢å¼é¦–å…ˆä½¿ç”¨LSTM Greff et al. [2015]æ¨¡å—å¦‚ä¸‹ï¼Œ<br>$$<br>h_t = f(x_t, h_{t-1})<br>$$<br>ä»¥åŠ<br>$$<br>o = \frac{1}{T}\sum_{t=1}^{T}{h_t}<br>$$<br>$h_t \in \mathbb{R}^n$æ˜¯LSTMçš„éšè—çŠ¶æ€ï¼Œfæ˜¯éçº¿æ€§å‡½æ•°ï¼ŒTæ˜¯åºåˆ—é•¿åº¦ã€‚ ç„¶åå¦‚ä¸‹å½¢æˆä¸€ä¸ªä¸Šä¸‹æ–‡å‘é‡ï¼Œ<br>$$<br>C = ReLU(o^T W)<br>$$<br>å…¶ä¸­ï¼Œ$W\in \mathbb R^n \times m$è¡¨ç¤ºæƒé‡å‚æ•°ã€‚è®¾ç½®ä¸¤ä¸ªåŒæ ·çš„è¿‡ç¨‹ä»¥å½¢æˆä¸¤ä¸ªç‹¬ç«‹çš„ä¸Šä¸‹æ–‡å‘é‡ï¼Œä¸€ä¸ªç”¨äºå®ä½“æ£€ç´¢($C_E$)å’Œä¸€ä¸ªç”¨äºå…³ç³»æ£€ç´¢($C_R$)ã€‚</p><p>ç”±äºåœ¨æœ´ç´ æ¨¡å‹ä¸­KGçš„äº‹å®ä¸‰å…ƒç»„çš„æ•°é‡æ˜¯æ•°ä»¥ç™¾ä¸‡è®¡çš„ï¼Œæ‰€ä»¥æˆ‘ä»¬åˆ†åˆ«å¯¹å®ä½“å’Œå…³ç³»ç©ºé—´äº§ç”Ÿæ³¨æ„åŠ›ã€‚ ç„¶åä½¿ç”¨æ£€ç´¢åˆ°çš„å®ä½“å’Œå…³ç³»å½¢æˆäº‹å®ã€‚ä½¿ç”¨å®ä½“ä¸Šä¸‹æ–‡å‘é‡çš„å®ä½“çš„æ³¨æ„åŠ›ç”±ä¸‹å¼ç»™å‡ºï¼š<br>$$<br>\alpha_{e_i} = \frac{\exp{C_E^T{e_i}}}{\sum_{j=0}^{|E|} \exp{C_E^T{e_j}}}<br>$$<br>åŒç†ï¼Œå…³ç³»çš„æ³¨æ„åŠ›ï¼š<br>$$<br>\alpha_{r_i} = \frac{\exp{C_R^T{r_i}}}{\sum_{j=0}^{|R|} \exp{C_R^T{r_j}}}<br>$$<br><img src="http://oi4yiqiop.bkt.clouddn.com/2018-05-10-image-201805110007120.png" alt="mage-20180511000712"></p><p>å›¾2æ˜¾ç¤ºäº†å®ä½“/å…³ç³»æ£€ç´¢çš„ç¤ºæ„å›¾ã€‚åœ¨è®¡ç®—å‡ºæœ€ç»ˆçš„å®ä½“å’Œå…³ç³»å‘é‡ä¹‹åï¼Œæˆ‘ä»¬å¸Œæœ›è¡¥å……äº‹å®ä¸‰å…ƒç»„ã€‚ç”¨äºå®éªŒçš„KGæŠ€æœ¯æ˜¯DKRLï¼Œå…¶ä½¿ç”¨TransEæ¨¡å‹å‡è®¾($h + r = t$)ã€‚å› æ­¤ï¼Œä½¿ç”¨ä¸»é¢˜å®ä½“(subject entity)å’Œå…³ç³»ï¼Œæˆ‘ä»¬å°†å¯¹è±¡å®ä½“å½¢æˆä¸º$t = e + r$ã€‚ å› æ­¤ï¼Œæ£€ç´¢çš„äº‹å®ä¸‰å…ƒç»„æ˜¯$\mathcal F = [eï¼Œrï¼Œe + r]$ï¼Œå…¶ä¸­$F \in \mathbb R^{3m}$ã€‚ è¯¥æ£€ç´¢åˆ°çš„äº‹å®ä¿¡æ¯ä¸ä½¿ç”¨LSTMæ¨¡å—è·å¾—çš„è¾“å…¥xçš„ä¸Šä¸‹æ–‡å‘é‡(C)ä¸€èµ·è¿æ¥ã€‚ æœ€ç»ˆåˆ†ç±»æ ‡ç­¾$\mathbb y$çš„è®¡ç®—å¦‚ä¸‹ï¼Œ<br>$$<br>\mathcal Fâ€™ = ReLU(\mathcal F^T V) \\<br>\mathbb y = softmax([\mathcal Fâ€™ : C]^T U)<br>$$<br>å…¶ä¸­ï¼Œ$Vâˆˆ\mathbb R^{3m \times u}$å’Œ$U\in \mathbb R^{2u\times u}$æ˜¯è¦å­¦ä¹ çš„æ¨¡å‹å‚æ•°ã€‚ $\mathbb y$æ˜¯é¢„æµ‹ç»“æœï¼Œç”¨äºè®¡ç®—äº¤å‰ç†µæŸå¤±ã€‚æˆ‘ä»¬å°½é‡å‡å°‘è®­ç»ƒæ ·æœ¬çš„å¹³å‡æŸå¤±ï¼Œä»¥ä¾¿ä½¿ç”¨éšæœºæ¢¯åº¦ä¸‹é™æ¥å­¦ä¹ å„ç§æ¨¡å‹å‚æ•°ã€‚æœ€åçš„é¢„æµ‹$\mathbb y$ç°åœ¨åŒ…å«äº†æ¥è‡ªæ•°æ®é›†ç‰¹å®šä¿¡æ¯å’Œä¸–ç•ŒçŸ¥è¯†çš„ä¿¡æ¯ï¼Œä»¥å¸®åŠ©æé«˜æ€§èƒ½ã€‚åœ¨è”åˆåŸ¹è®­æ³¨æ„åŠ›æœºåˆ¶çš„åŒæ—¶è°ƒæ•´è‡ªå·±ï¼Œä»¥æ£€ç´¢è¿›è¡Œæœ€ç»ˆåˆ†ç±»æ‰€éœ€çš„ç›¸å…³äº‹å®ã€‚</p><h4 id="A-é¢„è®­ç»ƒKGæ£€ç´¢æ¨¡å‹"><a href="#A-é¢„è®­ç»ƒKGæ£€ç´¢æ¨¡å‹" class="headerlink" title="A+. é¢„è®­ç»ƒKGæ£€ç´¢æ¨¡å‹"></a>A+. é¢„è®­ç»ƒKGæ£€ç´¢æ¨¡å‹</h4><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-05-10-image-201805110034147.png" alt="mage-20180511003414"></p><p>æœ´ç´ æ¨¡å‹éœ€è¦è€ƒè™‘æ•´ä¸ªå®ä½“/å…³ç³»ç©ºé—´ï¼Œè¿™ä¸æ˜¯ä¸€ä¸ªå¥½çš„æ–¹æ³•ï¼Œå› ä¸ºæˆ‘ä»¬è§‚å¯Ÿåˆ°æ¯ä¸ªattentionçš„å®¹æ˜“é¥±å’Œã€‚åœ¨ä¸€èµ·è®­ç»ƒåˆ†ç±»å’Œæ£€ç´¢æ¨¡å—æ—¶ï¼Œæ¨¡å‹å¾€å¾€ä¼šå¿½ç•¥KGéƒ¨åˆ†ï¼Œè€Œæ¢¯åº¦åªé€šè¿‡åˆ†ç±»æ¨¡å—è¿›è¡Œä¼ æ’­ã€‚è¿™åœ¨ä¸€å®šç¨‹åº¦ä¸Šæ˜¯å¯ä»¥é¢„æ–™çš„ï¼Œå› ä¸ºå½“å‰ä»»åŠ¡çš„å¤§å¤šæ•°ç›¸å…³ä¿¡æ¯æ¥è‡ªè®­ç»ƒæ ·æœ¬ï¼Œåªæœ‰èƒŒæ™¯è¾…åŠ©ä¿¡æ¯æ¥è‡ªKGã€‚ç»è¿‡å‡ ä¸ªè®­ç»ƒé˜¶æ®µåï¼ŒKGæ£€ç´¢åˆ°çš„äº‹å®æ€»æ˜¯æ”¶æ•›åˆ°ä¸€ä¸ªå›ºå®šçš„å‘é‡ã€‚ä¸ºäº†å…‹æœè¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬è¯•å›¾å•ç‹¬é¢„å…ˆè®­ç»ƒKGæ£€ç´¢éƒ¨åˆ†ã€‚é¢„è®­ç»ƒçš„KGæ¨¡å‹ç”¨äºæ£€ç´¢äº‹å®ï¼Œç„¶åä¸åˆ†ç±»æ¨¡å—è¿æ¥ï¼ŒåŒæ—¶ï¼Œåœ¨è”åˆè®­ç»ƒæ—¶é€šè¿‡é¢„å…ˆè®­ç»ƒçš„æ¨¡å‹å¯èƒ½ä¼šå¯¼è‡´ä¼ é€’è¯¯å·®ã€‚æˆ‘ä»¬æ¨æ–­ï¼ŒKGä¸ä¼šè¿”å›å™ªéŸ³ï¼Œå¹¶ä¸”å¯¹äºä»»åŠ¡å…·æœ‰åŸºæœ¬ä¿¡æ¯ï¼Œå› ä¸ºå•ç‹¬çš„KGéƒ¨ä»¶å•ç‹¬æ˜¾ç¤ºå‡ºæ˜¾ç€çš„æ€§èƒ½ï¼ˆNews20ä¸º59ï¼…ï¼ŒSNLIä¸º66ï¼…ï¼‰ã€‚å›¾3æè¿°äº†æ•´ä¸ªè®­ç»ƒè¿‡ç¨‹ã€‚è¯¥ç¨‹åºè§£å†³äº†è”åˆè®­ç»ƒæ—¶KGæ£€ç´¢éƒ¨åˆ†ä¸­çš„æ¢¯åº¦é¥±å’Œé—®é¢˜ã€‚ä½†æ˜¯ï¼Œattentionæœºåˆ¶å¿…é¡»è¦†ç›–å¤§é‡å®ä½“/å…³ç³»çš„å…³é”®é—®é¢˜ä¾ç„¶å­˜åœ¨ã€‚</p><h4 id="B-åŸºäºå·ç§¯çš„å®ä½“å’Œå…³ç³»é›†ç¾¤è¡¨ç¤º"><a href="#B-åŸºäºå·ç§¯çš„å®ä½“å’Œå…³ç³»é›†ç¾¤è¡¨ç¤º" class="headerlink" title="B. åŸºäºå·ç§¯çš„å®ä½“å’Œå…³ç³»é›†ç¾¤è¡¨ç¤º"></a>B. åŸºäºå·ç§¯çš„å®ä½“å’Œå…³ç³»é›†ç¾¤è¡¨ç¤º</h4><p>åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æœºåˆ¶æ¥å‡å°‘çŸ¥è¯†å›¾è°±ä¸­éœ€è¦attentionçš„å¤§é‡å®ä½“/å…³ç³»ã€‚ æˆ‘ä»¬é€šè¿‡å­¦ä¹ ç±»ä¼¼å®ä½“/å…³ç³»å‘é‡çš„è¡¨ç¤ºæ¥å‡å°‘attentionç©ºé—´ã€‚</p><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-05-10-image-201805110044225.png" width="60%"></p><p>ä¸ºäº†èšç±»ç›¸ä¼¼çš„å®ä½“/å…³ç³»å‘é‡ï¼Œæˆ‘ä»¬ä½¿ç”¨k-meansèšç±»ï¼Œå¹¶åœ¨æ¯ä¸ªèšç±»ä¸­å½¢æˆå…·æœ‰ç›¸åŒæ•°é‡çš„å®ä½“/å…³ç³»å‘é‡çš„$l$ä¸ªèšç±»ã€‚ç„¶åä½¿ç”¨CNNå¯¹æ¯ä¸ªclusterè¿›è¡Œç¼–ç ã€‚k-meansèšç±»çš„è¾“å‡ºæ˜¯ä¸€ä¸ªå®ä½“/å…³ç³»å‘é‡åºåˆ—${e^T_1,e^T_2,â€¦,e^T_q}$ï¼Œå…¶ä¸­$e_i \in\mathbb R^m$ï¼Œæ¯ä¸ªèšç±»ä¸­çš„å…ƒç´ ä¸ªæ•°ä¸º$ q =âŒˆ\frac{| E |}{l}âŒ‰$ã€‚å¯¹äºæ¯ä¸ªclusterï¼Œè¿™äº›çŸ¢é‡è¢«å †å å½¢æˆ$\mathcal E$ä½œä¸ºåˆ°CNNç¼–ç å™¨çš„2Dè¾“å…¥ï¼Œå…¶ä¸­$\mathcal E\in\mathbb R^{m\times q}$ã€‚ åœ¨å¯»æ‰¾åˆé€‚æ»¤æ³¢å™¨å½¢çŠ¶çš„å®éªŒä¸­ï¼Œæˆ‘ä»¬å‘ç°ä½¿ç”¨2-Dæ»¤æ³¢å™¨ï¼Œè¯¥æ¨¡å‹æ— æ³•æ”¶æ•›ã€‚å› æ­¤ï¼Œæˆ‘ä»¬æ¨æ–­ï¼Œå‘é‡$e_i$ä¸­ä¸¤ä¸ªä¸åŒç´¢å¼•çš„æ½œåœ¨è¡¨ç¤ºä¸åº”è¯¥è¢«å·ç§¯ä¿®æ”¹ã€‚ç„¶åï¼Œæˆ‘ä»¬é‡‡ç”¨ä¸€ç»´å·ç§¯æ»¤æ³¢å™¨ï¼Œåªæ²¿$\mathcal E$åˆ—æ»‘åŠ¨ï¼Œå¦‚å›¾4æ‰€ç¤ºã€‚æ²¿ç€yè½´çš„æ­¥é•¿æ˜¯çª—å£é•¿åº¦kï¼Œå·ç§¯å±‚çš„è¾“å‡ºè¡¨ç¤ºä¸ºï¼š<br>$$<br>\mathcal Eâ€™(i,j) = W^T[e_{i,j}, e_{i+1,j},â€¦,e_{i+k-1, j}]^T<br>$$<br>å…¶ä¸­ï¼Œ$\mathcal Eâ€™(i,j)$æ˜¯è¾“å‡ºçŸ©é˜µ$\mathcal Eâ€™$çš„ç¬¬(i, j)ä¸ªå…ƒç´ ï¼Œ$W\in \mathbb R^k$æ˜¯å·ç§¯æƒé‡æ»¤æ³¢å™¨ã€‚ä¸ºäº†å‡å°‘å‚æ•°ç©ºé—´ï¼Œåœ¨å·ç§¯å±‚ä¹‹åæ”¾ç½®ä¸€ä¸ªpoolingå±‚ï¼Œæˆ‘ä»¬åªæ²¿yè½´ä½¿ç”¨ä¸€ç»´çª—å£ï¼Œç±»ä¼¼äºä¸Šé¢æåˆ°çš„å·ç§¯æ ¸ã€‚æˆ‘ä»¬ä½¿ç”¨äº†ä¸€ä¸ªåŒå±‚å·ç§¯ç½‘ç»œï¼Œå…¶æ­¥é•¿kå’Œæœ€å¤§æ± çª—å£nè¢«è°ƒæ•´ä»¥è·å¾—è¾“å‡º$\mathcal E_i\in \mathbb R^m$ï¼Œå…¶ä¸­iæ˜¯èšç±»ç´¢å¼•ã€‚å¯¹äºå…³ç³»ä¹Ÿè¿›è¡Œç±»ä¼¼çš„èšç±»è¿‡ç¨‹ï¼Œæ¥ç€å¯¹èšç±»å®ä½“è¿›è¡Œç¼–ç ã€‚è¿™æ ·ï¼Œå®ä½“å’Œå…³ç³»ç©ºé—´éƒ½è¢«ç¼©å‡ä¸ºåŒ…å«æ›´å°‘çš„å…ƒç´ ï¼Œæ¯ä¸ªclusteréƒ½æœ‰ä¸€ä¸ªå…ƒç´ ã€‚åœ¨å½¢æˆç´§å‡‘çš„å®ä½“ç©ºé—´$E$å’Œå…³ç³»ç©ºé—´$R$ä¹‹åï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ä¸ä¹‹å‰ç›¸åŒçš„æ­¥éª¤æ¥å½¢æˆattentionï¼Œä½†æ˜¯ç°åœ¨ï¼Œç”±äºæ¢¯åº¦æœ‰æ•ˆåœ°ä¼ é€’å¹¶ä¸”æ²¡æœ‰è¢«è¿‡å¤§çš„ç©ºé—´æ‰€é˜»å¡ï¼Œæ‰€ä»¥è®­ç»ƒæ›´æœ‰æ•ˆã€‚æ­¤å¤–ï¼Œç”±äºå·ç§¯æ¶æ„ä¹ŸåŒæ—¶å¾—åˆ°è®­ç»ƒï¼Œæ‰€ä»¥attentionæœºåˆ¶å¹¶æ²¡æœ‰åƒä»¥å‰é‚£æ ·é€šè¿‡å®ä½“å’Œå…³ç³»çš„å·¨å¤§ç©ºé—´æ¥å­¦ä¹ ã€‚</p><h2 id="4-Conclusion"><a href="#4-Conclusion" class="headerlink" title="4. Conclusion"></a>4. Conclusion</h2><p>å®éªŒè¡¨æ˜ï¼Œå¼•å…¥KGä¸ä»…é™ä½äº†æ·±åº¦å­¦ä¹ æ¨¡å‹å¯¹è®­ç»ƒé›†çš„ä¾èµ–ï¼Œè¿˜æ˜¾è‘—åœ°æé«˜äº†é¢„æµ‹ç»“æœçš„å‡†ç¡®åº¦ï¼Œåœ¨æ•°æ®é›†ä¸å¤Ÿçš„æƒ…å†µä¸‹æ•ˆæœæ›´ä½³æ‹”ç¾¤ã€‚æ­¤å¤–ï¼Œæœ¬æ–‡çš„æ–¹æ³•å¯¹world knowledgeçš„å¤„ç†ã€embeddingçš„æ–¹æ³•æ˜¯é«˜åº¦å¯æ‰©å±•ï¼Œå¯ä»¥åº”ç”¨äºå„ç§NLPä»»åŠ¡ã€‚</p><h2 id="Bibliography"><a href="#Bibliography" class="headerlink" title="Bibliography"></a>Bibliography</h2><p>ç¬”è®°å‚è€ƒ <a href="https://blog.csdn.net/TgqDT3gGaMdkHasLZv/article/details/80118742" target="_blank" rel="noopener">https://blog.csdn.net/TgqDT3gGaMdkHasLZv/article/details/80118742</a></p><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style: none; padding-left: 0; margin-left: 40px"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">1.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Annervaz, K. M., Somnath Basu Roy Chowdhury, and Ambedkar Dukkipati. â€˜Learning beyond datasets: Knowledge Graph Augmented Neural Networks for Natural language Processing.â€™ arXiv preprint arXiv:1802.05930 (2018).<a href="#fnref:1" rev="footnote"> â†©</a></span></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h2 id=&quot;Knowledge-Graph-Augmented-Neural-
      
    
    </summary>
    
      <category term="research" scheme="https://juewang.me/categories/research/"/>
    
    
      <category term="knowledge-graph" scheme="https://juewang.me/tags/knowledge-graph/"/>
    
      <category term="neural-network" scheme="https://juewang.me/tags/neural-network/"/>
    
      <category term="NLP" scheme="https://juewang.me/tags/NLP/"/>
    
  </entry>
  
  <entry>
    <title>Reinforcement Learning for Relation Classification from Noisy Data é˜…è¯»ç¬”è®°</title>
    <link href="https://juewang.me/posts/%5B2018.4.14%5DReinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"/>
    <id>https://juewang.me/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/</id>
    <published>2018-04-14T00:00:00.000Z</published>
    <updated>2018-04-14T21:39:01.246Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2 id="Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data-é˜…è¯»ç¬”è®°"><a href="#Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data-é˜…è¯»ç¬”è®°" class="headerlink" title="Reinforcement Learning for Relation Classification from Noisy Data é˜…è¯»ç¬”è®°"></a>Reinforcement Learning for Relation Classification from Noisy Data é˜…è¯»ç¬”è®°</h2><p><strong>æ‘˜è¦</strong>ï¼šç°æœ‰å…³ç³»åˆ†ç±»æ–¹æ³•ä¾èµ–è¿œç¨‹ç›‘ç£(distant supervision)ï¼Œå®ƒå‡å®šæåˆ°å®ä½“å¯¹çš„å¥å­éƒ½æè¿°äº†è¿™ä¸ªå®ä½“å¯¹çš„å…³ç³»ã€‚è¿™æ ·çš„æ–¹æ³•ä¸€èˆ¬åœ¨å¥å­é›†åˆè¿›è¡Œåˆ†ç±»ï¼Œä¸èƒ½è¯†åˆ«å…³ç³»å’Œå¥å­ä¹‹é—´çš„æ˜ å°„ï¼Œå¹¶ä¸”å¾ˆå¤§ç¨‹åº¦ä¸Šå—åˆ°æ ‡ç­¾å™ªéŸ³é—®é¢˜çš„å½±å“ã€‚åœ¨è¿™ç¯‡è®ºæ–‡<sup id="fnref:1"><a href="#fn:1" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="Feng, J., Huang, M., Zhao, L., Yang, Y., & Zhu, X. (2018). Reinforcement Learning for Relation Classification from Noisy Data.">[1]</span></a></sup>ä¸­ï¼Œä½œè€…æå‡ºäº†ä¸€ä¸ªä»æœ‰å™ªå£°å¤šæ•°æ®çš„å¥å­å±‚æ¬¡çš„å…³ç³»åˆ†ç±»æ¨¡å‹ã€‚è¯¥æ¨¡å‹æœ‰ä¸¤ä¸ªæ¨¡å—ï¼šä¸€ä¸ªå®ä¾‹é€‰æ‹©å™¨å’Œä¸€ä¸ªå…³ç³»åˆ†ç±»å™¨ã€‚å®ä¾‹é€‰æ‹©å™¨é€šè¿‡å¢å¼ºå­¦ä¹ é€‰æ‹©é«˜è´¨é‡çš„å¥å­ï¼Œå¹¶å°†é€‰å®šçš„å¥å­è¾“å…¥åˆ°å…³ç³»åˆ†ç±»å™¨ä¸­ï¼Œå…³ç³»åˆ†ç±»å™¨è¿›è¡Œå¥å­çº§é¢„æµ‹ï¼Œå¹¶å‘å®ä¾‹é€‰æ‹©å™¨æä¾›å¥–åŠ±ã€‚è¿™ä¸¤ä¸ªæ¨¡å—å…±åŒè®­ç»ƒä»¥ä¼˜åŒ–å®ä¾‹é€‰æ‹©å’Œå…³ç³»åˆ†ç±»è¿‡ç¨‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæˆ‘ä»¬çš„æ¨¡å‹å¯ä»¥æœ‰æ•ˆåœ°å¤„ç†æ•°æ®ä¸­çš„å™ªéŸ³ï¼Œå¹¶åœ¨å¥å­çº§åˆ«è·å¾—æ›´å¥½çš„å…³ç³»åˆ†ç±»æ€§èƒ½ã€‚</p><h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>å…³ç³»æŠ½å–æ˜¯nlpé¢†åŸŸä¸­ä¸€ä¸ªéå¸¸é‡è¦çš„ä»»åŠ¡ï¼Œå°¤å…¶åœ¨çŸ¥è¯†å›¾è°±æ„å»ºç­‰ä»»åŠ¡ä¸Šã€‚ç›¸å…³çš„å·¥ä½œå¯ä»¥å‚è€ƒæˆ‘ä¹‹å‰å†™çš„ç¬”è®°ï¼Œä¸»è¦è¿˜æ˜¯åˆ†ä¸ºä¸¤ç§ï¼šä¼ ç»Ÿçš„æ‰‹å·¥ç‰¹å¾æ–¹æ³•ï¼Œå’Œæ·±åº¦ç¥ç»ç½‘ç»œã€‚</p><p>ä¸ºäº†è·å¾—æ›´å¤§é‡çš„è®­ç»ƒæ•°æ®é›†ï¼ŒåŠç›‘ç£ã€è¿œç¨‹ç›‘ç£ï¼Œç”šè‡³æ— ç›‘ç£æ¨¡å‹è¢«æå‡ºã€‚åŠç›‘ç£æ¨¡å‹å¯¹ä¸€å¼€å§‹çš„å°‘é‡æ•°æ®è¦æ±‚è¾ƒé«˜ï¼Œå®¹æ˜“äº§ç”Ÿè¾ƒå¤§çš„åå·®ï¼›æ— ç›‘ç£å­¦ä¹ ç›®å‰è¿˜æ²¡æœ‰æ¯”è¾ƒæˆç†Ÿçš„è§£å†³æ–¹æ¡ˆã€‚</p><p>è¿™é‡Œä¸»è¦æä¸€ä¸‹è¿œç¨‹ç›‘ç£æ¨¡å‹ã€‚è¿œç¨‹ç›‘ç£æ¨¡å‹æœ‰ä¸€ä¸ªå¾ˆå¼ºçš„å‡è®¾ï¼šå¦‚æœä¸¤ä¸ªå®ä½“åœ¨ç»™å®šçš„çŸ¥è¯†åº“ä¸­æœ‰ä¸€ç§å…³ç³»ï¼Œåˆ™åŒ…å«è¿™ä¸¤ä¸ªå®ä½“çš„æ‰€æœ‰å¥å­éƒ½ä¼šæåŠè¯¥å…³ç³»ï¼Œå®é™…ä¸Šå½“ç„¶ä¼šæœ‰å¾ˆå¤§é—®é¢˜ï¼Œä¼šå¸¦æ¥å¾ˆå¤šæ ‡æ³¨é”™è¯¯çš„ä¿¡æ¯ã€‚æœ‰ä¸€äº›è§£å†³æ–¹æ³•å°±æ˜¯è½¬åŒ–ä¸ºbag-levelçš„å…³ç³»æ ‡æ³¨ã€‚ä¸€ä¸ªbagåŒ…å«æåŠç›¸åŒå®ä½“å¯¹çš„å¥å­ï¼Œä½†æœ‰å¯èƒ½æè¿°ä¸åŒçš„å…³ç³»ï¼Œå¦‚ä¸‹å›¾ã€‚</p><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-04-14-WX20180414-152317%402x.png" alt="X20180414-152317@2"></p><p>ä¸è¿‡å®é™…ä¸Šè¿˜æ˜¯ä¼šæœ‰é—®é¢˜ï¼š1. ä¸èƒ½å¤„ç†å¥å­çº§åˆ«çš„å…³ç³»åˆ†ç±»ï¼›2. å¦‚æœä¸€ä¸ªbagé‡Œçš„å¥å­éƒ½ä¸å«çŸ¥è¯†åº“ä¸­çš„å…³ç³»ï¼Œå³éƒ½æ˜¯å™ªå£°ï¼Œè¿™æ ·å¯¹æ€§èƒ½ä¼šæœ‰å¾ˆå¤§å½±å“ã€‚</p><p>ä¸ºè§£å†³ä¸Šè¿°çš„ä¸¤ä¸ªç¼ºé™·ï¼Œä½œè€…æå‡ºäº†å®ä¾‹é€‰å–å™¨ï¼Œå¹¶å°†å…¶å®šä¹‰ä¸ºä¸€ä¸ªå¼ºåŒ–å­¦ä¹ ä»»åŠ¡ã€‚å®ƒæœ‰ä¸¤ä¸ªç‰¹å¾ï¼š1. å¥å­é€‰æ‹©æ˜¯ä¸€ä¸ªåå¤è¯•é”™çš„è¿‡ç¨‹ï¼Œéœ€è¦ä»åˆ†ç±»å™¨ä¸­å¾—åˆ°é€‰å–å¥å­è´¨é‡çš„åé¦ˆï¼›2. åé¦ˆåœ¨æŒ‘é€‰ç»“æŸåå¾—åˆ°ï¼Œå› æ­¤æ˜¯æ»åçš„ã€‚è¿™ä¸¤ç‚¹éå¸¸æ»¡è¶³å¼ºåŒ–å­¦ä¹ çš„ç‰¹ç‚¹ã€‚</p><h2 id="2-Methodology"><a href="#2-Methodology" class="headerlink" title="2. Methodology"></a>2. Methodology</h2><p>ä½œè€…æå‡ºäº†ä¸€ä¸ªæ–°çš„å…³ç³»åˆ†ç±»æ¡†æ¶ï¼Œå®ƒå¯ä»¥ä»å™ªéŸ³æ•°æ®ä¸­é€‰æ‹©æ­£ç¡®çš„å¥å­ç”¨äºæ›´å¥½çš„å…³ç³»åˆ†ç±»ã€‚ æ‰€æå‡ºçš„æ¡†æ¶å¯ä»¥ä»æ¸…ç†çš„æ•°æ®ä¸­é¢„æµ‹å¥å­çº§åˆ«çš„å…³ç³»ï¼Œè€Œä¸æ˜¯åœ¨bagçº§åˆ«ã€‚å¥å­çº§åˆ«çš„é¢„æµ‹å¯¹éœ€è¦ç†è§£å¥å­çš„ä»»åŠ¡ï¼ˆå¦‚QAå’Œè¯­ä¹‰åˆ†æï¼‰æ›´åŠ å‹å¥½ã€‚<br>æˆ‘ä»¬çš„æ¡†æ¶åŒ…å«ä¸¤ä¸ªå…³é”®æ¨¡å—ï¼šä»å™ªå£°æ•°æ®ä¸­é€‰æ‹©æ­£ç¡®å¥å­çš„å®ä¾‹é€‰æ‹©å™¨ï¼Œä»¥åŠé¢„æµ‹å…³ç³»å¹¶ä½¿ç”¨æ¸…ç†æ•°æ®æ›´æ–°å…¶å‚æ•°çš„å…³ç³»åˆ†ç±»å™¨ã€‚ è¿™ä¸¤ä¸ªæ¨¡å—ç›¸äº’ä½œç”¨å…±åŒè®­ç»ƒã€‚</p><h3 id="Problem-definition"><a href="#Problem-definition" class="headerlink" title="Problem definition"></a>Problem definition</h3><p>æˆ‘ä»¬å®šä¹‰ä¸¤ä¸ªå­ä»»åŠ¡ï¼šå®ä¾‹é€‰æ‹©å’Œä¸€ä¸ªå…³ç³»åˆ†ç±»ã€‚</p><p>æˆ‘ä»¬å®šä¹‰å®ä¾‹é€‰æ‹©é—®é¢˜ï¼šç»™å®šä¸€ç»„(sentence, relation label)ï¼Œå¦‚$X = {(x_1,r_1),(x_2,r_2),â€¦,(x_n,r_n)}$ï¼Œå…¶ä¸­$x_i$æ˜¯ä¸ä¸¤ä¸ªå®ä½“$(e_{1i},e_{2i})$ç›¸å…³çš„å¥å­ï¼Œ$r_i$æ˜¯ç”±è¿œç¨‹ç›‘ç£äº§ç”Ÿçš„å…³ç³»æ ‡ç­¾ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯ç¡®å®šå“ªä¸ªå¥å­çœŸæ­£æè¿°äº†è¿™ç§å…³ç³»ï¼Œå¹¶ä¸”åº”è¯¥è¢«é€‰ä½œè®­ç»ƒå®ä¾‹ã€‚</p><p>å…³ç³»åˆ†ç±»é—®é¢˜è¡¨è¿°å¦‚ä¸‹ï¼šç»™å®šä¸€ä¸ªå¥å­$x_i$å’Œæ‰€æåˆ°çš„å®ä½“å¯¹$(h_i,t_i)$ï¼Œç›®æ ‡æ˜¯é¢„æµ‹$x_i$ä¸­çš„è¯­ä¹‰å…³ç³»$r_i$ã€‚æ¨¡å‹ä¼°è®¡æ¦‚ç‡ï¼š$p_{\Phi}(r_i | x_i,h_i,t_i)$ã€‚</p><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-04-14-WX20180414-165503%402x.png" alt="X20180414-165503@2"></p><h3 id="Instance-Selector"><a href="#Instance-Selector" class="headerlink" title="Instance Selector"></a>Instance Selector</h3><p>è¿™é‡Œçš„Instance Selectorè¢«å½“ä½œå¼ºåŒ–å­¦ä¹ é—®é¢˜æ¥å¤„ç†ï¼Œå› æ­¤policyçš„æ›´æ–°æœ‰æ»åæ€§ï¼Œä½œè€…ä¸ºäº†åŠ å¿«æ›´æ–°é€Ÿåº¦ï¼ŒæŠŠæ‰€æœ‰å¥å­å®ä¾‹$X={x_1, â€¦,x_n}$åˆ†ä¸ºNä¸ªbag $B = {B^1, B^2, â€¦, B^N}$ï¼Œæ¯ä¸€ä¸ª$B^k$éƒ½åŒ…å«åŒä¸€ä¸ªå®ä½“å¯¹ï¼Œä¸”æ ‡æ³¨å…³ç³»éƒ½ä¸º$r^k$ã€‚</p><ul><li><p><strong>State</strong>ï¼šç¼–ç ä»¥ä¸‹ä¿¡æ¯ï¼š1) å½“å‰å¥å­çš„å‘é‡è¡¨ç¤ºï¼Œä»CNNçš„éçº¿æ€§å±‚è·å¾—ç”¨äºå…³ç³»åˆ†ç±»çš„å½“å‰å¥å­çš„å‘é‡è¡¨ç¤º; 2) è¢«é€‰çš„å¥å­é›†åˆçš„è¡¨ç¤ºï¼Œå®ƒæ˜¯æ‰€æœ‰é€‰æ‹©å¥å­çš„å‘é‡è¡¨ç¤ºçš„å¹³å‡å€¼; 3) ä¸€ä¸ªå¥å­ä¸­å®ä½“å¯¹çš„å‘é‡è¡¨ç¤ºï¼Œä»é¢„å…ˆè®­ç»ƒçš„çŸ¥è¯†å›¾è°±embeddingä¸­è·å¾—ã€‚</p></li><li><p><strong>Action</strong>ï¼šå®šä¹‰action $a_i \in {0,1}$ è¡¨ç¤ºæ˜¯å¦é€‰å–ç¬¬iä¸ªå¥å­ï¼Œ$a_i$çš„å–å€¼ç”±policy functionå¾—åˆ°ï¼Œå®šä¹‰å¦‚ä¸‹ï¼š<br>$$<br>\pi_{\Theta}(s_i,a_i) = a_i \sigma(W <em> F(s_i) + b) + (1 - a_i)(1 - \sigma(W </em> F(s_i)+b))<br>$$</p></li><li><p><strong>Reward</strong>ï¼šreward functionæ˜¯æ‰€é€‰å¥å­æ•ˆç”¨çš„æŒ‡æ ‡ã€‚å¯¹äºæŸäº›bag $B = {x_1,â€¦ ,x_{| B |}}$ï¼Œæˆ‘ä»¬ä¸ºæ¯ä¸ªå¥å­é€‰æ‹©ä¸€ä¸ªactionï¼Œä»¥ç¡®å®šæ˜¯å¦åº”è¯¥é€‰æ‹©å½“å‰å¥å­ã€‚æˆ‘ä»¬å‡è®¾è¯¥æ¨¡å‹åœ¨å®Œæˆæ‰€æœ‰é€‰æ‹©æ—¶å…·æœ‰æœ€ç»ˆå¥–åŠ±ã€‚ å› æ­¤ï¼Œæˆ‘ä»¬åªåœ¨ç»ˆç«¯çŠ¶æ€$s_{| B | +1}$æ”¶åˆ°å»¶è¿Ÿå¥–åŠ±ï¼Œå…¶ä»–çš„å¥–åŠ±ä¸ºé›¶ã€‚ rewardæ˜¯åŸºäºCNNçš„åˆ†ç±»åé¦ˆå¾—åˆ°ã€‚</p></li></ul><h3 id="Relation-Classifier"><a href="#Relation-Classifier" class="headerlink" title="Relation Classifier"></a>Relation Classifier</h3><p>è¿™é‡Œç”¨çš„åˆ†ç±»æ¨¡å‹æ¯”è¾ƒç®€å•ï¼Œä¸€ä¸ªç»å…¸çš„CNNã€‚</p><p>è¾“å…¥å±‚å¯ä»¥è¢«åˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼š</p><ol><li>word embedding</li><li>position embeddingï¼šä¸¤ä¸ªå›ºå®šé•¿åº¦çš„å‘é‡ï¼Œè¡¨ç¤ºè¯¥è¯åˆ†åˆ«åˆ°ä¸¤ä¸ªå®ä½“åº—è·ç¦»ã€‚</li></ol><h2 id="3-Analysis"><a href="#3-Analysis" class="headerlink" title="3. Analysis"></a>3. Analysis</h2><p>ä½œè€…ç”¨çš„æ•°æ®é›†æ˜¯New York Timesï¼Œä½œè€…éšæœºæŒ‘é€‰300å¥å­äººå·¥æ ‡æ³¨ï¼Œå†å¯¹å…¶åšè¯„æµ‹ã€‚å¯¹æ¯”çš„baselineåŒ…æ‹¬CNNã€CNN+Max(æ¯ä¸ªbagé€‰ä¸€ä¸ªæ­£ç¡®çš„å¥å­)ã€CNN+ATTã€‚æœ€åç»“æœä¸Šçœ‹å‡ºï¼Œæœ¬æ–‡çš„CNN+RLæ¨¡å‹å–å¾—äº†æœ€å¥½çš„ç»“æœï¼Œè¿™è¡¨æ˜å¼ºåŒ–å­¦ä¹ å¯¹äºè¯¥ä»»åŠ¡æ˜¯è¡Œä¹‹æœ‰æ•ˆçš„ï¼›å¹¶ä¸”å¥å­å±‚æ¬¡çš„æ¨¡å‹åœ¨è¯„æµ‹ä¸­æ™®éå¥½äºbagæ¨¡å‹ã€‚</p><p>å¼ºåŒ–å­¦ä¹ æ˜¯ç›®å‰æ¯”è¾ƒç«çƒ­çš„æŠ€æœ¯ï¼Œå®ƒåœ¨nlpç›¸å…³ä»»åŠ¡çš„åº”ç”¨ä»åœ¨æ¢ç´¢ä¸­ï¼Œä½†æ˜¯æœ€è¿‘çš„è®ºæ–‡ç¡®å®æœ‰å¾ˆå¤šéƒ½åœ¨è®¨è®ºå®ƒï¼Œå¹¶ä¸”ä¹Ÿåšåˆ°äº†ä¸é”™çš„æ•ˆæœã€‚å¸Œæœ›ä»è¿™ç¯‡æ–‡ç« ä¸ºå…¥å£ï¼Œå¼€å§‹äº†è§£å¼ºåŒ–å­¦ä¹ åŠå…¶åœ¨nlpä¸Šçš„åº”ç”¨ã€‚</p><p>è¿™ç¯‡æ–‡ç« ä¸­ï¼Œå¼ºåŒ–å­¦ä¹ ä¸»è¦æ˜¯ç”¨äºé€‰æ‹©å™ªå£°æ•°æ®ï¼Œç”¨ä»¥å‡å°‘æ•°æ®é›†çš„åå·®ç­‰ã€‚ä½†æ˜¯æˆ‘ä»¬ç›¸ä¿¡å¼ºåŒ–å­¦ä¹ èƒ½åšçš„ä¸ä»…å¦‚æ­¤ï¼Œäº‹å®ä¸Šæœ€è¿‘çš„é¡¶ä¼šè¿˜æ˜¯æœ‰ä¸€äº›ç›¸å…³çš„å·¥ä½œçš„ï¼Œå¯ä»¥æ”¾åˆ°ä»¥åå†çœ‹ã€‚</p><h2 id="Bibliography"><a href="#Bibliography" class="headerlink" title="Bibliography"></a>Bibliography</h2><p>æœ¬æ–‡çš„c++å®ç°ï¼š<a href="https://github.com/JuneFeng/RelationClassification-RL" target="_blank" rel="noopener">https://github.com/JuneFeng/RelationClassification-RL</a></p><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style: none; padding-left: 0; margin-left: 40px"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">1.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Feng, J., Huang, M., Zhao, L., Yang, Y., &amp; Zhu, X. (2018). Reinforcement Learning for Relation Classification from Noisy Data.<a href="#fnref:1" rev="footnote"> â†©</a></span></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h2 id=&quot;Reinforcement-Learning-for-Relati
      
    
    </summary>
    
      <category term="research" scheme="https://juewang.me/categories/research/"/>
    
    
      <category term="relation-extraction" scheme="https://juewang.me/tags/relation-extraction/"/>
    
      <category term="relation-classification" scheme="https://juewang.me/tags/relation-classification/"/>
    
      <category term="reinforcement-learning" scheme="https://juewang.me/tags/reinforcement-learning/"/>
    
  </entry>
  
  <entry>
    <title>A Neural Model for Joint Event Detection and Summarization é˜…è¯»ç¬”è®°</title>
    <link href="https://juewang.me/posts/%5B2018.4.4%5DA-Neural-Model-for-Joint-Event-Detection-and-Summarization/"/>
    <id>https://juewang.me/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/</id>
    <published>2018-04-04T00:00:00.000Z</published>
    <updated>2018-04-04T22:12:54.420Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2 id="A-Neural-Model-for-Joint-Event-Detection-and-Summarization-é˜…è¯»ç¬”è®°"><a href="#A-Neural-Model-for-Joint-Event-Detection-and-Summarization-é˜…è¯»ç¬”è®°" class="headerlink" title="A Neural Model for Joint Event Detection and Summarization é˜…è¯»ç¬”è®°"></a>A Neural Model for Joint Event Detection and Summarization é˜…è¯»ç¬”è®°</h2><p><strong>æ‘˜è¦</strong>ï¼šTwitteräº‹ä»¶æ£€æµ‹æ—¨åœ¨è¯†åˆ«æ¨æ–‡æµä¸­çš„first storiesã€‚ä¸€èˆ¬è®¤ä¸ºç”±ä¸¤ä¸ªå­ä»»åŠ¡ç»„æˆã€‚é¦–å…ˆï¼Œè¿‡æ»¤æ‰æ™®é€šçš„æˆ–ä¸ç›¸å…³çš„æ¨æ–‡ã€‚å…¶æ¬¡ï¼Œæ¨æ–‡ä¼šè¢«è‡ªåŠ¨åˆ†ç±»åˆ°event clusterä¸­ã€‚ä¼ ç»Ÿä¸Šï¼Œå°½ç®¡è¿™ä¸¤ä¸ªä»»åŠ¡ä¹‹é—´å­˜åœ¨ç›¸äº’ä¾èµ–å…³ç³»ï¼Œå®ƒä»¬ä»è¢«å•ç‹¬å¤„ç†ï¼Œå¹¶é€šè¿‡pipelineæ•´åˆã€‚å¦å¤–ï¼Œè¿˜æœ‰ä¸€ä¸ªç›¸å…³çš„ä»»åŠ¡æ˜¯æ‘˜è¦ï¼Œå³æå–èƒ½å¤Ÿä»£è¡¨event clusterçš„ç®€æ´æ‘˜è¦ã€‚è¿™é‡Œå’Œä¸Šä¸ªæš‘å‡çœ‹çš„Wang, Z.<sup id="fnref:2"><a href="#fn:2" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="Wang, Z., Shou, L., Chen, K., Chen, G., & Mehrotra, S. (2015). On summarization and timeline generation for evolutionary tweet streams. *IEEE Transactions on Knowledge and Data Engineering*, *27*(5), 1301-1315.">[2]</span></a></sup>çš„å·¥ä½œæ¯”è¾ƒç›¸ä¼¼ã€‚</p><p>åœ¨æœ¬æ–‡<sup id="fnref:1"><a href="#fn:1" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="Wang, Z., & Zhang, Y. (2017, August). A neural model for joint event detection and summarization. In *Proceedings of the 26th International Joint Conference on Artificial Intelligence* (pp. 4158-4164). AAAI Press.">[1]</span></a></sup>ä¸­ï¼Œæˆ‘ä»¬æ„å»ºäº†ä¸€ä¸ªjoint modelæ¥ç­›é€‰ã€èšç±»å’Œæ‘˜è¦æ¨æ–‡ä¸­çš„eventã€‚ç‰¹åˆ«çš„ï¼Œæˆ‘ä»¬åˆ©ç”¨æ·±åº¦è¡¨ç¤ºå­¦ä¹ æ¥å¯¹æ¨æ–‡è¿›è¡ŒçŸ¢é‡åŒ–å¤„ç†ã€‚Neural stacking modelç”¨äºæ•´åˆä¸åŒå­ä»»åŠ¡çš„pipelineï¼Œå¹¶æ›´å¥½åœ°å…±äº«å‰åå‚æ•°ã€‚å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„neural joint modelæ¯”pipelineæ›´æœ‰æ•ˆã€‚</p><h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h3><p>æœ‰æ–‡çŒ®è¯æ˜äº†æ¨ç‰¹ã€å¾®åšè¿™ç±»ä½“è£æ¯”èµ·ä¼ ç»Ÿçš„åª’ä½“ï¼Œå¯¹æ–°é—»äº‹ä»¶æœ‰æ›´å¿«çš„ååº”é€Ÿåº¦ï¼Œå› æ­¤ä»Šå¹´å¯¹äºæ¨ç‰¹çš„äº‹ä»¶ç›‘æµ‹ä¹Ÿæ˜¯ä»Šå¹´çš„çƒ­ç‚¹ä¹‹ä¸€ï¼Œå¼•èµ·äº†å¹¿æ³›å…³æ³¨ã€‚æˆ‘ä»¬åœ¨æœ¬æ–‡ä¸»è¦æ£€æµ‹ä¸€äº›å…¸å‹çš„äº‹ä»¶ç±»åˆ«ï¼Œæ¯”å¦‚åœ°éœ‡ã€DDosæ”»å‡»ç­‰ã€‚æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œè¯¥æ¨¡å‹ç›‘è§†ç‰¹å®šäº‹ä»¶ç±»åˆ«çš„æ¨ç‰¹æµï¼Œå…±åŒæ£€æµ‹å¹¶æ‘˜è¦è¯¥ç±»åˆ«ä¸‹çš„æ–°é—»äº‹ä»¶ã€‚</p><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-04-04-WX20180404-225501%402x.png" width="60%"></p><p>æ•´ä½“çš„æ¶æ„å¦‚ä¸Šå›¾æ‰€ç¤ºï¼Œç»™å®šä¸€ä¸ªæ¨ç‰¹æµï¼Œæˆ‘ä»¬çš„æ¨¡å‹è€ƒè™‘ä¸‰ä¸ªå­ä»»åŠ¡ï¼šæ¨æ–‡è¿‡æ»¤ï¼Œäº‹ä»¶èšç±»å’Œäº‹ä»¶æ‘˜è¦ã€‚</p><p>å…¸å‹çš„æ¨ç‰¹äº‹ä»¶æ£€æµ‹æ¨¡å‹çš„æ ¸å¿ƒéƒ¨åˆ†æ˜¯<strong>èšç±»</strong>ï¼Œå…¶ä¸­åŒ…æ‹¬å¢é‡èšç±»å’Œlocality sensitive hashingã€‚ä¸»è¦çš„æƒ³æ³•æ˜¯å°†åŒä¸€ä¸»é¢˜çš„æ¨æ–‡è¿›è¡Œåˆ†ç»„ï¼Œä»¥ä¾¿åœ¨æ–°æ¨æ–‡ä¸å±äºç°æœ‰ä¸»é¢˜ç±»çš„æƒ…å†µä¸‹æ£€æµ‹åˆ°æ–°ä¸»é¢˜ã€‚è¿™æ ·çš„èšç±»ç®—æ³•é€šå¸¸ä¾èµ–äºæ¨ç‰¹å†…å®¹çš„ç‰¹å¾ï¼Œå¦‚TFIDFï¼Œç”¨äºæµ‹é‡æ¨æ–‡ä¹‹é—´çš„ç›¸ä¼¼åº¦ã€‚</p><p>ç¬¬äºŒä¸ªå­ä»»åŠ¡æ˜¯<strong>æ‘˜è¦</strong>ï¼Œå®ƒå¹¶ä¸ç›´æ¥æ¶‰åŠevent detectionï¼Œä½†ä»ç„¶ä¸ä¹‹é«˜åº¦ç›¸å…³ï¼Œå› ä¸ºæ£€æµ‹åˆ°çš„äº‹ä»¶ç¾¤å¯èƒ½æ¯”è¾ƒå¤§å¹¶ä¸”åŒ…å«ä¸åŒç¨‹åº¦ä¿¡æ¯çš„æ¨æ–‡ã€‚ ä»ç³»ç»ŸåŠŸèƒ½çš„è§’åº¦æ¥è¯´ï¼Œå¯¹äºæ¨ç‰¹äº‹ä»¶æ£€æµ‹ç³»ç»Ÿï¼Œæ‘˜è¦æ˜¯ååˆ†å¿…è¦çš„ï¼Œå› ä¸ºæˆ‘ä»¬æ²¡åŠæ³•ç›´æ¥è¯»å–äº‹ä»¶ç¾¤ï¼Œåªæœ‰å°†å…¶æŠ½å–æ‘˜è¦ï¼Œå¹¶å°†äº‹ä»¶æ‘˜è¦ä½œä¸ºè¾“å‡ºï¼Œæ‰èƒ½å¤Ÿä¸ºæˆ‘ä»¬æ‰€ç”¨ã€‚</p><p>æ­¤å¤–ï¼Œç”±äºå¤§éƒ¨åˆ†æ¨æ–‡æµåŒ…å«æ™®é€šæˆ–ä¸ç›¸å…³çš„ä¿¡æ¯ï¼Œæ¨æ–‡<strong>è¿‡æ»¤</strong>æ˜¯æˆ‘ä»¬è€ƒè™‘çš„ç¬¬ä¸‰ä¸ªå­ä»»åŠ¡ã€‚ æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æ ¹æ®å…¶ä¸æ½œåœ¨æ–°äº‹ä»¶çš„ç›¸å…³æ€§å¯¹ä¼ å…¥æ¨æ–‡è¿›è¡Œåˆ†ç±»ï¼Œä»¥ä¾¿åªä¿ç•™ä¿¡æ¯æ€§æ¨æ–‡ã€‚ è¿‡æ»¤å¯ä»¥åœ¨èšç±»ä¹‹å‰æˆ–ä¹‹åè¿›è¡Œã€‚ åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬åœ¨èšç±»ä¹‹å‰æ‰§è¡Œè¿™é¡¹ä»»åŠ¡ã€‚</p><p>è¿™ä¸‰ä¸ªå­ä»»åŠ¡å½¢æˆäº†ä¸€ä¸ªä¸‰é˜¶æ®µpipelineï¼ˆè¿‡æ»¤â†’èšç±»â†’æ‘˜è¦ï¼‰ï¼Œå…¶ä¸­å„ä¸ªé˜¶æ®µæ˜¯å¯†åˆ‡ç›¸å…³çš„ã€‚ ä¾‹å¦‚ï¼Œå®Œæ•´æè¿°äº‹ä»¶çš„æ¨æ–‡åº”è¯¥åœ¨ç›¸å…³æ€§è¿‡æ»¤å’ŒæŠ½è±¡æ‘˜è¦æ­¥éª¤ä¸­å¾—åˆ°é«˜åˆ†ã€‚ å¦å¤–ï¼Œæ›´å¥½åœ°ç†è§£æ¨æ–‡å¯¹äºç›¸å…³æ€§è¿‡æ»¤å’Œäº‹ä»¶èšç±»éƒ½æœ‰å¸®åŠ©ã€‚ å—æ­¤å¯å‘ï¼Œæˆ‘ä»¬è€ƒè™‘ä½¿ç”¨ä¸€ä¸ªjoint modelè¿›è¡Œç­›é€‰ã€èšç±»å’Œæ‘˜è¦ã€‚</p><p>ç¥ç»ç½‘ç»œåœ¨è¿‘å¹´ä¹Ÿåœ¨ç±»ä¼¼ä»»åŠ¡ä¸Šå±•ç¤ºäº†è‰¯å¥½çš„è¡¨ç°ã€‚æˆ‘ä»¬ä½¿ç”¨ä¸¤ç§è”åˆå»ºæ¨¡ç­–ç•¥ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬ä»¥æ¨æ–‡çš„è¯­ä¹‰è¡¨ç¤ºä½œä¸ºå…³é”®è¿æ¥å› ç´ ï¼Œé€šè¿‡å‚æ•°å…±äº«æ•´åˆä¸‰é¡¹ä»»åŠ¡ã€‚å…¶æ¬¡ï¼Œæˆ‘ä»¬å°†neural stackingåº”ç”¨äºpipelineï¼Œå°†å‰ä¸€ä¸ªå­æ¨¡å‹çš„éšè—ç¥ç»å±‚ä½œä¸ºå…¶åç»§å­æ¨¡å‹çš„é™„åŠ è¾“å…¥ç‰¹å¾ï¼Œå¹¶å°†åç»§çš„è¯¯å·®ä¼ æ’­ç»™å‰è€…ï¼Œä½¿å¾—åœ¨åŸ¹è®­æœŸé—´ï¼Œè®©å‰åå­æ¨¡å‹ä¹‹é—´çš„ä¿¡æ¯å¾—åˆ°æ›´å¥½çš„å…±äº«ã€‚</p><h3 id="2-Model"><a href="#2-Model" class="headerlink" title="2. Model"></a>2. Model</h3><p>æˆ‘ä»¬ç³»ç»Ÿçš„è¾“å…¥æ˜¯ä¸€ä¸ªæ¨ç‰¹æµï¼Œå®æ—¶è¾“å‡ºäº‹ä»¶æŠ¥å‘Šã€‚ä¸‰ä¸ªä¸»è¦çš„å­ä»»åŠ¡å®šä¹‰å¦‚ä¸‹ï¼š</p><ul><li><strong>äº‹ä»¶ç­›é€‰</strong>ï¼šæˆ‘ä»¬å°†æµä¸­çš„æ¯æ¡æ¨æ–‡åˆ†ç±»ä¸ºä¸ç›¸å…³äº‹ä»¶ç›¸å…³æˆ–ä¸ç›¸å…³çš„äº‹ä»¶ã€‚ç”±äºæˆ‘ä»¬çš„ç›®æ ‡æ˜¯ä»…æ£€æµ‹æŸäº›ç±»å‹çš„äº‹ä»¶ï¼ˆå³åœ°éœ‡å’ŒDDOSæ”»å‡»äº‹ä»¶ï¼‰ï¼Œå› æ­¤æˆ‘ä»¬ä½¿ç”¨ç›¸åº”çš„ä¸€ç»„å…³é”®å­—æ¥è¿‡æ»¤æ¨æ–‡æµä½œä¸ºé¢„å¤„ç†æ­¥éª¤ã€‚ç›¸å…³åˆ†ç±»åœ¨é¢„å¤„ç†æ­¥éª¤ä¹‹åæ‰§è¡Œï¼Œå› ä¸ºå¹¶éæ‰€æœ‰åŒ…å«å…³é”®å­—çš„æ¨æ–‡éƒ½æ˜¯ç›¸å…³çš„ã€‚</li><li><strong>äº‹ä»¶èšç±»</strong>ï¼šæˆ‘ä»¬åœ¨äº‹ä»¶æ£€æµ‹åå¯¹æ¨æ–‡è¿›è¡Œå¢é‡èšç±»ã€‚ç»™å®šä¸€ä¸ªæåˆ°äº‹ä»¶çš„æ¨æ–‡ï¼Œå…¶ä»»åŠ¡æ˜¯ç¡®å®šå®ƒæ˜¯å¦å­˜åœ¨äºç°æœ‰çš„äº‹ä»¶é›†ç¾¤ä¸­ã€æ˜¯å¦æ˜¯ä¸€ä¸ªæ–°çš„äº‹ä»¶ã€‚è¿™ä¸ªä»»åŠ¡çš„å…³é”®æ˜¯æ¨æ–‡ä¹‹é—´çš„ç›¸ä¼¼åº¦è®¡ç®—ã€‚</li><li><strong>äº‹ä»¶æ‘˜è¦</strong>ï¼šå½“ä¸€ä¸ªäº‹ä»¶é›†ç¾¤è¶³å¤Ÿå¤§æ—¶ï¼Œæˆ‘ä»¬é€šè¿‡æå–å‰nä¸ªåŒ…å«æœ€å¤šä¿¡æ¯çš„æ¨æ–‡æ¥åˆ›å»ºç›¸åº”äº‹ä»¶çš„æŠ¥å‘Šã€‚è¿™ä¸ªå­ä»»åŠ¡å¯ä»¥è¢«çœ‹ä½œæ˜¯ä¸€ä¸ªå¤šæ–‡æ¡£æ‘˜è¦ä»»åŠ¡ã€‚</li></ul><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-04-04-WX20180404-232216%402x.png" width="60%"></p><p>æ¨¡å‹çš„æ•´ä½“æ„æ¶å¦‚ä¸Šå›¾ï¼ŒHæ˜¯æ¨æ–‡çš„embeddingï¼ŒHdæ˜¯äº‹ä»¶ç­›é€‰æ­¥éª¤çš„éšè—å±‚ï¼ŒHcæ˜¯èšç±»çš„éšè—å±‚ï¼ŒPsæ˜¯æ‘˜è¦çš„è¾“å‡ºã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œæ¯ä¸€ä¸ªå­ä»»åŠ¡éƒ½å……åˆ†åˆ©ç”¨äº†å‰é¢çš„ä¿¡æ¯ï¼Œä½¿å¾—å„ä¸ªå­æ¨¡å‹é¡¹ç›®è¡¥å……è¾…åŠ©ï¼Œè®©ç»“æœæ›´ç†æƒ³ã€‚</p><p>ç»“æœè¡¨æ˜ï¼Œä¸ç‹¬ç«‹çš„pipelineç›¸æ¯”ï¼Œè¿™ç§neural stackingæ–¹æ³•å¯ä»¥äº§ç”Ÿæ›´å¥½çš„å­æ¨¡å‹ã€‚è¯·æ³¨æ„ï¼Œè™½ç„¶è®¡ç®—ä¸¤ä¸ªtweetsä¹‹é—´çš„ç›¸ä¼¼æ€§çš„è¿‡ç¨‹æ˜¯ç”¨LSTMæ¨¡å‹ç›‘ç£çš„ï¼Œä½†èšç±»ç®—æ³•æ˜¯ä¸€ç§æ— ç›‘ç£çš„åœ¨çº¿èšç±»ç®—æ³•ã€‚</p><h4 id="2-1-Shared-Tweet-Representation"><a href="#2-1-Shared-Tweet-Representation" class="headerlink" title="2.1 Shared Tweet Representation"></a>2.1 Shared Tweet Representation</h4><p>æˆ‘ä»¬ä½¿ç”¨æ ‡å‡†çš„LSTMæ¨¡å‹æ¥å­¦ä¹ ä¸åŒä»»åŠ¡ä¹‹é—´çš„æ¨æ–‡è¡¨ç¤ºã€‚ å‡è®¾$X =(w_1,w_2,â€¦,w_n)$æ˜¯æ¨æ–‡ï¼Œå…¶ä¸­$n$æ˜¯æ¨æ–‡é•¿åº¦ï¼Œ$w_i$æ˜¯ç¬¬iä¸ªæ ‡è®°ã€‚ æˆ‘ä»¬ä½¿ç”¨$w_i$çš„word embeddingå°†æ¯ä¸ª$w_i$è½¬æ¢ä¸ºå®å€¼å‘é‡$x_i$ï¼Œé€šè¿‡æŸ¥æ‰¾é¢„å…ˆè®­ç»ƒçš„word embeddingè¡¨Dè·å¾—ã€‚æˆ‘ä»¬ä½¿ç”¨skip-gramç®—æ³•æ¥è®­ç»ƒembeddingã€‚<br>LSTMç”¨ä»¥ç”Ÿæˆéšè—åºåˆ—$(h_1,h_2,â€¦,h_n)$ã€‚ åœ¨æ¯ä¸ªæ­¥éª¤tï¼ŒåŸºäºå½“å‰å‘é‡$x_t$å’Œå‰ä¸€ä¸ªå‘é‡$h_{t-1}$å’Œ$h_t = LSTM(x_tï¼Œh_{t-1})$è®¡ç®—LSTMæ¨¡å‹çš„éšè—å‘é‡$h_t$ã€‚ åˆå§‹çŠ¶æ€å’Œæ‰€æœ‰LSTMå‚æ•°éšæœºåˆå§‹åŒ–å¹¶åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è°ƒæ•´ã€‚ æˆ‘ä»¬ä½¿ç”¨$H = h_n$ä½œä¸ºXçš„å…±äº«è¡¨ç¤ºã€‚</p><h4 id="2-2-Joint-Model"><a href="#2-2-Joint-Model" class="headerlink" title="2.2 Joint Model"></a>2.2 Joint Model</h4><h5 id="Event-mention-detection"><a href="#Event-mention-detection" class="headerlink" title="Event mention detection"></a>Event mention detection</h5><p>äº‹ä»¶æåŠæ£€æµ‹æ˜¯ä¸€ä¸ªäºŒå…ƒåˆ†ç±»ä»»åŠ¡ï¼Œä½¿ç”¨å¤šå±‚æ„ŸçŸ¥å™¨è¿›è¡Œæè¿°ã€‚ç»™å‡ºè¾“å…¥å‘é‡Hï¼Œéšå«å±‚ç”¨äºæ¿€å‘ä¸€ç»„é«˜çº§ç‰¹å¾ï¼š<br>$$<br>H_d = \sigma(W_d^h H + b_d^h)<br>$$<br>$H_d$è¢«ç”¨äºsoftmaxè¾“å‡ºå±‚çš„è¾“å…¥ï¼š<br>$$<br>P_d = softmax(W_dH_d + B_d)<br>$$<br>è¿™é‡Œ$W_d^h, b_d^b, W_d$éƒ½æ˜¯æ¨¡å‹å‚æ•°ã€‚$P_d$ é•¿åº¦ä¸º2ï¼Œ$P_d(0)$è¡¨ç¤ºæ¨æ–‡Xç›¸å…³çš„æ¦‚ç‡ï¼Œ$P_d(1)$è¡¨ç¤ºä¸ç›¸å…³çš„æ¦‚ç‡ã€‚</p><h5 id="Event-clustering"><a href="#Event-clustering" class="headerlink" title="Event clustering"></a>Event clustering</h5><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-04-04-WX20180404-234532%402x.png" width="60%"></p><p>æˆ‘ä»¬ä½¿ç”¨åŸºäºæµçš„èšç±»ç®—æ³•å°†ä¼ å…¥çš„æ¨æ–‡åˆ†ä¸ºä¸åŒçš„äº‹ä»¶ç»„ï¼Œæ¯ä¸ªäº‹ä»¶ç»„è¡¨ç¤ºä¸€ä¸ªç‰¹å®šçš„äº‹ä»¶ã€‚è¯¥ç®—æ³•éšç€æµä¸­çš„æ¯ä¸ªä¼ å…¥æ¨æ–‡å¢é•¿å¼åœ°å·¥ä½œï¼Œè®¡ç®—æ–°æ¨æ–‡ä¸ç°æœ‰äº‹ä»¶ç¾¤ä¸­çš„æ¯æ¡æ¨æ–‡ä¹‹é—´çš„ç›¸ä¼¼åº¦åˆ†æ•°ã€‚æ–°ä¼ å…¥çš„æ¨æ–‡ä¸æ¯ä¸ªäº‹ä»¶ç¾¤ä¸­æœ€ç›¸ä¼¼çš„å¯¹åº”æ–‡ä»¶ä¹‹é—´çš„ç›¸ä¼¼åº¦ç”¨äºè¡¡é‡æ–°æ¨æ–‡ä¸äº‹ä»¶ç¾¤é›†ä¹‹é—´çš„ç›¸ä¼¼åº¦ã€‚ä½¿ç”¨é˜ˆå€¼$\mu - 3\cdot \sigma$æ¥æ£€æµ‹æ–°æ¨æ–‡æ˜¯å¦å±äºç°æœ‰èšç±»ï¼Œå…¶ä¸­Î¼æ˜¯æ‰€æœ‰å…ˆå‰ç›¸ä¼¼åº¦åˆ†æ•°çš„å‡å€¼ï¼ŒÏƒæ˜¯æ ‡å‡†åå·®ã€‚å¦‚æœæ¨ç‰¹å’Œæ‰€æœ‰ç°æœ‰ç¾¤é›†ä¹‹é—´çš„ç›¸ä¼¼åº¦ä½äºé˜ˆå€¼ï¼Œåˆ™å»ºç«‹æ–°çš„äº‹ä»¶ç¾¤é›†ã€‚å¦åˆ™ï¼Œå°†æ¨æ–‡æ·»åŠ åˆ°æœ€ç›¸ä¼¼çš„ç°æœ‰äº‹ä»¶ç¾¤é›†ä¸­ã€‚<br>ä¸ºäº†è®¡ç®—ä¸¤æ¡æ¨æ–‡$X_i$å’Œ$X_j$ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ä¸€ä¸ªè¿ä½“ç½‘ç»œï¼Œå®ƒé‡‡ç”¨å…±äº«è¡¨ç¤ºå‘é‡$H_i$å’Œ$H_j$ï¼Œå¹¶é€šè¿‡å‚æ•°åŒ–è®¡ç®—ç›¸ä¼¼æ¦‚ç‡å¾—åˆ†$P_c$:<br>$$<br>H_c = \sigma(W_c^h(H_i \oplus H_j)+ b_c^h) \\<br>P_c = softmax(W_cH_c + B_c)<br>$$<br>âŠ•è¡¨ç¤ºå‘é‡çº§è”ã€‚ $W_c^hï¼Œb_b^c,W_c,b_c$æ˜¯æ¨¡å‹å‚æ•°ã€‚</p><p>ä¸ºäº†æ›´å¥½åœ°æ•´åˆäº‹ä»¶æåŠæ£€æµ‹å’Œäº‹ä»¶èšç±»ï¼Œæˆ‘ä»¬è¿˜å°†$X_i$å’Œ$X_j$çš„éšè—ç‰¹å¾çŸ¢é‡$H_d$é¦ˆé€åˆ°Siameseç½‘ç»œï¼Œä»è€Œ<br>$$<br>H_c = \sigma(W_c^h(H_i \oplus H_j \oplus H_{d_i} \oplus H_{d_j})+ b_c^h)<br>$$</p><h5 id="Event-summarization"><a href="#Event-summarization" class="headerlink" title="Event summarization"></a>Event summarization</h5><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-04-04-WX20180405-000354%402x.png" width="60%"></p><p>ä¸ºäº†ç”Ÿæˆäº‹ä»¶é›†ç¾¤çš„æ‘˜è¦ï¼Œæˆ‘ä»¬ä½¿ç”¨æ¦‚ç‡åˆ†æ•°$P_s$å¯¹é›†ç¾¤ä¸­çš„æ‰€æœ‰æ¨æ–‡è¿›è¡Œæ’åºã€‚ å¯¹äºé›†ç¾¤ä¸­çš„æ¯ä¸ªæ¨ç‰¹Xï¼Œä½¿ç”¨å¤šå±‚æ„ŸçŸ¥å™¨æ¥ä¼°è®¡$P_s$ï¼Œå…¶ä¸­è¾“å…¥æ˜¯$H \oplus \bar{H_c^h}$ã€‚ è¿™é‡Œçš„çŸ¢é‡$\bar{H_c^h}$æ˜¯æ¨æ–‡Xä¸åŒä¸€é›†ç¾¤ä¸­æ‰€æœ‰å…¶ä»–æ¨ç‰¹ä¹‹é—´çš„$H_c^h$ä¹‹å’Œã€‚ å®ƒæœ‰ä¸¤ä¸ªç”¨é€”ã€‚é¦–å…ˆï¼Œ$H_c^h$æä¾›æœ‰å…³æ•´ä¸ªç¾¤é›†çš„ä¿¡æ¯ï¼Œè¿™å¯¹äºæ›´å¥½åœ°ç¡®å®šç¾¤é›†ä¸­ç»™å®šæ¨æ–‡çš„ç›¸å…³æ€§å¾ˆæœ‰ç”¨ã€‚ å…¶æ¬¡ï¼Œ$H_c^h$è¿˜æŠŠèšç±»å’Œæ‘˜è¦è”ç³»äº†èµ·æ¥ï¼Œä»è€Œå¼ºåŒ–äº†ä¿¡æ¯å…±äº«ã€‚<br>$$<br>P_s = softmax(W_sH_s + B_s)<br>$$<br>where<br>$$<br>H_s = \sigma(W_s^h(H\oplus \bar{H_c^h})+ b_s^h)<br>$$<br>$W_s^h, b_s^b, Ws$æ˜¯æ¨¡å‹çš„å‚æ•°</p><h4 id="2-3-Training"><a href="#2-3-Training" class="headerlink" title="2.3 Training"></a>2.3 Training</h4><p>æˆ‘ä»¬çš„åŸ¹è®­ç›®æ ‡æ˜¯å°½é‡å‡å°‘è¿™ä¸‰é¡¹ä»»åŠ¡ä¸­æ ‡æ³¨çš„æ ‡ç­¾å’Œé¢„æµ‹æ ‡ç­¾ä¹‹é—´çš„cross-entropy lossã€‚ æˆ‘ä»¬åº”ç”¨åœ¨çº¿åŸ¹è®­ï¼Œä½¿ç”¨Adagradè°ƒæ•´æ¨¡å‹å‚æ•°ã€‚ä¸ºäº†é¿å…è¿‡æ‹Ÿåˆï¼Œå¯¹word embeddingä½¿ç”¨0.2ç‚¹dropoutã€‚éšè—å±‚$H_d, H_c,H_s$çš„å¤§å°éƒ½è®¾ç½®ä¸º32ã€‚æˆ‘ä»¬ä½¿ç”¨Skip-gramç®—æ³•è®­ç»ƒword embeddingï¼Œå¹¶åœ¨è®­ç»ƒæœŸé—´å¯¹å®ƒä»¬è¿›è¡Œå¾®è°ƒã€‚ Word embeddingçš„å¤§å°æ˜¯128ã€‚</p><h3 id="3-Experiment"><a href="#3-Experiment" class="headerlink" title="3. Experiment"></a>3. Experiment</h3><p>è§paperåŸæ–‡</p><h3 id="4-Conclusion"><a href="#4-Conclusion" class="headerlink" title="4. Conclusion"></a>4. Conclusion</h3><p>æ–‡çŒ®<sup id="fnref:1"><a href="#fn:1" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="Wang, Z., & Zhang, Y. (2017, August). A neural model for joint event detection and summarization. In *Proceedings of the 26th International Joint Conference on Artificial Intelligence* (pp. 4158-4164). AAAI Press.">[1]</span></a></sup>æå‡ºäº†ä¸€ä¸ªjoint modelï¼Œé€šè¿‡ä½¿ç”¨å…¨å±€å…±äº«è¡¨ç¤ºå’Œä¸åŒå­ä»»åŠ¡ä¹‹é—´çš„å †å æ¥å…±åŒæ£€æµ‹ã€èšç±»å’Œæ‘˜è¦äº‹ä»¶ã€‚ å®éªŒè¡¨æ˜ï¼Œæˆ‘ä»¬æå‡ºçš„joint modelæ¯”pipelineæ¨¡å‹æ›´æœ‰æ•ˆã€‚è¯¥è”åˆç¥ç»ç³»ç»Ÿä¼˜äºé‡‡ç”¨ç¦»æ•£æˆ–ç¥ç»ç½‘ç»œè¿›è¡Œæ–°é—»äº‹ä»¶æ£€æµ‹å’Œæ‘˜è¦çš„æœ€æ–°baselineã€‚</p><h2 id="Bibliography"><a href="#Bibliography" class="headerlink" title="Bibliography"></a>Bibliography</h2><p>ä»£ç å¼€æºï¼š<a href="https://github.com/wangzq870305/joint_event_detection" target="_blank" rel="noopener">https://github.com/wangzq870305/joint_event_detection</a></p><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style: none; padding-left: 0; margin-left: 40px"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">1.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Wang, Z., &amp; Zhang, Y. (2017, August). A neural model for joint event detection and summarization. In <em>Proceedings of the 26th International Joint Conference on Artificial Intelligence</em> (pp. 4158-4164). AAAI Press.<a href="#fnref:1" rev="footnote"> â†©</a></span></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">2.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Wang, Z., Shou, L., Chen, K., Chen, G., &amp; Mehrotra, S. (2015). On summarization and timeline generation for evolutionary tweet streams. <em>IEEE Transactions on Knowledge and Data Engineering</em>, <em>27</em>(5), 1301-1315.<a href="#fnref:2" rev="footnote"> â†©</a></span></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h2 id=&quot;A-Neural-Model-for-Joint-Event-De
      
    
    </summary>
    
      <category term="research" scheme="https://juewang.me/categories/research/"/>
    
    
      <category term="event-detection" scheme="https://juewang.me/tags/event-detection/"/>
    
      <category term="summarization" scheme="https://juewang.me/tags/summarization/"/>
    
  </entry>
  
  <entry>
    <title>Event detection çš„å‡ ä¸ªç¥ç»ç½‘ç»œæ¨¡å‹</title>
    <link href="https://juewang.me/posts/%5B2018.3.20%5DEvent-detection/"/>
    <id>https://juewang.me/posts/[2018.3.20]Event-detection/</id>
    <published>2018-03-20T00:00:00.000Z</published>
    <updated>2018-04-03T15:05:37.447Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2 id="Event-detection-çš„å‡ ä¸ªç¥ç»ç½‘ç»œæ¨¡å‹"><a href="#Event-detection-çš„å‡ ä¸ªç¥ç»ç½‘ç»œæ¨¡å‹" class="headerlink" title="Event detection çš„å‡ ä¸ªç¥ç»ç½‘ç»œæ¨¡å‹"></a>Event detection çš„å‡ ä¸ªç¥ç»ç½‘ç»œæ¨¡å‹</h2><p><strong>æ‘˜è¦ï¼š</strong> æ ¹æ®aceçš„å®šä¹‰ï¼Œäº‹ä»¶è¢«åˆ†ä¸º trigger word å’Œ attributesï¼Œå› æ­¤ event detection ä¹Ÿå¯ä»¥è¢«è®¤ä¸ºæ˜¯ trigger word detectionã€‚ç›®å‰åŸºäºç¥ç»ç½‘ç»œçš„æ–¹æ³•çš„æ€è·¯åŸºæœ¬å¤§åŒå°å¼‚ï¼Œæœ¬æ–‡æŒ‘é€‰å¹¶é˜è¿°3ç¯‡paperçš„ä¸»è¦å†…å®¹ï¼Œå¹¶æ¯”è¾ƒå…¶ç‰¹ç‚¹ã€‚</p><h3 id="1-Dual-CNN"><a href="#1-Dual-CNN" class="headerlink" title="1. Dual CNN"></a>1. Dual CNN</h3><p>è¿™ç¯‡<sup id="fnref:1"><a href="#fn:1" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="Burel, G., Saif, H., Fernandez, M., & Alani, H. (2017). On semantics and deep learning for event detection in crisis situations.">[1]</span></a></sup>ä¸»è¦æ˜¯å¯¹é€šå¸¸çš„CNNçš„æ”¹è¿›ï¼Œå¢åŠ äº†ä¸€å±‚è¯­ä¹‰å±‚ç”¨ä»¥æ„ŸçŸ¥ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚</p><p>æ•´ä¸ªpiplineå¯ä»¥æ€»ç»“ä¸ºå¦‚ä¸‹å›¾ï¼š</p><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-03-20-WX20180320-221054%402x.png" alt="WX20180320-221054@2x"></p><ol><li>Text Processing: æ•°æ®æ¸…æ´—ã€åˆ†è¯ç­‰ï¼Œä¾¿äºåç»­å¤„ç†ï¼›</li><li>Word Vector Initialisation: åˆå§‹åŒ–è¯å‘é‡ï¼ŒåŒ…æ‹¬åŠ è½½ pre-trained word embedding ç­‰ï¼›</li><li>Concept Extraction: ä¸2.å¹¶è¡Œè¿è¡Œï¼Œè¿™é‡Œåˆ©ç”¨å¤–éƒ¨å·¥å…·å®ç°å®ä½“çš„è¯­æ„æ¦‚å¿µï¼›</li><li>Concept Vector Initialisation: å°†å®ä½“å’Œå®ä½“ç›¸å…³çš„æ¦‚å¿µå‘é‡åŒ–ï¼›</li><li>Dual-CNN Training: è¿™ä¸€æ­¥åˆ©ç”¨æˆ‘ä»¬æå‡ºçš„ Dual-CNN è®­ç»ƒï¼›</li></ol><h4 id="Dual-CNN"><a href="#Dual-CNN" class="headerlink" title="Dual-CNN"></a>Dual-CNN</h4><p>æˆ‘ä»¬çŸ¥é“CNNå¯ä»¥ç”¨æ¥ä½œä¸ºåˆ†ç±»å™¨ï¼Œå› æ­¤ä¹Ÿå¯ä»¥è¢«æ„é€ ä¸ºä¸€ä¸ªäº‹ä»¶æ£€æµ‹æ¨¡å‹ï¼Œå¹¶èƒ½å¤Ÿåˆ†å‡ºç±»åˆ«ã€‚åœ¨è¿™ä¸ªæ¨¡å‹ä¸­ï¼Œæˆ‘ä»¬å¢åŠ ä¸€å±‚è¯­æ„å±‚ã€‚ä¸€èˆ¬ä»æ­£å¸¸é€»è¾‘å‡ºå‘ï¼Œæˆ‘ä»¬å¯ä»¥å¢åŠ ä¸€ä¸ªchannelæ¥å­˜æ”¾entity related embeddingï¼Œå°±åƒæˆ‘ä»¬å›¾åƒçš„å¤šä¸ªchannelä¸€æ ·ï¼›ä½†æ˜¯è¿™è¦æ±‚å®ä½“å’ŒåŸæ¥çš„å¥å­å®Œå…¨å¯¹é½ï¼Œå› æ­¤ä½œè€…ç”¨ä¸¤ä¸ªCNNå¹¶è¡Œè®­ç»ƒã€‚</p><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-03-20-WX20180320-224531%402x.png" alt="WX20180320-224531@2x"></p><p>äº‹å®ä¸Šï¼Œè¿™ç¯‡æ–‡ç« æå‡ºçš„embeddingæ–¹æ³•å¹¶ä¸èƒ½è·ŸåŸæ¥çš„å¥å­å¯¹é½ã€‚æˆ‘ä»¬æœ‰ä¸€ä¸ªå¥å­ $D = $ â€˜Obama attends vigil for Boston Marathon bombing victims.â€™ï¼›åˆ†è¯ä¸º $T_w = $ [â€˜obamaâ€™, â€˜attendsâ€™, â€˜vigilâ€™, â€˜forâ€™, â€˜bostonâ€™, â€˜marathonâ€™, â€˜bombingâ€™, â€˜victimsâ€™]ï¼›è€Œè¯­æ„åˆ†è¯å°†åˆ†ä¸º$T_s = $ [â€˜obamaâ€™, â€˜politicianâ€™, â€˜noneâ€™, â€˜noneâ€™, â€˜noneâ€™, â€˜bostonâ€™, â€˜locationâ€™, â€˜noneâ€™, â€˜noneâ€™, â€˜noneâ€™]ã€‚æˆ‘ä»¬å¯ä»¥çœ‹åˆ°è¯­æ„åˆ†è¯é‡‡ç”¨äº† entity-type çš„æ–¹æ³•ï¼Œè¿™å¯¼è‡´äº†$T_w$å’Œ$T_s$é•¿åº¦å¹¶ä¸ç›¸åŒ ï¼Œå› æ­¤æ— æ³•æŠŠä»–ä»¬å¹¶ä¸ºä¸¤ä¸ªchannelsã€‚ï¼ˆå…¶å®è¿™é‡Œæˆ‘æ„Ÿè§‰å¯ä»¥æŠŠentityå’Œtypeåˆ†åˆ«embeddingä¹‹åçº§è”èµ·æ¥ï¼Œè¿™æ ·å°±èƒ½å¤Ÿå¯¹é½äº†ï¼Œä¸çŸ¥é“è¿™æ ·å¯ä¸å¯è¡Œï¼Ÿï¼‰</p><p>æœ€åçš„ç»“æœæ˜¾ç¤ºï¼Œå®ƒèƒ½å¤Ÿè¾ƒå¥½åœ°æ£€æµ‹å’Œè¯†åˆ«äº‹ä»¶ç±»åˆ«ï¼Œå¯¹æ¯”CNNæœ‰ä¸€äº›æå‡ï¼›ä½†æ˜¯å¯¹äºé¢—ç²’åº¦è¾ƒç»†çš„äº‹ä»¶åè€Œæœ‰æ‰€ä¸‹é™ã€‚ä½†æ˜¯è¿™äº›ç»“æœéƒ½å¥½äºä¼ ç»Ÿçš„æœºå™¨å­¦ä¹ æ–¹æ³•ã€‚</p><h3 id="2-convolution-BiLSTM"><a href="#2-convolution-BiLSTM" class="headerlink" title="2. convolution BiLSTM"></a>2. convolution BiLSTM</h3><p>æ–‡çŒ®<sup id="fnref:2"><a href="#fn:2" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="Zeng, Y., Yang, H., Feng, Y., Wang, Z., & Zhao, D. (2016). A convolution BiLSTM neural network model for Chinese event extraction. In *Natural Language Understanding and Intelligent Applications* (pp. 275-287). Springer, Cham.">[2]</span></a></sup>å…¶å®ä¹‹å‰å°±çœ‹è¿‡ï¼Œè¯¦ç»†å†™åœ¨2018.1.29çš„ç¬”è®°é‡Œï¼Œè¿™é‡Œå†ç®€å•æä¸€ä¸‹ï¼Œæ¨¡å‹å¦‚ä¸‹ã€‚</p><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-03-20-WX20180320-224725%402x.png" alt="WX20180320-224725@2x"></p><p>ç®€å•æ¥è¯´ï¼Œå°±æ˜¯åœ¨é€šå¸¸çš„biLSTMæ¨¡å‹ä¸‹ï¼Œå¹¶è¡Œåœ°è®­ç»ƒä¸€ä¸ªCNNæ¨¡å‹ï¼Œå…¶è¾“å‡ºå’ŒbiLSTMçš„è¾“å‡ºçš„å‘é‡è¿›è¡Œè¿æ¥ï¼ŒOutput layeræ¥Softmaxè¾“å‡ºæ ‡ç­¾çš„æ¦‚ç‡åˆ†å¸ƒã€‚åˆ›æ–°ç‚¹åœ¨äºå¼•å…¥äº†CNNæ•è·å±€éƒ¨è¯­æ„ä¿¡æ¯ï¼Œä¹Ÿè·å¾—ä¸é”™çš„æ•ˆæœã€‚æœ¬æ¨¡å‹ä¹Ÿé€‚ç”¨äºå…¶ä»–sequence labelingä»»åŠ¡ã€‚</p><h3 id="3-BiLSTM-CNN"><a href="#3-BiLSTM-CNN" class="headerlink" title="3. BiLSTM + CNN"></a>3. BiLSTM + CNN</h3><p>è¿™ç¯‡æ–‡ç« <sup id="fnref:3"><a href="#fn:3" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="Feng, X., Huang, L., Tang, D., Ji, H., Qin, B., & Liu, T. (2016). A language-independent neural network for event detection. In *Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)* (Vol. 2, pp. 66-71).">[3]</span></a></sup>å’Œæ–‡ç« <sup id="fnref:2"><a href="#fn:2" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="Zeng, Y., Yang, H., Feng, Y., Wang, Z., & Zhao, D. (2016). A convolution BiLSTM neural network model for Chinese event extraction. In *Natural Language Understanding and Intelligent Applications* (pp. 275-287). Springer, Cham.">[2]</span></a></sup>çš„æ€è·¯ä¹Ÿå¾ˆç›¸ä¼¼ï¼Œä¸»è¦çš„æƒ³æ³•æ˜¯BiLSTMå¯¹æ–‡æœ¬çš„è¯­æ„è¿›è¡Œç¼–ç ï¼Œåé¢ä¸²è”CNNæ¥æ•è·å±€éƒ¨ç»“æ„ä¿¡æ¯ã€‚</p><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-03-20-WX20180320-225956%402x.png" alt="WX20180320-225956@2x"></p><h3 id="4-Conclusion"><a href="#4-Conclusion" class="headerlink" title="4. Conclusion"></a>4. Conclusion</h3><p>å¦‚æœè®¤ä¸ºæ˜¯ä¸€ä¸ªæ–‡æœ¬åˆ†ç±»ä»»åŠ¡ï¼ŒCNNèƒ½å¤Ÿå¾ˆå¥½çš„å®Œæˆä»»åŠ¡ï¼Œè€Œä¸”ç”±äºå®ƒæœ¬èº«çš„ç‰¹æ€§è®­ç»ƒé€Ÿåº¦æ¯”è¾ƒå¿«ï¼›å¦ä¸€æ–¹é¢å¯ä»¥ç”¨RNNæ¥åšæ•°æ®æ ‡æ³¨ä»»åŠ¡ï¼Œä»…æ ‡æ³¨è§¦å‘è¯ï¼›æ­¤å¤–å¯ä»¥åˆ©ç”¨å¥½biLSTMèƒ½å¤Ÿå¤„ç†é•¿è·ç¦»å‰åæ–‡ä¿¡æ¯ã€CNNç€é‡å±€éƒ¨ä¿¡æ¯çš„å…³ç³»ç­‰ç‰¹æ€§ï¼Œæ„é€ ä¸åŒçš„å˜ä½“ï¼Œå¯¹äºå®é™…ä»»åŠ¡å¯èƒ½ä¹Ÿæœ‰ä¸é”™çš„æ•ˆæœã€‚</p><p>ä»ç»“æœä¸Šæ¥çœ‹å®é™…ä¸Šå„ç§å˜ä½“æ•ˆæœå·®è·å¹¶ä¸å¤§ï¼Œå¯¹ç‰¹å®šç§ç±»ç‰¹å®šä½“è£å¯èƒ½ä¼šæœ‰è¾ƒå¤§çš„å·®åˆ«ï¼›å¯èƒ½æ›´é‡è¦çš„å¯èƒ½æ˜¯å¦‚ä½•æ„é€ ç‰¹å¾ï¼ˆé™¤äº†word embedding ä¹‹å¤–ï¼Œè¿˜å¯ä»¥è€ƒè™‘entity embeddingï¼Ÿentity typeï¼Ÿè¿˜æœ‰è¯æ€§çš„embeddingï¼Ÿï¼‰</p><h2 id="Bibliographies"><a href="#Bibliographies" class="headerlink" title="Bibliographies"></a>Bibliographies</h2><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style: none; padding-left: 0; margin-left: 40px"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">1.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Burel, G., Saif, H., Fernandez, M., &amp; Alani, H. (2017). On semantics and deep learning for event detection in crisis situations.<a href="#fnref:1" rev="footnote"> â†©</a></span></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">2.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Zeng, Y., Yang, H., Feng, Y., Wang, Z., &amp; Zhao, D. (2016). A convolution BiLSTM neural network model for Chinese event extraction. In <em>Natural Language Understanding and Intelligent Applications</em> (pp. 275-287). Springer, Cham.<a href="#fnref:2" rev="footnote"> â†©</a></span></li><li id="fn:3"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">3.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Feng, X., Huang, L., Tang, D., Ji, H., Qin, B., &amp; Liu, T. (2016). A language-independent neural network for event detection. In <em>Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</em> (Vol. 2, pp. 66-71).<a href="#fnref:3" rev="footnote"> â†©</a></span></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h2 id=&quot;Event-detection-çš„å‡ ä¸ªç¥ç»ç½‘ç»œæ¨¡å‹&quot;&gt;&lt;a hre
      
    
    </summary>
    
      <category term="research" scheme="https://juewang.me/categories/research/"/>
    
    
      <category term="event-detection" scheme="https://juewang.me/tags/event-detection/"/>
    
      <category term="neural-network" scheme="https://juewang.me/tags/neural-network/"/>
    
  </entry>
  
  <entry>
    <title>Several models for knowledge graph representing and completing å‡ ä¸ªçŸ¥è¯†å›¾è°±æ¨¡å‹</title>
    <link href="https://juewang.me/posts/%5B2018.3.10%5DSeveral-models-for-kenowledge-graoh-representing-and-completing/"/>
    <id>https://juewang.me/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/</id>
    <published>2018-03-10T00:00:00.000Z</published>
    <updated>2018-03-16T18:44:54.839Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="2018-3-10"><a href="#2018-3-10" class="headerlink" title="2018.3.10"></a>2018.3.10</h1><h2 id="Several-models-for-knowledge-graph-representing-and-completing"><a href="#Several-models-for-knowledge-graph-representing-and-completing" class="headerlink" title="Several models for knowledge graph representing and completing"></a>Several models for knowledge graph representing and completing</h2><p><strong>æ‘˜è¦</strong>ï¼šä¸Šæ¬¡çœ‹åˆ°çš„ConMaskåœ¨å¼€æ”¾é¢†åŸŸknowledge graph completionæœ‰ç€ä¸é”™çš„è¡¨ç°ï¼Œè¿™æ¬¡æˆ‘ä»¬ä¸è€ƒè™‘å¼€æ”¾é¢†åŸŸï¼Œä»‹ç»å‡ ä¸ªç»å…¸çš„æ¨¡å‹ã€‚</p><h3 id="1-Series-of-Trans"><a href="#1-Series-of-Trans" class="headerlink" title="1. Series of Trans"></a>1. Series of Trans</h3><h4 id="1-1-TransE"><a href="#1-1-TransE" class="headerlink" title="1.1 TransE"></a>1.1 TransE</h4><p>TransE <sup id="fnref:1"><a href="#fn:1" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="Bordes, A., Usunier, N., Garcia-Duran, A., Weston, J., & Yakhnenko, O. (2013). Translating embeddings for modeling multi-relational data. In *Advances in neural information processing systems* (pp. 2787-2795).">[1]</span></a></sup> å¯èƒ½æ˜¯æœ€ä¸ºå¸¸ç”¨ä¹Ÿæœ€ä¸ºåŸºç¡€çš„æ–¹æ³•æ˜¯ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ (RL)çš„æ¨¡å‹. å®ƒæœ‰ä¸€ä¸ªç®€å•å®ç”¨çš„å‡è®¾ï¼š<br>$$<br>h+r = t<br>$$<br>å…¶ä¸­hæ˜¯head entityçš„å‘é‡ï¼Œtæ˜¯tail entityçš„å‘é‡ï¼Œræ˜¯å…³ç³»å‘é‡ã€‚</p><p>TransEå®šä¹‰äº†loss functionï¼š<br>$$<br>\mathcal{L(T)} = \sum_{&lt;h,r,t&gt;\in T} [\gamma + E(&lt;h,r,t&gt;) - E(&lt;hâ€™,râ€™,tâ€™&gt;)]_+<br>$$<br>å…¶ä¸­ $T$ ä»£è¡¨ä¸€ä¸ªä¸‰å…ƒç»„çš„é›†åˆï¼›$E(&lt;h,r,t&gt;) = ||h+r-t||_{L_n}$æ˜¯energy functionï¼›$&lt;h,r,t&gt;$æ˜¯Gä¸­çš„ä¸€ä¸ªä¸‰å…ƒç»„ï¼›$&lt;hâ€™,râ€™,tâ€™&gt;$ä»£è¡¨ä¸€ä¸ªä¸å­˜åœ¨äº $T$ çš„ä¸‰å…ƒç»„ï¼Œé€šè¿‡éšæœºæ›¿æ¢ä¸€éƒ¨åˆ†$&lt;h,r,t&gt;$æ¥å¾—åˆ°ï¼›$\gamma$ è¡¨ç¤ºè¾¹é™…è·ç¦»</p><p>ç®—æ³•çš„æ ¸å¿ƒæ˜¯ä»¤æ­£ä¾‹çš„ h+r-t è¶‹è¿‘äº 0ï¼Œè€Œè´Ÿä¾‹çš„ h+r-t è¶‹è¿‘äºæ— ç©·å¤§ã€‚æ•´ä¸ª TransE æ¨¡å‹çš„è®­ç»ƒè¿‡ç¨‹æ¯”è¾ƒç®€å•ï¼Œé¦–å…ˆå¯¹å¤´å°¾èŠ‚ç‚¹ä»¥åŠå…³ç³»è¿›è¡Œåˆå§‹åŒ–ï¼Œç„¶åæ¯å¯¹ä¸€ä¸ªæ­£ä¾‹å–ä¸€ä¸ªè´Ÿä¾‹æ ·æœ¬ï¼Œç„¶ååˆ©ç”¨ hinge loss function å°½å¯èƒ½ä½¿æ­£ä¾‹å’Œè´Ÿä¾‹åˆ†å¼€ï¼Œæœ€åé‡‡ç”¨ SGD(Stochastic Gradient Descent) æ–¹æ³•æ›´æ–°å‚æ•°ã€‚</p><p>ç”±TransEåˆè¡ç”Ÿå‡ºäº†è®¸å¤šæ¨¡å‹ã€‚</p><h4 id="1-2-TransH"><a href="#1-2-TransH" class="headerlink" title="1.2 TransH"></a>1.2 TransH</h4><p>è™½ç„¶ TransE æ¨¡å‹è®­ç»ƒé€Ÿåº¦å¿«ã€æ˜“äºå®ç°ï¼Œä½†æ˜¯å®ƒä¸èƒ½å¤Ÿè§£å†³å¤šå¯¹ä¸€å’Œä¸€å¯¹å¤šå…³ç³»çš„é—®é¢˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜å¹¶ä»ç„¶ç»´æŒè¾ƒä½çš„å¤æ‚åº¦ï¼ŒTransH <sup id="fnref:2"><a href="#fn:2" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="Wang, Z., Zhang, J., Feng, J., & Chen, Z. (2014, July). Knowledge Graph Embedding by Translating on Hyperplanes. In *AAAI* (Vol. 14, pp. 1112-1119).">[2]</span></a></sup> ä¸å†ä¸¥æ ¼è¦æ±‚ h+r-l=0ï¼Œè€Œæ˜¯åªéœ€è¦ä¿è¯å¤´ç»“ç‚¹å’Œå°¾èŠ‚ç‚¹åœ¨å…³ç³»å¹³é¢ä¸Šçš„æŠ•å½±åœ¨ä¸€æ¡ç›´çº¿ä¸Šï¼Œå› æ­¤èƒ½å¤Ÿå¾—åˆ°å›¾ä¸­å¤´ç»“ç‚¹å‘é‡æ­£ç¡®çš„è¡¨ç¤ºã€‚</p><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-03-12-202332.jpg"></p><p>è®ºæ–‡å¦ä¸€ä¸ªäº®ç‚¹æ˜¯è®¾è®¡äº†ä¸€ç§è´Ÿç±»æŠ½æ ·çš„æ–¹æ³•ï¼Œå³ä¸€å¯¹å¤šçš„æ—¶å€™ï¼Œç»™headæ›´å¤šçš„æŠ½æ ·æ¦‚ç‡ï¼Œ åŒæ ·çš„å¤šå¯¹ä¸€çš„æ—¶å€™ï¼Œç»™tailæ›´å¤šæŠ½æ ·æ¦‚ç‡ã€‚</p><h4 id="1-3-TransR-CTrans"><a href="#1-3-TransR-CTrans" class="headerlink" title="1.3 TransR/CTrans"></a>1.3 TransR/CTrans</h4><p>TransEå’ŒTransHéƒ½å‡è®¾äº†å®ä½“å’Œå…³ç³»éƒ½åœ¨åŒä¸€ä¸ªç©ºé—´å†…ï¼Œä½†ç”±äºå®ä½“å’Œå…³ç³»æœ¬èº«çš„ä¸åŒï¼Œç®€å•åœ°è®¤ä¸ºå®ƒä»¬embeddingåœ¨åŒä¸€ä¸ªç©ºé—´å†…æ˜¯ä¸å……åˆ†çš„ã€‚å› æ­¤ï¼ŒTransR<sup id="fnref:3"><a href="#fn:3" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="Lin, Y., Liu, Z., Sun, M., Liu, Y., & Zhu, X. (2015, January). Learning entity and relation embeddings for knowledge graph completion. In *AAAI* (Vol. 15, pp. 2181-2187).">[3]</span></a></sup>å¯¹äº<strong>æ¯ä¸€ä¸ªr</strong>ï¼Œæˆ‘ä»¬è®¾ç½®mappingçŸ©é˜µ$M_r$ï¼Œä½¿å¾—<br>$$<br>h_{\perp} + r \simeq t_{\perp} \quad \text{where } h_{\perp} = M_{r}\cdot h, t_{\perp} = M_{r} \cdot t<br>$$<br>åé¢çš„æ–¹æ³•å°±å’ŒTransEè¾ƒä¸ºç±»ä¼¼äº†ã€‚</p><h4 id="1-4-TransD"><a href="#1-4-TransD" class="headerlink" title="1.4 TransD"></a>1.4 TransD</h4><p>å®é™…ä¸ŠTransD<sup id="fnref:4"><a href="#fn:4" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="Ji, G., He, S., Xu, L., Liu, K., & Zhao, J. (2015). Knowledge graph embedding via dynamic mapping matrix. In *Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)* (Vol. 1, pp. 687-696).">[4]</span></a></sup>æ˜¯å¯¹TransR/CTransçš„æ”¹è¿›ã€‚TransRæœ‰ä»¥ä¸‹ç¼ºç‚¹ï¼š</p><ul><li>å¯¹äºæ¯ä¸ªrï¼Œæ‰€æœ‰çš„å®ä½“éƒ½ä½¿ç”¨åŒä¸€ä¸ªmappingçŸ©é˜µ$M_{r}$ï¼Œä½†æ˜¯å®é™…ä¸Šå¯¹åº”äºä¸€ä¸ªrçš„å®ä½“æœ‰ä¸åŒçš„ç§ç±»ã€ç‰¹å¾ï¼Œè¿™ä¹ˆåšä¼šæœ‰ä¸€äº›é—®é¢˜ï¼›</li><li>mappingæ˜¯entityå’Œrelationä¹‹é—´çš„äº¤äº’è¿‡ç¨‹ï¼ŒmappingçŸ©é˜µä»…ç”±å…³ç³»å†³å®šæ˜¯ä¸åˆç†çš„ï¼›</li><li>çŸ©é˜µä¸å‘é‡çš„è¿ç®—çš„è®¡ç®—æ¯”è¾ƒå¤æ‚ï¼Œå¦‚æœåœ¨ä¸€ä¸ªKnowledge graphé‡Œæœ‰è¾ƒå¤šçš„relationï¼Œé‚£ä¹ˆå°±ä¼šæœ‰å¤§é‡çš„å‚æ•°ï¼Œä»¥åŠè¾ƒé«˜çš„å¤æ‚åº¦ï¼Œå› æ­¤å¯¼è‡´è®¡ç®—é‡è¿‡å¤§ï¼Œæ— æ³•åº”ç”¨åˆ°å¤§è§„æ¨¡knowledge graphã€‚</li></ul><p>å¯¹äºä»»æ„ä¸€ä¸ªentityæˆ–relationï¼ŒTransDå®šä¹‰ä¸¤ä¸ªå‘é‡ï¼Œç¬¬ä¸€ä¸ªè¡¨ç¤ºentityæˆ–relationçš„å«ä¹‰ï¼Œå¦ä¸€ä¸ªç”¨äºæŠŠentityæŠ•å½±åˆ°relationç©ºé—´ï¼ˆæˆ–è€…è¯´ç”¨äºæ„é€ mappingçŸ©é˜µï¼‰ã€‚å› æ­¤å¯¹äºæ¯ä¸ªentity-relation pairï¼Œéƒ½æœ‰ä¸€ä¸ªåŠ¨æ€ç”Ÿæˆçš„å”¯ä¸€çš„mappingçŸ©é˜µã€‚æ­¤å¤–ï¼Œä¸Šè¿°è¿‡ç¨‹æ²¡æœ‰ç”¨åˆ°çŸ©é˜µå‘é‡è¿ç®—ï¼Œè€Œç”¨å‘é‡çš„è¿ç®—ä»£æ›¿äº†ã€‚</p><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-03-12-202326.jpg"></p><p>TransDå¤§å¤§é™ä½è®¡ç®—å¤æ‚åº¦ï¼Œä½†ä»ç„¶ä¿æŒä¸é”™çš„æ•ˆæœã€‚</p><h4 id="1-5-TransA"><a href="#1-5-TransA" class="headerlink" title="1.5 TransA"></a>1.5 TransA</h4><p>å‰é¢çš„æ¨¡å‹éƒ½æ˜¯åŸºäºæ¬§å¼è·ç¦»è®¡ç®—ï¼Œä¹Ÿå°±æ˜¯è®¤ä¸ºæ¯ä¸€ç»´çš„é‡è¦æ€§æ˜¯ç›¸åŒçš„ã€‚ä½†å®é™…ä¸Šï¼Œæœ‰ä¸€äº›ç»´åº¦èƒ½è¾ƒå¥½çš„åŒºåˆ†ä¸åŒçš„entityå’Œrelationï¼Œä½†ä¹Ÿæœ‰è®¸å¤šä¸åŒ…å«ä»€ä¹ˆæœ‰æ•ˆä¿¡æ¯ï¼Œå› æ­¤ç”šè‡³å¯ä»¥è¢«è®¤ä¸ºæ˜¯å™ªéŸ³ï¼Œå› æ­¤ä¸åŒç»´åº¦çš„é‡è¦æ€§æ˜¾ç„¶æ˜¯ä¸åŒçš„ã€‚</p><p>TransA<sup id="fnref:5"><a href="#fn:5" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="Xiao, H., Huang, M., Hao, Y., & Zhu, X. (2015). TransA: An adaptive approach for knowledge graph embedding. *arXiv preprint arXiv:1509.05490*.">[5]</span></a></sup> æ¨¡å‹é€šè¿‡å¼•å…¥åŠ æƒçŸ©é˜µï¼Œèµ‹ç»™æ¯ä¸€ç»´åº¦æƒé‡ã€‚</p><p>ç»“æœå¦‚ä¸‹å›¾ï¼Œæ¬§å¼è·ç¦»æ¯ä¸€ç»´éƒ½æ˜¯åŒç­‰é‡è¦çš„ï¼Œä½“ç°ä¸ºåœ†å½¢ï¼›è€ŒTransAä½“ç°ä¸ºæ¤­åœ†å½¢ï¼Œæ˜¾ç„¶æ›´ç¬¦åˆæ•°æ®çš„åˆ†å¸ƒã€‚</p><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-03-12-202330.jpg"></p><h3 id="2-ProjE"><a href="#2-ProjE" class="headerlink" title="2. ProjE"></a>2. ProjE</h3><p>ProjE<sup id="fnref:6"><a href="#fn:6" rel="footnote"><span class="hint--top-right hint--error hint--large" aria-label="Shi, B., & Weninger, T. (2017, February). ProjE: Embedding Projection for Knowledge Graph Completion. In *AAAI* (Vol. 17, pp. 1236-1242).">[6]</span></a></sup>çš„ä½œè€…å°±æ˜¯Open-World Knowledge Graph Completionçš„ä½œè€…ï¼Œä¸¤ç¯‡æ–‡ç« åˆ†åˆ«è¢«AAAI2017å’ŒAAAI2018æ”¶å½•ï¼Œå¯ä»¥è®¤ä¸ºæ˜¯KGCä»»åŠ¡çš„ state-of-the-artã€‚è¿™é‡Œæä¸€ä¸‹ProjEçš„æ€è·¯ã€‚</p><h4 id="2-1-Model-Architecture"><a href="#2-1-Model-Architecture" class="headerlink" title="2.1 Model Architecture"></a>2.1 Model Architecture</h4><p>ç»™å‡º\&lt;h, r, ?>ï¼Œå·²çŸ¥hã€rï¼Œè¦æ±‚é¢„æµ‹ ? ã€‚é€šå¸¸çš„åšæ³•å°±æ˜¯æŠŠæ‰€æœ‰çš„å€™é€‰entityéƒ½æ‹¿æ¥æ‰“åˆ†ï¼Œå¾—åˆ†æœ€é«˜çš„å°±æ˜¯é¢„æµ‹çš„ç»“æœã€‚ä¸ºäº†å¾—åˆ°è¿™ä¸€ç³»åˆ—æ‰“åˆ†ï¼Œé¦–å…ˆæˆ‘ä»¬é€šè¿‡ä¸€ä¸ªè¿ç®—ç¬¦æ¥åˆå¹¶hå’Œrï¼Œå¾—åˆ°ä¸€ä¸ªå‘é‡ï¼Œç„¶åæˆ‘ä»¬æŠŠæ‰€æœ‰å€™é€‰entityæŠ•å½±åˆ°è¿™ä¸ªå‘é‡ä¸Šï¼Œéšåè¿ç®—å¾—åˆ°åˆ†æ•°ã€‚</p><p>ç°æœ‰çš„æ¨¡å‹ï¼ˆåŒ…æ‹¬ä¸Šé¢æåˆ°çš„ä¸€ç³»åˆ—transï¼‰å¾€å¾€é€šè¿‡mappingçŸ©é˜µæ¥åˆå¹¶entityå’Œrelationï¼Œè¿™é‡Œä½œè€…ä¹Ÿæ˜¯è¿™ä¹ˆåšï¼Œä½†æ˜¯ä»–è®¤ä¸ºç›®å‰è¿˜ä¸éœ€è¦è€ƒè™‘å„ä¸ªç»´åº¦ä¹‹é—´çš„ç›¸äº’ä½œç”¨ï¼Œå› æ­¤è¿™ä¸ªmappingçŸ©é˜µåº”è¯¥æ˜¯ä¸€ä¸ªå¯¹è§’çŸ©é˜µã€‚æ‰€ä»¥è¿™ä¸ªåˆå¹¶æ“ä½œå¯ä»¥è¢«å®šä¹‰ä¸ºï¼š<br>$$<br>e \oplus r = D_e e + D_r r + b_c<br>$$<br>å…¶ä¸­$D_e$å’Œ$D_r$å°±æ˜¯ä¸¤ä¸ªå¯¹è§’çŸ©é˜µã€‚</p><p>ç”±æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥å®šä¹‰embeddingæ˜ å°„å‡½æ•°ï¼š<br>$$<br>h(e, r) = g(W^c f(e \oplus r) + b_r )<br>$$<br>å…¶ä¸­få’Œgæ˜¯æ¿€æ´»å‡½æ•°(activation function)ï¼Œæˆ‘ä»¬åœ¨åé¢å®šä¹‰ï¼›$W^c$æ˜¯å€™é€‰entityæ„æˆçš„çŸ©é˜µã€‚å› æ­¤hå°±æ˜¯å¯¹æ‰€æœ‰å€™é€‰entityçš„æ‰“åˆ†çŸ©é˜µã€‚</p><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-03-12-202328.jpg"></p><p>ä¸Šå›¾æ˜¯ProjEçš„ç»“æ„ï¼ŒåŒ…æ‹¬ä¸¤éƒ¨åˆ†ç¥ç»ç½‘ç»œå±‚ï¼Œå…¶ä¸­ä¸ŠåŠéƒ¨åˆ†æ˜¯åˆå¹¶æ“ä½œï¼Œå³$e \oplus r$ï¼›ä¸‹åŠéƒ¨åˆ†æ˜¯æ˜ å°„å‡½æ•°ï¼Œæˆ–è€…è¯´æ‰“åˆ†å‡½æ•°ï¼Œå³$h(e,r)$ã€‚</p><h4 id="2-2-Loss-function"><a href="#2-2-Loss-function" class="headerlink" title="2.2 Loss function"></a>2.2 Loss function</h4><p>æˆ‘ä»¬è¿™é‡Œåˆ†ææ–¹ä¾¿åªçœ‹pointwise loss functionï¼š<br>$$<br>\mathcal{L}(e, r, y) = - \sum_{i\in{i|y_i=1} } {log(h(e,r)_i)} - \sum_{m} {\mathbb{E}_{j \sim P_y} log(h(e,r)_j)}<br>$$<br>å…¶ä¸­$y$æ˜¯ä¸€ä¸ªå¸ƒå°”å‘é‡ï¼Œ1ä¸ºæ­£ä¾‹ï¼Œ0ä¸ºåä¾‹ï¼›mä¸ªåä¾‹ã€‚pointwise ProjE å¯ä»¥è¢«çœ‹ä½œæ˜¯å¤šç±»åˆ†ç±»é—®é¢˜ï¼Œæ‰€ä»¥æˆ‘ä»¬é€‰å– f å’Œ g åˆ†åˆ«ä¸º sigmoid å’Œ tanh å‡½æ•°ã€‚</p><p>ä»£ç å®ç° <a href="https://github.com/bxshi/ProjE" target="_blank" rel="noopener">https://github.com/bxshi/ProjE</a></p><h2 id="Bibliographies"><a href="#Bibliographies" class="headerlink" title="Bibliographies"></a>Bibliographies</h2><p>ç¬”è®°å‚è€ƒï¼š</p><p><a href="http://www.infosec-wiki.com/?p=175755" target="_blank" rel="noopener">http://www.infosec-wiki.com/?p=175755</a></p><p><a href="https://www.jiqizhixin.com/articles/2017-11-03-5" target="_blank" rel="noopener">https://www.jiqizhixin.com/articles/2017-11-03-5</a></p><div id="footnotes"><hr><div id="footnotelist"><ol style="list-style: none; padding-left: 0; margin-left: 40px"><li id="fn:1"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">1.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Bordes, A., Usunier, N., Garcia-Duran, A., Weston, J., &amp; Yakhnenko, O. (2013). Translating embeddings for modeling multi-relational data. In <em>Advances in neural information processing systems</em> (pp. 2787-2795).<a href="#fnref:1" rev="footnote"> â†©</a></span></li><li id="fn:2"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">2.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Wang, Z., Zhang, J., Feng, J., &amp; Chen, Z. (2014, July). Knowledge Graph Embedding by Translating on Hyperplanes. In <em>AAAI</em> (Vol. 14, pp. 1112-1119).<a href="#fnref:2" rev="footnote"> â†©</a></span></li><li id="fn:3"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">3.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Lin, Y., Liu, Z., Sun, M., Liu, Y., &amp; Zhu, X. (2015, January). Learning entity and relation embeddings for knowledge graph completion. In <em>AAAI</em> (Vol. 15, pp. 2181-2187).<a href="#fnref:3" rev="footnote"> â†©</a></span></li><li id="fn:4"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">4.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Ji, G., He, S., Xu, L., Liu, K., &amp; Zhao, J. (2015). Knowledge graph embedding via dynamic mapping matrix. In <em>Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</em> (Vol. 1, pp. 687-696).<a href="#fnref:4" rev="footnote"> â†©</a></span></li><li id="fn:5"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">5.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Xiao, H., Huang, M., Hao, Y., &amp; Zhu, X. (2015). TransA: An adaptive approach for knowledge graph embedding. <em>arXiv preprint arXiv:1509.05490</em>.<a href="#fnref:5" rev="footnote"> â†©</a></span></li><li id="fn:6"><span style="display: inline-block; vertical-align: top; padding-right: 10px; margin-left: -40px">6.</span><span style="display: inline-block; vertical-align: top; margin-left: 10px;">Shi, B., &amp; Weninger, T. (2017, February). ProjE: Embedding Projection for Knowledge Graph Completion. In <em>AAAI</em> (Vol. 17, pp. 1236-1242).<a href="#fnref:6" rev="footnote"> â†©</a></span></li></ol></div></div>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;2018-3-10&quot;&gt;&lt;a href=&quot;#2018-3-10&quot; c
      
    
    </summary>
    
      <category term="research" scheme="https://juewang.me/categories/research/"/>
    
    
      <category term="knowledge-graph" scheme="https://juewang.me/tags/knowledge-graph/"/>
    
      <category term="KGC" scheme="https://juewang.me/tags/KGC/"/>
    
  </entry>
  
  <entry>
    <title>Open-World Knowledge Graph Completion ç¬”è®°</title>
    <link href="https://juewang.me/posts/%5B2018.2.26%5DOpen-World-Knowledge-Graph-Completion/"/>
    <id>https://juewang.me/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/</id>
    <published>2018-02-26T00:00:00.000Z</published>
    <updated>2018-03-12T20:23:16.728Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2 id="Open-World-Knowledge-Graph-Completion"><a href="#Open-World-Knowledge-Graph-Completion" class="headerlink" title="Open-World Knowledge Graph Completion"></a>Open-World Knowledge Graph Completion</h2><p><strong>æ‘˜è¦</strong>ï¼š[1]æ–‡é¦–å…ˆè®¨è®ºäº†Closed-World KGCï¼Œå®ƒæ— æ³•å¤„ç†ä» KG å¤–éƒ¨åŠ å…¥çš„æ–°å®ä½“ï¼Œå¹¶ä¸¥é‡ä¾èµ–å·²æœ‰KGè¿æ¥çš„ï¼Œä¸èƒ½å¯¹å¼±è¿æ¥æœ‰å¥½çš„é¢„æµ‹ã€‚ä¸ºæ­¤å®šä¹‰äº† Open-World KGCï¼Œå¯ä»¥æ¥æ”¶ æ–°çš„å®ä½“å¹¶é“¾æ¥åˆ° KGï¼›å¹¶ä¾æ­¤æå‡ºäº†ConMaskæ¨¡å‹ï¼Œåœ¨ç»™å®šå…³ç³»å’Œå®ä½“åã€å®ä½“æè¿°çš„å‰æä¸‹ï¼Œåˆ©ç”¨attentionæœºåˆ¶é€šè¿‡å…³ç³»å®šä½å®ä½“æè¿°ä¸­æœ€ç›¸å…³çš„è¯ï¼Œå†ä»¥è¿™äº›è¯å’Œå®ä½“å¾—åˆ°è¦é“¾æ¥çš„å®ä½“ã€‚</p><h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h3><p>çŸ¥è¯†å›¾è°±ï¼ˆKGï¼‰æ˜¯ä¸€ç§ä¿¡æ¯ç½‘ç»œï¼Œå®ƒç”¨ä¸‰å…ƒç»„ $(h,r,t)$ æ¥è¡¨ç¤ºçŸ¥è¯†ï¼ˆh: head entity, t: tail entity, r: relationï¼‰ï¼Œç›®å‰æ¯”è¾ƒå‡ºåçš„KGæœ‰ DBPediaï¼ŒConceptNet ç­‰ï¼Œç›®å‰çš„å¤§å¤šæ•°KGéƒ½æœ‰å™ªéŸ³ä¸”ä¸å®Œæ•´ï¼Œæ¯”å¦‚åŸºäºWikipediaçš„DBPediaæœ‰460ä¸‡ä¸ªå®ä½“ï¼Œä½†å…¶ä¸­ä¸€åŠå®ä½“æ‹¥æœ‰å°‘äº5ä¸ªçš„å…³ç³»ã€‚</p><p>è¿™è¯´æ˜äº†å¤§éƒ¨åˆ†çš„çŸ¥è¯†å›¾è°±ä»ç„¶æ˜¯éå¸¸ä¸å®Œå–„çš„ï¼Œæˆ‘ä»¬å¿…é¡»ä»ä¸€å¼€å§‹å°±è¦è€ƒè™‘ç³»ç»Ÿçš„ä¿®æ”¹ã€è¡¥å……å®Œå–„çš„å¯èƒ½æ€§ã€‚è¿™é¡¹ä»»åŠ¡è¢«å®šä¹‰ä¸ºKnowledge Graph Completion (KGC)ã€‚</p><h4 id="Closed-World-KGC"><a href="#Closed-World-KGC" class="headerlink" title="Closed-World KGC"></a>Closed-World KGC</h4><p>ç»™å®šä¸€ä¸ªä¸å®Œæ•´çš„KG $G=(E,R,T)$ å…¶ä¸­ $E,R,T$ åˆ†åˆ«è¡¨ç¤ºå®ä½“é›†ï¼Œå…³ç³»é›†ä»¥åŠä¸‰å…ƒç»„é›†ï¼ŒClosed-World KGCçš„ä»»åŠ¡å°±æ˜¯é€šè¿‡æ‰¾åˆ°ä¸€ç³»åˆ—ä¸¢å¤±çš„ä¸‰å…ƒç»„ $ Tâ€™ = { \langle h,r,t \rangle|h \in E, r \in R, t \in E, \langle h,r,t \rangle \notin T }$ æ¥è¡¥å……ç°æœ‰çš„ $G$.</p><p>ä¸€ä¸ªå¾ˆé‡è¦çš„åœ°æ–¹åœ¨äºï¼ŒClosed-World KGC å‡å®šäº†æ–°çš„å®ä½“ã€å…³ç³»éƒ½è¢«åŸæœ‰çš„ $G$ åŒ…å«ï¼Œå¯¹äºä¸åœ¨ $G$ ä¸­çš„å®ä½“åˆ™ä¸€ç­¹è«å±•ã€‚</p><p>ç›®å‰çš„Closed-World KGCæ–¹æ³•å¾ˆå¤šå¾€å¾€ä½¿ç”¨TranEæˆ–è€…ä½ç»´ç‰¹å¾è¡¨ç¤ºæ¨¡å‹ï¼Œå‰è€…çš„æ ¸å¿ƒæ€æƒ³å°±æ˜¯ $h+r=t$ ï¼Œåè€…åˆ™æŒ‡ Embedding ç­‰ã€‚</p><p>è¯¥æ–¹æ³•ä»…å¯¹å›ºå®šçš„æˆ–è€…ç¼“æ…¢æ›´æ–°çš„KGæœ‰æ•ˆï¼Œå¯¹äºå¿«é€Ÿå˜æ›´çš„KGåˆ™æ•ˆæœä¸€èˆ¬ã€‚</p><h4 id="Open-World-KGC"><a href="#Open-World-KGC" class="headerlink" title="Open-World KGC"></a>Open-World KGC</h4><p>ç»™å®šä¸€ä¸ªä¸å®Œæ•´çš„KG $G=(E,R,T)$ å…¶ä¸­ $E,R,T$ åˆ†åˆ«è¡¨ç¤ºå®ä½“é›†ï¼Œå…³ç³»é›†ä»¥åŠä¸‰å…ƒç»„é›†ï¼ŒOpen-World KGC çš„ä»»åŠ¡å°±æ˜¯æ‰¾åˆ° $G$ ä¸­æ²¡æœ‰çš„ä¸‰å…ƒç»„é›†ï¼Œ$Tâ€™ ={&lt;h,r,t&gt;|h\in E^i,r\in R, t\in E^i,&lt;h,r,t&gt;\notin T}$ å…¶ä¸­ $E^i$ æ˜¯Gçš„å®ä½“è¶…é›†ã€‚</p><p>Closed-Worldæ–¹æ³•å°±æ˜¯æ ¹æ®çŸ¥è¯†å›¾è°±çš„æ‹“æ‰‘ç»“æ„æ›´æ–°ä¸€ä¸ªéšæœºçš„å‘é‡ä½œä¸ºå®ä½“å’Œå…³ç³»çš„embeddingï¼Œä½†å¯¹äºä¸åœ¨ç½‘ç»œä¸­çš„å®ä½“ï¼Œè¿™ä¸ªæ–¹æ³•å°±å¤±æ•ˆäº†ï¼Œè¿™ä¸ªæ—¶å€™å°±éœ€è¦ç”¨åˆ«çš„ç‰¹å¾æ¥ä»£æ›¿è¿™ä¸ªç”¨ç½‘ç»œæ‹“æ‰‘ç»“æ„å¾—åˆ°çš„ç‰¹å¾ã€‚</p><p>ä¸€èˆ¬ç›´è§‰å°±æ˜¯ç”¨å®ä½“çš„æè¿°ï¼ˆentity descriptionï¼‰ï¼Œæ ¹æ®å®ä½“çš„æè¿°æ¥å¾—åˆ°ç‰¹å¾ï¼Œä½†ä»éç»“æ„åŒ–æ–‡æœ¬ä¸­å­¦ä¹ å‘é‡è¡¨ç¤ºæ¯”åœ¨ç½‘ç»œçš„æ‹“æ‰‘ç»“æ„ä¸­è¦éš¾å¾—å¤šï¼ŒåŸå› å¦‚ä¸‹ï¼š</p><ol><li>åœ¨Closed-world KGCæ¨¡å‹ä¸­ï¼Œæ¯ä¸ªå®ä½“éƒ½æœ‰ä¸€ä¸ªembedding (ä»ä¸å®ƒç›¸è¿çš„å®ä½“ä¸Šå­¦å¾—çš„)ï¼Œä½†Open-World KGCæ¨¡å‹åˆ™éœ€è¦ä»å®ä½“æè¿°çš„word embeddingä¸­å¾—åˆ°entity embeddingã€‚è€Œæ— è®ºå®ä½“ä¹‹é—´çš„è”ç³»æƒ…å†µæ˜¯ä»€ä¹ˆï¼Œword embeddingçš„æ›´æ–°éƒ½ä¼šå¯¼è‡´æœ‰ç›¸åŒè¯çš„entitiesçš„æ›´æ–°ã€‚</li><li>å› ä¸ºä½¿ç”¨äº†éç»“æ„åŒ–æ–‡æœ¬ï¼Œæ‰€ä»¥Open-World KGCæ¨¡å‹å¯èƒ½ä¼šå¼•å…¥å™ªéŸ³æˆ–è€…å†—ä½™ä¿¡æ¯ã€‚</li></ol><h3 id="2-Closed-World-KGC"><a href="#2-Closed-World-KGC" class="headerlink" title="2. Closed-World KGC"></a>2. Closed-World KGC</h3><p>åœ¨ Closed-World KGC ä¸­ï¼Œæœ€ä¸ºå¸¸ç”¨ä¹Ÿæœ€ä¸ºåŸºç¡€çš„æ–¹æ³•æ˜¯ä¸€ç§ç»™äºˆå¼ºåŒ–å­¦ä¹ (RL)çš„æ¨¡å‹ï¼Œè¢«ç§°ä¸ºTransE [2]. å®ƒæœ‰ä¸€ä¸ªç®€å•å®ç”¨çš„å‡è®¾ï¼š<br>$$<br>h+r = t<br>$$<br>å…¶ä¸­hæ˜¯head entityçš„å‘é‡ï¼Œtæ˜¯tail entityçš„å‘é‡ï¼Œræ˜¯å…³ç³»å‘é‡ã€‚</p><p>TransEå®šä¹‰äº†loss functionï¼š<br>$$<br>\mathcal{L(T)} = \sum_{&lt;h,r,t&gt;\in T} [\gamma + E(\langle h,r,t \rangle) - E(\langle hâ€™,râ€™,tâ€™ \rangle)]_+<br>$$<br>å…¶ä¸­ $T$ ä»£è¡¨ä¸€ä¸ªä¸‰å…ƒç»„çš„é›†åˆï¼›$E(\langle h,r,t \rangle) = ||h+r-t||_{L_n}$æ˜¯energy functionï¼›$\langle h,r,t \rangle$æ˜¯Gä¸­çš„ä¸€ä¸ªä¸‰å…ƒç»„ï¼›$hâ€™,\langle râ€™,tâ€™ \rangle$ä»£è¡¨ä¸€ä¸ªä¸å­˜åœ¨äº $T$ çš„ä¸‰å…ƒç»„ï¼Œé€šè¿‡éšæœºæ›¿æ¢ä¸€éƒ¨åˆ†$\langle h,r,t \rangle$æ¥å¾—åˆ°ã€‚</p><p>è¿™é‡Œè¿˜ç•¥å»äº†å¾ˆå¤šTransEçš„å˜ä½“ç­‰å…¶ä»–æ¨¡å‹ï¼Œä½†å®ƒä»¬éƒ½æ˜¯åŸºäºClosed-World KGCæ¥åšçš„ã€‚</p><h3 id="3-ConMask-for-Open-World-KGC"><a href="#3-ConMask-for-Open-World-KGC" class="headerlink" title="3. ConMask for Open-World KGC"></a>3. ConMask for Open-World KGC</h3><p>é¦–å…ˆé€šè¿‡ä¸€ä¸ªä¾‹å­æ¥è¯´æ˜ï¼š</p><p><strong>ä»»åŠ¡ï¼š</strong>å¡«è¡¥ä¸‰å…ƒç»„ $\langle \text{Ameen Sayani, residence, ?}\rangle$ï¼Œå…¶ä¸­KGä¸­å¹¶æ²¡æœ‰Ameen Sayaniè¿™ä¸ªå®ä½“ã€‚</p><p><strong>æè¿°ï¼š</strong>â€œâ€¦ <strong>Ameen Sayani</strong> was introduced to All India Radio, <strong>Bombay</strong>, by his brother Hamid Sayani. Ameen participated in English programmes there for ten years â€¦â€ ï¼Œ</p><p><strong>ç›®æ ‡é¢„æµ‹å®ä½“ï¼š</strong>Bombay (or Mumbai)</p><p>ä¸ºäº†æ‰¾åˆ°Ameen Sayaniçš„ä½å€ï¼Œåœ¨å¤„ç†è¿™ä¸ªä»»åŠ¡çš„è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬ä¸ä¼šä»å¤´çœ‹åˆ°å°¾ï¼Œè€Œæ˜¯æ‰¾åˆ°ç›¸å…³çš„å…³é”®è¯æ¯”å¦‚å®¶åº­æˆ–å·¥ä½œç›¸å…³çš„è¯ã€‚è¿™é‡Œï¼Œæˆ‘ä»¬å‘ç°Ameen Sayaniçš„å·¥ä½œåœ°ç‚¹All India Radioåœ¨Bombayï¼Œå› æ­¤æˆ‘ä»¬æ¨æµ‹Ameen Sayaniä¹Ÿä½åœ¨Bombayï¼ˆBombayå°±æ˜¯ç°åœ¨çš„Mumbaiï¼‰ã€‚</p><p>è¿™ä¸ªè¿‡ç¨‹ä¹Ÿå¯ä»¥è¢«å½’çº³ä¸ºï¼š</p><ol><li>å®šä½ä¸è¯¥ä»»åŠ¡ç›¸å…³çš„ä¿¡æ¯ã€‚</li><li>æ ¹æ®ä¸Šä¸‹æ–‡å’Œç›¸å…³æ–‡æœ¬æ¨æ–­ã€‚</li><li>æ ¹æ®ç›¸å…³æ–‡æœ¬æ¨å‡ºæ­£ç¡®ç›®æ ‡å®ä½“ã€‚</li></ol><p>ä»¿ç…§è¿™ä¸ªè¿‡ç¨‹ï¼ŒConMaskçš„å·¥ä½œæ–¹å¼è¢«è®¾è®¡ä¸ºï¼š</p><ol><li><strong>Relationship-dependent content masking</strong> â€“ æ ‡è®°é‚£äº›ä¸ä»»åŠ¡ç›¸å…³çš„è¯è¯­ã€‚</li><li><strong>Target fusion</strong> â€“ ä»ç›¸å…³æ–‡æœ¬ä¸­æŠ½å–ç›®æ ‡å®ä½“çš„embeddingã€‚</li><li><strong>Target entity resolution</strong> â€“ é€šè¿‡è®¡ç®—KGä¸­çš„å€™é€‰ç›®æ ‡å®ä½“ï¼Œ2ä¸­æŠ½å–å‡ºçš„å®ä½“embeddingä»¥åŠå…¶å®ƒæ–‡æœ¬ç‰¹å¾ä¹‹é—´çš„ç›¸ä¼¼åº¦æ¥é€‰å®šç›®æ ‡å®ä½“ã€‚</li></ol><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-03-12-202310.jpg" width="60%"></p><p>ConMaskæ¨¡å‹æ€»ä½“ç»“æ„å¦‚ä¸Šï¼ŒConMaské€šè¿‡é€‰æ‹©ä¸ç»™å®šå…³ç³»ç›¸å…³çš„è¯æ¥é¿å…å¼•å…¥ä¸ç›¸å…³çš„å’Œæœ‰å™ªéŸ³çš„è¯ã€‚å¯¹äºç›¸å…³çš„æ–‡æœ¬ï¼ŒConMaské€šè¿‡å…¨è¿æ¥å·ç§¯ç¥ç»ç½‘ç»œï¼ˆFCNï¼‰æ¥æå–word-embeddingã€‚æœ€åå®ƒå°†æå–çš„embeddingäºKGä¸­å­˜åœ¨çš„å®ä½“è¿›è¡Œæ¯”è¾ƒï¼Œä»è€Œè·å¾—ä¸€ç³»åˆ—ç›®æ ‡å®ä½“ã€‚</p><h4 id="3-1-Relationship-dependent-content-masking"><a href="#3-1-Relationship-dependent-content-masking" class="headerlink" title="3.1 Relationship-dependent content masking"></a>3.1 Relationship-dependent content masking</h4><p>ConMaskæ ¹æ®ç»™å®šçš„å…³ç³»é¢„å¤„ç†è¾“å…¥æ–‡æœ¬ï¼Œæ¥é€‰æ‹©ä¸€äº›ç›¸å…³çš„å°ç‰‡æ®µï¼Œä»è€Œå±è”½æ‰æ— å…³æ–‡æœ¬ã€‚content-maskingè¿™ä¸€çµæ„Ÿæ¥æºäºåŸºäºattentionæœºåˆ¶çš„RNNç½‘ç»œ[3]ï¼Œå…³äºattentionä¹‹å‰çš„ç¬”è®°ä¹Ÿæœ‰å­¦ä¹ è¿‡ã€‚</p><p>åŸºäºç›¸ä¼¼åº¦å¾—åˆ°é€‰æ‹©æœ€ç›¸å…³çš„è¯ï¼Œå…·ä½“å…¬å¼å¦‚ä¸‹ï¼š<br>$$<br>\tau(\phi(e), \psi(r)) = W_{\phi(e)} \circ f_w(W_{\phi(e)}, W_{\psi(r)})<br>$$<br>å…¶ä¸­ $e$ æ˜¯ä¸€ä¸ªå®ä½“ï¼Œ$r$ æ˜¯æŸä¸ªå…³ç³», $\phi$ æ˜¯description functionå¹¶è¿”å›ä¸€ä¸ªå‘é‡ç”¨äºè¡¨ç¤ºå¯¹ä¸€ä¸ªå®ä½“æˆ–å…³ç³»çš„æè¿°ï¼Œ$\psi$ æ˜¯name mapping functionå¹¶è¿”å›ä¸€ä¸ªå‘é‡ç”¨äºè¡¨ç¤ºä¸€ä¸ªå®ä½“æˆ–å…³ç³»çš„åå­—ï¼Œ $ W_{\phi{(e)}} \in \mathbb{R}^{|\phi(r)|\times k} $ æ˜¯ä¸€ä¸ªæè¿°çŸ©é˜µæ¯ä¸€è¡Œè¡¨ç¤ºä¸€ä¸ªkç»´çš„æè¿°ä¸­çš„word-embeddingï¼Œ $W_{\phi{(e)}} \in \mathbb{R}^{|\phi(r)|\times k} $ æ˜¯ä¸€ä¸ªåå­—çŸ©é˜µæ¯ä¸€è¡Œè¡¨ç¤ºä¸€ä¸ªkç»´çš„å®ä½“åå­—word-embeddingï¼Œ$\circ$ æ˜¯row-wise productï¼Œ$f_w$ ç”¨äºè®¡ç®—çš„æ¯ä¸€è¡Œçš„å±è”½æ¯”é‡ã€‚</p><p>ä½œè€…ç»™äº†ä¸€ä¸ªç®€å•çš„$f_w$ ï¼ŒMaximal Word-Relationship Weights(MWRW)ï¼Œå°±æ˜¯è®¡ç®—å®ä½“æè¿°ä¸­æ¯ä¸ªè¯å‘é‡ä¸å…³ç³»åç§°çš„æ¯ä¸ªè¯å‘é‡çš„æœ€å¤§cosç›¸ä¼¼åº¦:<br>$$<br>f_w^{MWRW}(W_{\phi(e)}, W_{\psi(r)})_{[i]} =  max_j(\frac{\sum_m^k{W_{\phi(e)[i,m]} W_{\psi(r)[j,m]}}}{\sqrt{\sum_m^k{W^2_{\phi(e)[i,m]}}}\sqrt{\sum_m^k{W^2_{\psi(e)[j,m]}}}})<br>$$<br>è¿™ä¸ªå…¬å¼ä¼šç»™ä¸ç»™å®šå…³ç³»æ— å…³çš„è¯æ›´å°çš„æƒé‡ï¼Œä¸å…³ç³»è¯­ä¹‰æ¥è¿‘çš„è¯æ›´å¤§çš„æƒé‡ï¼Œä½†æƒé‡æœ€é«˜çš„è¯ä¸€èˆ¬ä¸æ˜¯ç›®æ ‡å®ä½“ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œç»™å®šå…³ç³»spouseï¼Œå¾—åˆ°æœ€å¤§æƒé‡çš„æ˜¯marriedï¼Œè™½ç„¶marriedä¸spouseåœ¨è¯­ä¹‰ä¸Šæ¥è¿‘ï¼Œä½†å®ƒå¹¶ä¸æ˜¯ç›®æ ‡å®ä½“ï¼Œå› æ­¤ä½œè€…ç§°è¿™ç§æœ‰ç€æœ€å¤§MWRWæƒé‡çš„è¯ä¸ºæŒ‡ç¤ºè¯ï¼ˆindicator wordï¼‰ï¼Œå› ä¸ºæ­£ç¡®çš„è¯ä¸€èˆ¬å°±åœ¨è¯¥è¯é™„è¿‘ï¼Œåœ¨ä¸‹å›¾ä¾‹å­ä¸­å¯ä»¥å‘ç°ç›®æ ‡å®ä½“barack obamaå°±åœ¨marriedåé¢ã€‚</p><p>ä¸ºäº†ç»™ç›®æ ‡å®ä½“wordæ­£ç¡®çš„æƒé‡ï¼Œä½œè€…æ”¹è¿›äº†è¿™ä¸ªå…¬å¼ï¼Œå…·ä½“å…¬å¼å¦‚ä¸‹ï¼Œè¿™ä¸ªå…¬å¼å°±æ˜¯æ¯ä¸ªè¯çš„æƒé‡ä¸ä¼šå°äºä¹‹å‰ $k_m$ ç§°ä¸º Maximal Context-Relationship Weights (MCRW)ï¼š<br>$$<br>f_w^{MCRW}(W_{\phi(e)}, W_{\psi(r)})_{[i]} =  max(f_w^{MWRW}(W_{\phi(e)}, W_{\psi(r)})_{[i-k_m:i]})<br>$$<br><img src="http://oi4yiqiop.bkt.clouddn.com/2018-03-12-202313.jpg"></p><h4 id="3-2-Target-Fusion"><a href="#3-2-Target-Fusion" class="headerlink" title="3.2 Target Fusion"></a>3.2 Target Fusion</h4><p>è¿™ä¸€æ­¥éª¤ç”¨äºè¾“å‡ºåŸºäºè¯çš„å®ä½“embeddingï¼Œè¿™ä¸ªè¿‡ç¨‹è®°ä¸º$\xi$ï¼Œä½¿ç”¨Conetent Masking $\tau$ çš„è¾“å‡ºã€‚å®ƒä½¿ç”¨å…¨è¿æ¥å·ç§¯ç½‘ç»œï¼Œå…¶ç»“æ„å¦‚ä¸‹ï¼š</p><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-03-12-202312.jpg"></p><p><strong>Semantic Averaging</strong></p><p>æˆ‘ä»¬å¯ä»¥å¯¹æ‰€æœ‰å®ä½“è¿›è¡Œembeddingï¼Œä½†æ˜¯è¿™ä¼šäº§ç”Ÿå¤§é‡çš„å‚æ•°ï¼Œä½¿è®¡ç®—å˜å¾—éå¸¸å¤æ‚ã€‚äº‹å®ä¸Šï¼Œå› ä¸ºTarget fusionå‡½æ•°ç”¨äºæŠ½å–ï¼Œæ‰€ä»¥å¯¹ä¸éœ€è¦æŠ½å–çš„å®ä½“åå­—ä½¿ç”¨target fusionå°±ä¼šæ˜¾å¾—å¾ˆå¥‡æ€ªä¹Ÿå¾ˆæ²¡æœ‰å¿…è¦ã€‚</p><p>è¿™é‡Œä½œè€…æå‡ºäº†ä¸€ä¸ªç®€å•çš„è¯­ä¹‰å¹³å‡æ³•æ¥è®¡ç®—è¿™äº›å®ä½“çš„embeddingï¼š$\eta(W) = \frac{1}{k_l}\sum_i^{k_i}W_i$</p><h4 id="3-3-Loss-function"><a href="#3-3-Loss-function" class="headerlink" title="3.3 Loss function"></a>3.3 Loss function</h4><p>ä¸ºäº†åŠ é€Ÿè®­ç»ƒï¼Œæˆ‘ä»¬å‚è€ƒ list-wise ranking loss function (Shi and Weninger 2017)ï¼Œå¹¶è®¾è®¡ partial list-wise ranking loss functionï¼Œæ‹¥æœ‰æ­£è´Ÿç›®æ ‡é‡‡æ ·ã€‚æ­£æ ·æœ¬å°±æ˜¯è®­ç»ƒé›†çš„æ ‡æ³¨å†…å®¹ï¼Œè®°ä¸º$E^+$ï¼›è´Ÿæ ·æœ¬å°±æ˜¯æ›¿æ¢æ­£æ ·æœ¬çš„head entityæˆ–tail entityæ‰€å¾—åˆ°çš„ï¼Œè®°ä¸º$E^-$ ã€‚<br>$$<br>\mathcal{L}(h, r, t) =  \begin{cases}<br>\sum_{h_+\in E^+}{-\frac{log(S(h_+,r,t,E^+\cup E^-))}{|E^+|}}, &amp; \text{if }p_c &gt; 0.5; \\<br>\sum_{h_+\in E^+}{-\frac{log(S(h,r,t_+,E^+\cup E^-))}{|E^+|}}, &amp; \text{if }p_c \le 0.5; .<br>\end{cases}<br>$$<br>$p_c$ æœä»$[0,1]$çš„å‡åŒ€åˆ†å¸ƒï¼Œå¤§äº0.5æ—¶ï¼ŒæŠŠè¾“å…¥å®ä½“ä½œä¸ºtail entityï¼Œå°äº0.5çš„æ—¶å€™å°±æ˜¯ä½œä¸ºhead entityï¼Œè¡¨ç¤ºæ›¿æ¢head entityå’Œtail entityçš„æ¦‚ç‡å„ä¸º50%ã€‚å¦æœ‰$S$, å³ softmax normalized output of ConMaskï¼š<br>$$<br>S(h,r,t,E^+) = \begin{cases}<br>\sum_{e \in E^\pm}^{exp(ConMask(h,r,t))}{exp(ConMask(e,r,t))} &amp; \text{if } p_c &gt; 0.5 \\<br>\sum_{e \in E^\pm}^{exp(ConMask(e,r,t))}{exp(ConMask(h,r,t))} &amp; \text{if } p_c \le 0.5 \\<br>\end{cases}<br>$$</p><h3 id="4-Results"><a href="#4-Results" class="headerlink" title="4. Results"></a>4. Results</h3><p>ä»ç»“æœä¸Šçœ‹ï¼Œå¯¹æ¯”å…¶ä»–æ¨¡å‹ï¼Œåœ¨å¼€æ”¾é¢†åŸŸï¼ŒConMaskè·å¾—äº†æœ€ä½³çš„æ•ˆæœï¼›åœ¨Closed-Worldä¸­ï¼Œå°½ç®¡ConMaskä¸æ˜¯ä¸ºæ­¤è®¾è®¡çš„ï¼Œä½†æ˜¯å¯¹æ¯”TransEå’ŒTransRä¾ç„¶ä¸é€Šè‰²ï¼Œç»“æœç›¸ä»¿ã€‚</p><p>ç›®å‰è€Œè¨€ï¼ŒConMaskæ¨¡å‹åªèƒ½é¢„æµ‹åœ¨å®ä½“æè¿°ä¸­è¡¨è¾¾çš„å…³ç³»ï¼Œå°†æ¥è¿˜åº”è€ƒè™‘æ‰©å±•å®ƒï¼Œä½¿å…¶èƒ½å¤Ÿå‘ç°æ–°çš„æˆ–éšå«çš„å…³ç³»ã€‚</p><h2 id="Bibliographies"><a href="#Bibliographies" class="headerlink" title="Bibliographies"></a>Bibliographies</h2><p>ç¬”è®°å‚è€ƒï¼š<a href="https://zhuanlan.zhihu.com/p/33026043ï¼Œhttp://blog.csdn.net/TgqDT3gGaMdkHasLZv/article/details/79224178" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/33026043ï¼Œhttp://blog.csdn.net/TgqDT3gGaMdkHasLZv/article/details/79224178</a></p><p>ä»£ç å®ç°ï¼š<a href="https://github.com/bxshi/ConMask" target="_blank" rel="noopener">https://github.com/bxshi/ConMask</a></p><p>[1] Shi, Baoxu, and Tim Weninger. â€œOpen-World Knowledge Graph Completion.â€ <em>arXiv preprint arXiv:1711.03438</em> (2017).</p><p>[2] Bordes, A., Usunier, N., Garcia-Duran, A., Weston, J., &amp; Yakhnenko, O. (2013). Translating embeddings for modeling multi-relational data. In <em>Advances in neural information processing systems</em> (pp. 2787-2795).</p><p>[3] Chorowski, J. K., Bahdanau, D., Serdyuk, D., Cho, K., &amp; Bengio, Y. (2015). Attention-based models for speech recognition. In <em>Advances in neural information processing systems</em> (pp. 577-585).</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h2 id=&quot;Open-World-Knowledge-Graph-Comple
      
    
    </summary>
    
      <category term="research" scheme="https://juewang.me/categories/research/"/>
    
    
      <category term="CNN" scheme="https://juewang.me/tags/CNN/"/>
    
      <category term="knowledge-graph" scheme="https://juewang.me/tags/knowledge-graph/"/>
    
      <category term="KGC" scheme="https://juewang.me/tags/KGC/"/>
    
  </entry>
  
  <entry>
    <title>Nested LSTMs ç¬”è®°</title>
    <link href="https://juewang.me/posts/%5B2018.2.5%5DNested-LSTMs/"/>
    <id>https://juewang.me/posts/[2018.2.5]Nested-LSTMs/</id>
    <published>2018-02-05T00:00:00.000Z</published>
    <updated>2018-03-12T20:22:57.677Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2 id="Nested-LSTMs"><a href="#Nested-LSTMs" class="headerlink" title="Nested LSTMs"></a>Nested LSTMs</h2><p><strong>æ‘˜è¦</strong>ï¼šæœ€è¿‘ï¼Œä¸€ç§æ–°çš„ Nested LSTMs ç½‘ç»œè¢«æå‡ºã€‚åœ¨é€šå¸¸çš„LSTMç½‘ç»œä¸­ï¼Œæˆ‘ä»¬é€šè¿‡å°†LSTMå•å…ƒå †å ï¼Œä»è€Œå½¢æˆæ·±åº¦RNNç½‘ç»œï¼Œæé«˜å…¶æ•ˆæœï¼›Nested LSTMåˆ™é€šè¿‡åµŒå¥—è€Œä¸æ˜¯å †æ ˆæ¥å¢æ·»LSTMçš„æ·±åº¦ã€‚åœ¨NLSTMä¸­ï¼Œè®°å¿†å•å…ƒçš„å€¼æ˜¯ç”±LSTMå•å…ƒè®¡ç®—çš„ï¼Œå…¶ä¸­ï¼ŒLSTMå•å…ƒå…·æœ‰è‡ªèº«å†…åœ¨çš„è®°å¿†å•å…ƒã€‚å…·ä½“è€Œè¨€ï¼ŒNLSTMè®°å¿†å•å…ƒå¹¶ä¸æ˜¯æŒ‰ç…§ç­‰å¼ï¼š$c_t^{outer} = f_t \odot c_{t-1} + i_t \odot g_t$ å¯¹ï¼ˆå¤–éƒ¨ï¼‰è®°å¿†å•å…ƒçš„å€¼è¿›è¡Œè®¡ç®—ï¼Œè€Œæ˜¯ä½¿ç”¨çº§è”ï¼š$(f_t \odot c_{t-1}, i_t \odot g_t)$ å°†å…¶ä½œä¸ºå†…éƒ¨LSTMï¼ˆæˆ–NLSTMï¼‰è®°å¿†å•å…ƒçš„è¾“å…¥ï¼Œå¹¶è®¾å®š $c_t^{outer} = h_t^{inner}$ã€‚åœ¨è®¿é—®å†…éƒ¨è®°å¿†æ—¶ï¼ŒNested LSTM ç›¸æ¯”ä¼ ç»Ÿçš„å †æ ˆ LSTM æœ‰æ›´é«˜çš„è‡ªç”±åº¦ï¼Œä»è€Œèƒ½å¤„ç†æ›´é•¿æ—¶é—´è§„æ¨¡çš„å†…éƒ¨è®°å¿†ï¼›å®éªŒä¹Ÿè¡¨æ˜ï¼Œåœ¨å‚æ•°æ•°é‡ç›¸ä¼¼çš„æƒ…å†µä¸‹ï¼ŒNLSTM åœ¨å¤šç§ä»»åŠ¡ä¸Šéƒ½è¶…è¶Šäº†å †æ ˆ LSTMã€‚ä½œè€…è®¤ä¸ºNested LSTM æœ‰æ½œåŠ›ç›´æ¥å–ä»£å †æ ˆ LSTMã€‚</p><h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h3><p>å­¦ä¹ é•¿æœŸçš„ä¾èµ–å…³ç³»æ˜¯å½“å‰äººå·¥æ™ºèƒ½é¢†åŸŸä¸­ï¼Œå°¤å…¶æ˜¯åœ¨nlpé¢†åŸŸï¼Œæœºå™¨å­¦ä¹ æ–¹æ³•çš„å…³é”®æ€§æŒ‘æˆ˜ã€‚åŸºäºå¾ªç¯ç¥ç»ç½‘ç»œçš„ä½“ç³»ç»“æ„å·²ç»åœ¨ä½¿å¾—æœºå™¨èƒ½å¤Ÿæ¨¡ä»¿è¿™ç§èƒ½åŠ›æ–¹é¢å–å¾—äº†æ˜¾è‘—è¿›å±•ã€‚</p><h4 id="single-layer-LSTM"><a href="#single-layer-LSTM" class="headerlink" title="single-layer LSTM"></a>single-layer LSTM</h4><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-03-12-202251.jpg" width="90%"></p><p>RNNçš„è¾“å…¥æ˜¯ä»¥å½“å‰çš„çŠ¶æ€ä¸ºä¾æ®ï¼Œé€‚åˆå­¦ä¹ æ—¶é—´ä¸Šçš„æŠ½è±¡ç‰¹å¾ã€‚åœ¨å®è·µä¸­ï¼Œè®¸å¤šä¸“å®¶å·²ç»è¯æ˜ï¼Œæ›´ä¸ºå¤æ‚çš„ä½“ç³»ç»“æ„æ˜¯è§£å†³è®¸å¤šä»»åŠ¡çš„å…³é”®ã€‚å…¶ä¸­ä¸€ä¸ªåŸå› æ˜¯æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼ˆHochreiteräº1991å¹´ã€Bengioç­‰äººäº1994å¹´æå‡ºï¼‰ï¼Œå®ƒä½¿å¾—ç®€å•çš„RNNéš¾ä»¥å­¦ä¹ é•¿æœŸä¾èµ–å…³ç³»ã€‚Hochreiterå’ŒSchmidhuberäº1997å¹´æå‡ºäº†LSTMï¼ŒåŒ…å«èƒ½å¤Ÿæ”¹å–„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜çš„è®°å¿†æœºåˆ¶ã€‚å•å±‚LSTMå¦‚ä¸Šå›¾ï¼Œå›¾ä¸­çš„ä¸‰ä¸ªå•å…ƒå®é™…ä¸Šæ˜¯åŒä¸€ä¸ªå•å…ƒï¼Œå®ƒå¾ªç¯åœ°å°†å†…éƒ¨çš„å‚æ•°ä¼ é€’ç»™è‡ªå·±ã€‚</p><h4 id="Stacked-LSTMs"><a href="#Stacked-LSTMs" class="headerlink" title="Stacked LSTMs"></a>Stacked LSTMs</h4><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-03-12-202254.jpg" width="60%"></p><p>å †æ ˆ LSTM æ¶æ„ä½¿ç”¨ä¸€ç³»åˆ— LSTM ä¸€å±‚å±‚åœ°å †å åœ¨ä¸€èµ·æ¥å¤„ç†æ•°æ®ï¼Œä¸€å±‚çš„è¾“å‡ºæˆä¸ºä¸‹ä¸€å±‚çš„è¾“å…¥ã€‚ä¸Šå›¾ä¸ºä¸€ä¸ªä¸¤å±‚çš„LSTMç½‘ç»œã€‚</p><p>å¼•å…¥å¤šå±‚çš„ç»“æ„ï¼Œå³å°†å¤šä¸ªLSTMå•å…ƒå †å ï¼Œæ¯ä¸€å±‚çš„è¾“å‡ºæˆä¸ºä¸‹ä¸€å±‚çš„è¾“å…¥ã€‚ æ¯å±‚å¤„ç†æˆ‘ä»¬å¸Œæœ›è§£å†³çš„ä»»åŠ¡çš„ä¸€éƒ¨åˆ†ï¼Œå¹¶å°†å…¶ä¼ é€’ç»™ä¸‹ä¸€å±‚ã€‚é¢å¤–çš„éšè—å±‚å¯ä»¥æ·»åŠ åˆ°å¤šå±‚æ„ŸçŸ¥å™¨ç¥ç»ç½‘ç»œï¼Œä½¿å…¶æœ‰æ›´æ·±å…¥çš„â€œç†è§£â€ã€‚ é¢å¤–çš„éšè—å±‚è¢«è®¤ä¸ºé‡æ–°ç»„åˆäº†æ¥è‡ªå…ˆå‰å±‚çš„å­¦ä¹ è¡¨ç¤ºï¼Œå¹¶åœ¨é«˜åº¦æŠ½è±¡å±‚æ¬¡ä¸Šæ‰¾åˆ°æ–°çš„è¡¨ç¤ºã€‚ ä¾‹å¦‚ï¼Œä»çº¿æ¡åˆ°å½¢çŠ¶åˆ°å¯¹è±¡ã€‚</p><h4 id="Nested-LSTMs-1"><a href="#Nested-LSTMs-1" class="headerlink" title="Nested LSTMs"></a>Nested LSTMs</h4><p>åœ¨ NLSTM ä¸­ï¼ŒLSTM çš„è®°å¿†å•å…ƒå¯ä»¥è®¿é—®å†…éƒ¨è®°å¿†ã€‚ç›¸æ¯”äºä¼ ç»Ÿçš„å †æ ˆ LSTMï¼Œè¿™ä¸€å…³é”®ç‰¹å¾ä½¿å¾—è¯¥æ¨¡å‹èƒ½å®ç°æ›´æœ‰æ•ˆçš„æ—¶é—´å±‚çº§ã€‚åœ¨ NLSTM ä¸­ï¼Œå¤–éƒ¨è®°å¿†å•å…ƒå¯è‡ªç”±é€‰æ‹©è¯»å–ã€ç¼–å†™çš„ç›¸å…³é•¿æœŸä¿¡æ¯åˆ°å†…éƒ¨å•å…ƒã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œåœ¨Stacked LSTM ä¸­ï¼Œé«˜å±‚çº§çš„æ¿€æ´»ï¼ˆç±»ä¼¼å†…éƒ¨è®°å¿†ï¼‰ç›´æ¥ç”Ÿæˆè¾“å‡ºï¼Œå› æ­¤å¿…é¡»åŒ…å«æ‰€æœ‰çš„ä¸å½“å‰é¢„æµ‹ç›¸å…³çš„çŸ­æœŸä¿¡æ¯ã€‚æ¢è¨€ä¹‹ï¼ŒStacked LSTM ä¸Nested LSTM ä¹‹é—´çš„ä¸»è¦ä¸åŒåœ¨äºï¼ŒNLSTM å¯ä»¥é€‰æ‹©æ€§åœ°è®¿é—®å†…éƒ¨è®°å¿†ã€‚è¿™ä½¿å¾—ï¼Œå³ä½¿è¿™äº›äº‹ä»¶ä¸å½“å‰äº‹ä»¶ä¸ç›¸å…³ï¼Œå†…éƒ¨è®°å¿†ä¹Ÿèƒ½å¤Ÿè®°ä½ã€å¤„ç†æ›´é•¿æ—¶é—´è§„æ¨¡ä¸Šçš„äº‹ä»¶ã€‚æˆ‘ä»¬åœ¨åé¢ä¸€ç« æ›´è¯¦ç»†åœ°ä»‹ç»å®ƒã€‚</p><h3 id="2-Model-of-Nested-LSTMs"><a href="#2-Model-of-Nested-LSTMs" class="headerlink" title="2. Model of Nested LSTMs"></a>2. Model of Nested LSTMs</h3><p>LSTM ä¸­çš„è¾“å‡ºé—¨ä¼šç¼–ç å¯èƒ½ä¸å½“å‰çš„æ—¶é—´æ­¥éª¤ä¸ç›¸å…³ï¼Œä½†æ˜¯ä»ç„¶å€¼å¾—è®°å¿†çš„ä¿¡æ¯ã€‚Nested LSTM æ ¹æ®è¿™ä¸€ç›´è§‚ç†è§£æ¥åˆ›é€ ä¸€ç§è®°å¿†çš„æ—¶é—´å±‚çº§ã€‚ä»¥åŒæ ·çš„æ–¹å¼è¢«gateæ§è®¿é—®å†…éƒ¨è®°å¿†ï¼Œå› æ­¤é•¿æœŸä¿¡æ¯åªæœ‰åœ¨æƒ…æ™¯ç›¸å…³çš„æ¡ä»¶ä¸‹æ‰èƒ½é€‰æ‹©æ€§åœ°è®¿é—®ã€‚</p><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-03-12-202253.jpg" width="80%"></p><h4 id="The-architecture"><a href="#The-architecture" class="headerlink" title="The architecture"></a>The architecture</h4><p>åœ¨ LSTM ç½‘ç»œä¸­ï¼Œå•å…ƒçŠ¶æ€çš„æ›´æ–°å…¬å¼å’Œé—¨æ§æœºåˆ¶å¯ä»¥è¡¨ç¤ºä¸ºä»¥ä¸‹æ–¹ç¨‹å¼ï¼š<br>$$<br>i_t = \sigma_i (x_t W_{xi} + h_{t-1} W_{hi} + b_i) \\<br>f_t = \sigma_t (x_t W_{xf} + h_{t-1} W_{hf} + b_i) \\<br>c_t = f_t \odot c_{c-1} + \sigma_c (x_t W_{xc} + h_{t-1} W_{hc} + b_c) \\<br>o_t = \sigma_o (x_t W_{xo} + h_{t-1} W_{ho} + b_o) \\<br>h_t = o_t \odot \sigma_h(c_t)<br>$$<br>Nested LSTM ä½¿ç”¨å·²å­¦ä¹ çš„çŠ¶æ€å‡½æ•° $c_t = m_t(f_t\odot c_{tâˆ’1}, i_t \odot g_t)â€‹$ æ¥æ›¿ä»£ LSTM ä¸­è®¡ç®— $c_tâ€‹$ çš„åŠ è¿ç®—ã€‚æˆ‘ä»¬å°†å‡½æ•°çš„çŠ¶æ€è¡¨ç¤ºä¸º m åœ¨æ—¶é—´ t çš„å†…éƒ¨è®°å¿†ï¼ˆinner memoryï¼‰ï¼Œè°ƒç”¨è¯¥å‡½æ•°ä»¥è®¡ç®— $c_tâ€‹$ å’Œ $m_{t+1}â€‹$ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨å¦ä¸€ä¸ª LSTM å•å…ƒæ¥å®ç°è¯¥è®°å¿†å‡½æ•°ï¼Œå°±ç”Ÿæˆäº† Nested LSTMã€‚åŒæ ·ï¼Œè¯¥è®°å¿†å‡½æ•°èƒ½å¤Ÿç”±å¦ä¸€ä¸ª Nested LSTM å•å…ƒæ›¿æ¢ï¼Œå› æ­¤å°±èƒ½æ„å»ºä»»æ„æ·±çš„åµŒå¥—ç½‘ç»œã€‚</p><p>å› æ­¤ï¼Œæˆ‘ä»¬å¾—åˆ°NLSTM ä¸­è®°å¿†å‡½æ•°çš„è¾“å…¥å’Œéšè—çŠ¶æ€ï¼š<br>$$<br>\tilde{h}_{t-1} = f_t \odot c_{t-1} \\<br>\tilde{x}_t = i_t \odot \sigma_c (x_t W_{xc} + h_{t-1} W_{hc} + b_c)<br>$$<br>æ³¨æ„å¦‚æœè®°å¿†å‡½æ•°æ˜¯åŠ æ€§çš„ï¼Œé‚£ä¹ˆ$c_t = f_t \odot c_{c-1} + \sigma_c (x_t W_{xc} + h_{t-1} W_{hc} + b_c) =  \tilde{h}_{t-1} + \tilde{x}_t $ï¼Œæ•´ä¸ªç³»ç»Ÿå°†é€€åŒ–åˆ°ç»å…¸çš„ LSTMã€‚</p><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-03-12-202250.jpg"></p><p><em>LSTMã€Stacked LSTM å’Œ Nested LSTM çš„è®¡ç®—å›¾å½¢ã€‚éšè—çš„çŠ¶æ€ã€å¤–éƒ¨è®°å¿†å•å…ƒå’Œå†…éƒ¨è®°å¿†å•å…ƒåˆ†åˆ«ç”±hã€cå’Œdè¿›è¡Œè¡¨ç¤ºã€‚è™½ç„¶å½“å‰çš„éšè—çŠ¶æ€å¯ä»¥ç›´æ¥å½±å“ä¸‹ä¸€ä¸ªå†…éƒ¨è®°å¿†å•å…ƒçš„å†…å®¹ï¼Œä½†å†…éƒ¨è®°å¿†åªæœ‰é€šè¿‡å¤–éƒ¨è®°å¿†æ‰èƒ½å¤Ÿå½±å“éšè—çŠ¶æ€ã€‚</em><br>$$<br>\widetilde{i}_t = \widetilde{\sigma}_i (\widetilde{x}_t \widetilde{W}_{xi} + \widetilde{h}_{t-1} \widetilde{W}_{hi} + \widetilde{b}_i) \\<br>\widetilde{f}_t = \widetilde{\sigma}_t (\widetilde{x}_t \widetilde{W}_{xf} + \widetilde{h}_{t-1} \widetilde{W}_{hf} + \widetilde{b}_i) \\<br>\widetilde{c}_t = \widetilde{f}_t \odot \widetilde{c}_{c-1} + \widetilde{\sigma}_c (\widetilde{x}_t \widetilde{W}_{xc} + \widetilde{h}_{t-1} \widetilde{W}_{hc} + \widetilde{b}_c) \\<br>\widetilde{o_t} = \widetilde{\sigma}_o (\widetilde{x}_t \widetilde{W}_{xo} + \widetilde{h}_{t-1} \widetilde{W}_{ho} + \widetilde{b}_o) \\<br>\widetilde{h}_t = \widetilde{o}_t \odot \widetilde{\sigma}_h(\widetilde{c}_t)<br>$$<br>ç°åœ¨ï¼Œå¤–éƒ¨ LSTM çš„å•å…ƒçŠ¶æ€æ›´æ–°æ–¹å¼ä¸º $ c_t = \tilde{h}_{t} $ ã€‚</p><h3 id="3-Experiments"><a href="#3-Experiments" class="headerlink" title="3. Experiments"></a>3. Experiments</h3><p>è§é™„ä»¶è®ºæ–‡[1]</p><h3 id="4-Conclusion"><a href="#4-Conclusion" class="headerlink" title="4. Conclusion"></a>4. Conclusion</h3><p>Nested LSTMï¼ˆNLSTMï¼‰æ˜¯LSTMæ¨¡å‹çš„ç®€å•æ‰©å±•ï¼Œé€šè¿‡åµŒå¥—æ¥å¢åŠ æ·±åº¦ï¼Œè€Œä¸æ˜¯é€šè¿‡å †å ã€‚ NLSTMçš„å†…éƒ¨å­˜å‚¨å™¨å•å…ƒå½¢æˆå†…éƒ¨å­˜å‚¨å™¨ï¼Œå…¶ä»…é€šè¿‡å¤–éƒ¨å­˜å‚¨å™¨å•å…ƒè¢«å…¶ä»–è®¡ç®—å…ƒä»¶è®¿é—®ï¼Œå®ç°äº†æ—¶é—´å±‚çº§çš„å½¢å¼ã€‚</p><p>è®ºæ–‡[1]çš„å®éªŒè¡¨æ˜ï¼Œåœ¨ç›¸ä¼¼çš„å‚æ•°è®¾ç½®ä¸‹ï¼ŒNested LSTM åœ¨å¤šç§å­—ç¬¦çº§è¯­è¨€å»ºæ¨¡ä»»åŠ¡ä¸­çš„è¡¨ç°éƒ½è¶…è¶Šäº†Stacked LSTMå’Œsingle-layer LSTMï¼Œå¹¶ä¸”å’ŒStacked LSTM çš„é«˜å±‚çº§å•å…ƒç›¸æ¯”ï¼ŒLSTM çš„å†…éƒ¨è®°å¿†å¯ä»¥å­¦ä¹ æ›´é•¿æœŸçš„ä¾èµ–å…³ç³»ã€‚</p><p><a href="https://github.com/hannw/nlstm" target="_blank" rel="noopener">NLSTMçš„Tensorflowå®ç°</a></p><p><a href="https://github.com/titu1994/Nested-LSTM" target="_blank" rel="noopener">NLSTMçš„Keraså®ç°</a></p><h2 id="Bibliographies"><a href="#Bibliographies" class="headerlink" title="Bibliographies"></a>Bibliographies</h2><p>ç¬”è®°å‚è€ƒï¼š<a href="http://www.sohu.com/a/220745456_390227ï¼Œhttp://posts.careerengine.us/p/5a768ab3381fe136215b3de5?from=latest-posts-panel&amp;type=title" target="_blank" rel="noopener">http://www.sohu.com/a/220745456_390227ï¼Œhttp://posts.careerengine.us/p/5a768ab3381fe136215b3de5?from=latest-posts-panel&amp;type=title</a></p><p>[1] Moniz, Joel Ruben Antony, and David Krueger. â€œNested LSTMs.â€ <em>Asian Conference on Machine Learning</em>. 2017.</p><p>[2] Hochreiter, Sepp, and JÃ¼rgen Schmidhuber. â€œLong short-term memory.â€ <em>Neural computation</em> 9.8 (1997): 1735-1780.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h2 id=&quot;Nested-LSTMs&quot;&gt;&lt;a href=&quot;#Nested-LS
      
    
    </summary>
    
      <category term="research" scheme="https://juewang.me/categories/research/"/>
    
    
      <category term="LSTM" scheme="https://juewang.me/tags/LSTM/"/>
    
      <category term="RNN" scheme="https://juewang.me/tags/RNN/"/>
    
  </entry>
  
  <entry>
    <title>A convolution BiLSTM neural network model for chinese event extraction ç¬”è®°</title>
    <link href="https://juewang.me/posts/%5B2018.1.29%5DA-convolution%20BiLSTM-neural-network-model-for-chinese-event-extraction/"/>
    <id>https://juewang.me/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/</id>
    <published>2018-01-29T00:00:00.000Z</published>
    <updated>2018-03-12T20:22:36.989Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2 id="A-convolution-BiLSTM-neural-network-model-for-chinese-event-extraction"><a href="#A-convolution-BiLSTM-neural-network-model-for-chinese-event-extraction" class="headerlink" title="A convolution BiLSTM neural network model for chinese event extraction"></a>A convolution BiLSTM neural network model for chinese event extraction</h2><p><strong>æ‘˜è¦ï¼š</strong>ä¸­æ–‡äº‹ä»¶æå–æ˜¯ä¿¡æ¯æŠ½å–ä¸­çš„ä¸€é¡¹å…·æœ‰æŒ‘æˆ˜æ€§çš„ä»»åŠ¡ï¼Œä»¥å‰çš„æ–¹æ³•é«˜åº¦ä¾èµ–äºå¤æ‚çš„ç‰¹å¾å·¥ç¨‹å’Œå¤æ‚çš„è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰å·¥å…·ã€‚ åœ¨æ–‡çŒ®[1]ä¸­ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆLSTMå’ŒCNNçš„å·ç§¯åŒå‘LSTMç¥ç»ç½‘ç»œæ¥æ•è·å¥çº§å’Œè¯æ±‡ä¿¡æ¯ã€‚æœ€ç»ˆçš„æµ‹è¯•ä¸­è¾¾åˆ°ç›¸å½“ä¸é”™çš„æ°´å¹³ã€‚</p><h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h3><p>åœ¨äº‹ä»¶æå–ä¸­ï¼Œæˆ‘ä»¬éœ€è¦æå–äº‹ä»¶ç±»åˆ«ã€å‚ä¸è€…å’Œå…¶ä»–å±æ€§ï¼ˆæ—¶é—´ã€åœ°ç‚¹ç­‰ï¼‰ã€‚æ ¹æ®Automatic Content Extractionï¼ˆACEï¼‰å®šä¹‰çš„äº‹ä»¶æŠ½å–ä»»åŠ¡ï¼Œæˆ‘ä»¬å®šä¹‰ï¼š</p><ul><li>è§¦å‘è¯ï¼šæœ€ä¸»è¦çš„ã€ç”¨äºè¡¨è¾¾ä¸€ä¸ªäº‹ä»¶çš„è¯ï¼Œé€šå¸¸æ˜¯å¥å­çš„è°“è¯­ã€‚</li><li>äº‹ä»¶å±æ€§ï¼šå®ä½“ã€çŸ­è¯­æˆ–æ•°å€¼ã€‚åœ¨ä¸€ä¸ªäº‹ä»¶ä¸­æ‰®æ¼”ç‰¹å®šä½œç”¨ã€‚</li></ul><p>å› æ­¤ï¼Œæˆ‘ä»¬æŠŠäº‹ä»¶æŠ½å–åˆ†ä¸ºä¸¤æ­¥ï¼Œå³<strong>è§¦å‘è¯æ ‡æ³¨</strong>å’Œ<strong>äº‹ä»¶å±æ€§æ ‡æ³¨</strong>ã€‚ä¾‹å¦‚ï¼š</p><p>S1ï¼šIntelåœ¨ä¸­å›½<strong>æˆç«‹</strong>äº†ç ”ç©¶ä¸­å¿ƒã€‚</p><p>å…¶ä¸­ï¼Œâ€œæˆç«‹â€è¡¨æ˜è¯¥å¥å­è¡¨è¾¾äº†ä¸€ä¸ªå•†ä¸šäº‹ä»¶ï¼›Intelã€ä¸­å›½ã€ç ”ç©¶ä¸­å¿ƒåˆ™æ˜¯äº‹ä»¶çš„å±æ€§ï¼Œå±æ€§å°†è¢«æ ‡æ³¨ä¸ºå‚ä¸è€…ã€åœ°ç‚¹ã€æ—¶é—´ç­‰ã€‚</p><p>ç›®å‰çš„ state-of-the-art [2-4] é€šå¸¸å¾ˆä¾èµ–äºç‰¹å¾çš„é€‰æ‹©ã€‚è¿™äº›ç‰¹å¾é€šå¸¸å¯ä»¥è¢«åˆ’åˆ†ä¸º<strong>è¯­ä¹‰ç‰¹å¾</strong>å’Œ<strong>ç»“æ„ç‰¹å¾</strong>ã€‚å†ç»™ä¸¤ä¸ªåŒ…å«â€æˆç«‹â€œçš„ä¾‹å­ï¼Œä½†å®ƒåœ¨å…¶ä¸­å¹¶ä¸è¡¨è¾¾ä¸€ä¸ªå•†ä¸šäº‹ä»¶ã€‚</p><p>S2ï¼šå®ƒ<strong>æˆç«‹</strong>äº1994å¹´ï¼Œç°åœ¨æ˜¯ä¸€æ”¯æ·±å—æ¬¢è¿çš„æ‘‡æ»šä¹é˜Ÿã€‚</p><p>S3ï¼šåŒ»é™¢å·²<strong>æˆç«‹</strong>æ•‘æ´ä¸­å¿ƒã€‚</p><p>ä»ç»“æ„ç‰¹å¾ä¸Šæ¥çœ‹ï¼ŒS2å¯ä»¥è¢«ç¼©å†™ä¸ºâ€œå®ƒæ˜¯ä¹é˜Ÿâ€ï¼Œå› æ­¤â€œæˆç«‹â€åœ¨è¿™ä¸ªå¥å­ä¸­ä¸æ˜¯ä¸€ä¸ªè§¦å‘è¯ï¼Œè¿™ä¸ªå¥å­ä¸æ˜¯ä¸€ä¸ªäº‹ä»¶ã€‚</p><p>ä»è¯­ä¹‰ç‰¹å¾ä¸Šæ¥çœ‹ï¼ŒS3ä¸­çš„â€œæ•‘æ´ä¸­å¿ƒâ€çš„è¯­ä¹‰ä¸Šçœ‹ï¼Œè¿™ä¸ªäº‹ä»¶ä¸æ˜¯ä¸€ä¸ªå•†ä¸šè¡Œä¸ºï¼Œå› æ­¤â€œæˆç«‹â€ä¸è¡¨è¾¾ä¸€ä¸ªå•†ä¸šäº‹ä»¶ã€‚</p><p>ä¼ ç»Ÿçš„æ–¹æ³•[2, 3]é€šå¸¸ä¾èµ–äºå¤§é‡çš„NLPå·¥å…·ï¼Œå¯¹äºè¯­ä¹‰ç‰¹å¾è€Œè¨€ï¼Œæœ‰è¯æ€§æ ‡æ³¨ã€å‘½åå®ä½“è¯†åˆ«ç­‰ï¼›å¯¹äºç»“æ„ç‰¹å¾è€Œè¨€ï¼Œæœ‰ä¾å­˜å…³ç³»åˆ†æã€‚å°½ç®¡æœ€ç»ˆæ•ˆæœå¾ˆå¥½ï¼Œä½†æ˜¯è¿™éœ€è¦å¤§é‡çš„äººå·¥ç‰¹å¾ï¼Œå¹¶ä¸”éœ€è¦å¿å—ä¼ é€’è¯¯å·®ã€‚</p><p>Chen et al. [5] æå‡ºäº†ä¸€ä¸ªç”¨äºå®Œæˆäº‹ä»¶æŠ½å–çš„å·ç§¯ç¥ç»ç½‘ç»œã€‚å—æ­¤æ¿€å‘ï¼Œæœ¬æ–‡æå‡ºä¸€ä¸ªå·ç§¯åŒå‘LSTMç¥ç»ç½‘ç»œï¼Œç”¨æ¥åŒæ—¶æ•è·è¯­ä¹‰ç‰¹å¾å’Œç»“æ„ç‰¹å¾ã€‚æˆ‘ä»¬é¦–å…ˆä½¿ç”¨åŒå‘LSTMå°†æ•´ä¸ªå¥å­ä¸­çš„å•è¯çš„è¯­ä¹‰ç¼–ç æˆå¥å­çº§åˆ«çš„ç‰¹å¾ã€‚ ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥åˆ©ç”¨å·ç§¯ç¥ç»ç½‘ç»œæ¥æ•è·çªå‡ºçš„å±€éƒ¨è¯æ±‡ç‰¹å¾ï¼Œä»¥ä¾¿åœ¨æ²¡æœ‰ä»»ä½•POSæ ‡ç­¾æˆ–NERå¸®åŠ©çš„æƒ…å†µä¸‹è¿›è¡Œè§¦å‘è¯æ¶ˆæ­§ã€‚</p><h3 id="2-Trigger-Labeling"><a href="#2-Trigger-Labeling" class="headerlink" title="2. Trigger Labeling"></a>2. Trigger Labeling</h3><h4 id="2-1-Language-Specific-Issues"><a href="#2-1-Language-Specific-Issues" class="headerlink" title="2.1 Language Specific Issues"></a>2.1 Language Specific Issues</h4><p>ç”±äºä¸­æ–‡çš„ç‰¹æ®Šæ€§ï¼Œè§¦å‘è¯å¯ä»¥è¢«åˆ†ä¸ºä¸¤ç±»ï¼š</p><ul><li>å¤šè¯è§¦å‘è¯ï¼šä»»ä½•æ‹†å¼€åå°±æ— æ³•è¢«äººä¸ºæ˜¯è§¦å‘è¯çš„ï¼Œæˆ‘ä»¬æŠŠå®ƒç»„åˆèµ·æ¥è®¤ä¸ºæ˜¯è§¦å‘è¯ã€‚ä¾‹å¦‚â€œçŠ¯ç½ªå«Œç–‘äººéƒ½è½å…¥æ³•ç½‘â€ï¼Œå…¶ä¸­â€œè½å…¥æ³•ç½‘â€è¢«è®¤ä¸ºæ˜¯è§¦å‘è¯ã€‚</li><li>å•è¯è§¦å‘è¯ï¼šå¾€å¾€æ˜¯è°“è¯­ï¼Œä½†ä¹Ÿå¯ä»¥æ˜¯ç»„åˆè¯ä¸­çš„ä¸€éƒ¨åˆ†ã€‚ä¾‹å¦‚â€œè­¦å¯Ÿå‡»æ¯™äº†ä¸€åæ­¹å¾’â€ä¸­çš„â€œå‡»æ¯™â€ï¼Œâ€œè¿™æ˜¯ä¸€ä»¶é¢„è°‹çš„å‡¶æ€æ¡ˆâ€ä¸­çš„â€œå‡¶æ€â€</li></ul><p>ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å°†äº‹ä»¶æ£€æµ‹è§†ä¸ºåºåˆ—æ ‡è®°ä»»åŠ¡è€Œä¸æ˜¯åˆ†ç±»ä»»åŠ¡ã€‚ é‡‡ç”¨BIOæ–¹æ¡ˆï¼Œå…¶ä¸­æ ‡è®°Bæ˜¯äº‹ä»¶è§¦å‘è¯çš„å¼€å§‹ï¼ŒIå‹æ˜¯åœ¨è§¦å‘è¯å†…ï¼Œå¦åˆ™æ ‡è®°ä¸ºOã€‚æˆ‘ä»¬åˆ©ç”¨å·ç§¯åŒå‘LSTMç¥ç»ç½‘ç»œæ¥å®Œæˆè¿™ä¸ªä»»åŠ¡ã€‚</p><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-03-12-202231.jpg" alt="trigger-labeling"></p><p>æˆ‘ä»¬åŸºäºå•è¯æ¨¡å‹çš„ä¸»è¦æ¶æ„ã€‚ ï¼ˆaï¼‰ä¸­çš„æ¯ä¸ªè¯wtçš„å±€éƒ¨ä¸Šä¸‹æ–‡ç‰¹å¾ctï¼ˆç°è‰²çŸ©å½¢ï¼‰ç”±CNNè®¡ç®—ï¼ˆbï¼‰æ‰€ç¤ºã€‚ æˆ‘ä»¬çš„å·ç§¯ç¥ç»ç½‘ç»œå­¦ä¹ äº†å…³äºä¸­å¿ƒè¯â€œè½å…¥â€çš„æœ¬åœ°ä¸Šä¸‹æ–‡ä¿¡æ¯çš„è¡¨ç¤ºã€‚ è¿™é‡Œçš„ä¸Šä¸‹æ–‡å¤§å°æ˜¯7ï¼ˆä¸­å¿ƒè¯çš„å·¦å³å„3ä¸ªè¯ï¼‰ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªå¤§å°ä¸º4çš„å†…æ ¸ä¸ä¸¤ä¸ªç‰¹å¾æ˜ å°„ã€‚ ï¼ˆbï¼‰å¥å­ä¸­çš„ç¬¦å·Pè¡¨ç¤ºå¡«å……è¯ã€‚</p><h4 id="2-2-Word-Based-Method"><a href="#2-2-Word-Based-Method" class="headerlink" title="2.2 Word-Based Method"></a>2.2 Word-Based Method</h4><p><strong>LSTM Network</strong>  åœ¨nlpä»»åŠ¡ä¸­LSTMç›¸å¯¹å¸¸ç”¨ï¼Œç‰¹åˆ«çš„ï¼ŒåŒå‘LSTMèƒ½å¤Ÿè”ç³»å†å²å’Œæœªæ¥çš„ä¿¡æ¯ï¼Œèƒ½å¤Ÿé‡å¤åˆ©ç”¨å¥å­ä¿¡æ¯ï¼Œæœ‰åˆ©äºæˆ‘ä»¬è¿›è¡Œåˆ¤æ–­ã€‚å› ä¸ºä¹‹å‰çš„æŠ¥å‘Šå·²ç»å™è¿°è¿‡ï¼Œæ•…è¿™é‡Œç•¥å†™ã€‚</p><p><strong>CNN</strong>  å·ç§¯ç¥ç»ç½‘ç»œæœ€ä¸€å¼€å§‹ç”¨äºå›¾åƒé¢†åŸŸï¼Œè¿‘å¹´ä¹Ÿåœ¨nlpé¢†åŸŸå¤§æ”¾å…‰å½©ã€‚è¿™é‡Œï¼Œæˆ‘ä»¬é‡‡ç”¨å·ç§¯ç¥ç»ç½‘ç»œæ¥æå–å¥å­ä¸­æ¯ä¸ªå•è¯çš„å±€éƒ¨ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚</p><p>ç»™å®šä¸€ä¸ªåŒ…å«nä¸ªå•è¯{w1, w2, â€¦ , wn}çš„å¥å­å’Œå½“å‰ä¸­å¿ƒè¯wtï¼Œå·ç§¯è¿ç®—åŒ…å«ä¸€ä¸ªå†…æ ¸ï¼Œå°†å…¶åº”ç”¨äºwtå‘¨å›´çš„å•è¯ä»¥ç”Ÿæˆç‰¹å¾æ˜ å°„ã€‚ æˆ‘ä»¬å¯ä»¥åˆ©ç”¨ä¸åŒå®½åº¦çš„å¤šä¸ªå†…æ ¸æ¥æå–ä¸åŒç²’åº¦çš„å±€éƒ¨ç‰¹å¾ã€‚ ç„¶ååœ¨æ¯ä¸ªmapä¸Šæ‰§è¡Œæœ€å¤§æ±‡é›†ï¼Œä»¥ä¾¿ä»…è®°å½•æ¯ä¸ªç‰¹å¾åœ°å›¾çš„æœ€å¤§æ•°é‡ã€‚ æ± çš„ä¸€ä¸ªç‰¹æ€§æ˜¯å®ƒäº§ç”Ÿä¸€ä¸ªå›ºå®šå¤§å°çš„è¾“å‡ºå‘é‡ï¼Œè¿™ä½¿æˆ‘ä»¬èƒ½å¤Ÿåº”ç”¨ä¸åŒçš„å¤§å°å†…æ ¸ã€‚ è€Œé€šè¿‡æ‰§è¡Œæœ€å¤§æ“ä½œï¼Œæˆ‘ä»¬ä¿æŒæœ€æ˜¾ç€çš„ä¿¡æ¯ã€‚ æœ€åï¼Œå°†å›ºå®šé•¿åº¦çš„è¾“å‡ºå‘é‡cwtä½œä¸ºå…³äºä¸­å¿ƒè¯wtçš„æœ¬åœ°ä¸Šä¸‹æ–‡ä¿¡æ¯çš„è¡¨ç¤ºã€‚</p><p>åœ¨æˆ‘ä»¬çš„å®ç°ä¸­ï¼Œæ»‘åŠ¨çª—å£å¤§å°ä¸º7ï¼ˆä¸­å¿ƒè¯çš„å·¦å³å„3ä¸ªè¯ï¼‰ï¼Œå¹¶ä¸”æˆ‘ä»¬ä½¿ç”¨ä¸åŒçš„å†…æ ¸æ¥æ•è·å„ç§ç²’åº¦çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚</p><p><strong>Output Layer</strong>  æˆ‘ä»¬å°†BiLSTMçš„éšè—çŠ¶æ€ä¸CNNåœ¨æ¯ä¸ªæ—¶é—´æ­¥tæå–çš„ä¸Šä¸‹æ–‡ç‰¹å¾cwtè¿æ¥èµ·æ¥ã€‚ ç„¶å[ht; cwt]è¢«é€å…¥softmaxå±‚ä»¥äº§ç”Ÿwtçš„æ¯ä¸ªæ ‡è®°çš„å¯¹æ•°æ¦‚ç‡ã€‚<br>ç„¶è€Œï¼ŒåŸºäºå•è¯çš„æ–¹æ³•ä»ç„¶ä¸èƒ½è§£å†³å†…éƒ¨è¯è§¦å‘å¼•èµ·çš„ä¸€è‡´æ€§é—®é¢˜ï¼Œå³æ— æ³•è¯†åˆ«é•¿è¯å†…éƒ¨çš„è§¦å‘è¯ã€‚</p><h4 id="2-3-Character-Based-Method"><a href="#2-3-Character-Based-Method" class="headerlink" title="2.3 Character-Based Method"></a>2.3 Character-Based Method</h4><p>ä¸ºäº†è§£å†³ä¸€è‡´æ€§é—®é¢˜ï¼Œæˆ‘ä»¬å¯ä»¥é‡‡ç”¨Character-embeddingï¼Œå”¯ä¸€çš„åŒºåˆ«å°±åœ¨input layerã€‚</p><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-03-12-202234.jpg" alt="character"></p><h3 id="3-Argument-Labeling"><a href="#3-Argument-Labeling" class="headerlink" title="3. Argument Labeling"></a>3. Argument Labeling</h3><p>ä¸Šé¢ä»‹ç»çš„è§¦å‘è¯æ ‡æ³¨æ¨¡å‹ä¾ç„¶å¯ä»¥è¢«æ²¿ç”¨ï¼Œæˆ‘ä»¬å°†ä»‹ç»ç”¨äºè§¦å‘è¯æ ‡æ³¨å’Œäº‹ä»¶å±æ€§æ ‡æ³¨çš„æ¨¡å‹ä¹‹é—´çš„ä¸»è¦åŒºåˆ«ã€‚</p><h4 id="3-1-Input-Layer"><a href="#3-1-Input-Layer" class="headerlink" title="3.1 Input Layer"></a>3.1 Input Layer</h4><p>ä½œä¸ºä¸€ä¸ªpipelineç³»ç»Ÿï¼Œé™¤äº†word embeddingsä¹‹å¤–ï¼Œè¿˜å¯ä»¥ä½¿ç”¨ä»ä¸Šé¢è§¦å‘è¯æ ‡è®°ä»»åŠ¡ä¸­æå–çš„ä¿¡æ¯ã€‚ å› æ­¤ï¼Œæˆ‘ä»¬æå‡ºäº†å¦å¤–å››ç§ç±»å‹çš„ç‰¹å¾embeddingæ¥å½¢æˆBiLSTMå’ŒCNNçš„è¾“å…¥å±‚ã€‚</p><ul><li>è§¦å‘ä½ç½®ç‰¹å¾ï¼šä¸€ä¸ªå•è¯æ˜¯å¦å±äºè§¦å‘è¯çš„ä¸€éƒ¨åˆ†</li><li>è§¦å‘ç±»å‹ç‰¹å¾ï¼šå•è¯è§¦å‘ç±»å‹ï¼ŒNONEç±»å‹å¯¹äºéè§¦å‘è¯</li><li>å®ä½“ä½ç½®ç‰¹å¾ï¼šä¸€ä¸ªå•è¯æ˜¯å¦å±äºå®ä½“çš„ä¸€éƒ¨åˆ†</li><li>å®ä½“ç±»å‹ç‰¹å¾ï¼šå•è¯çš„å®ä½“ç±»å‹ï¼ŒNONEç±»å‹å¯¹äºéå®ä½“ã€‚ ACEæ•°æ®é›†æä¾›äº†å®ä½“è¯†åˆ«çš„ç»“æœï¼Œæ— éœ€ä½¿ç”¨å¤–éƒ¨NLPå·¥å…·ã€‚ï¼ˆ<em>æ€è€ƒ</em>ï¼šè‹¥æ•°æ®é›†ä¸æä¾›å®ä½“ä¿¡æ¯ï¼Œä¸¤ç§è§£å†³æ–¹æ³•ï¼š1. ä¸embedå®ä½“ç‰¹å¾ï¼›2. å€ŸåŠ©å¤–éƒ¨å·¥å…·ï¼‰<br>ç„¶åï¼Œæˆ‘ä»¬é€šè¿‡æŸ¥è¡¨å°†è¿™äº›ç‰¹å¾è½¬æ¢æˆçŸ¢é‡ï¼Œå¹¶å°†å®ƒä»¬ä¸åŸå§‹å•è¯åµŒå…¥çº§è”ï¼Œä½œä¸ºBiLSTMå’ŒCNNçš„æœ€ç»ˆè¾“å…¥å±‚ã€‚</li></ul><h4 id="3-2-Output-Layer"><a href="#3-2-Output-Layer" class="headerlink" title="3.2 Output Layer"></a>3.2 Output Layer</h4><p>å€¼å¾—ä¸€æçš„æ˜¯ï¼Œäº‹ä»¶å±æ€§æ ‡æ³¨ä¸å†æ˜¯ä¸€ä¸ªåºåˆ—æ ‡æ³¨ä»»åŠ¡ï¼Œè€Œæ˜¯ä¸€ä¸ªåˆ†ç±»ä»»åŠ¡ã€‚ ACEæ•°æ®é›†æä¾›äº†å®ä½“è¯†åˆ«çš„ç»“æœï¼Œå®ƒä¿è¯äº†äº‹ä»¶å±æ€§åªèƒ½å‡ºç°åœ¨è¿™äº›å®ä½“ã€‚ å› æ­¤ï¼Œæˆ‘ä»¬åªéœ€è¦é¢„æµ‹æ ‡è®°å®ä½“çš„è§’è‰²ï¼Œè€Œä¸æ˜¯æ•´ä¸ªå¥å­ä¸­çš„æ¯ä¸ªå•è¯ã€‚ ä¾‹å¦‚ï¼ŒS4ä¸­æœ‰ä¸‰ä¸ªè§¦å‘å™¨ï¼ˆç²—ä½“å­—ï¼‰å’Œä¸‰ä¸ªå®ä½“ï¼ˆæ–œä½“å­—ï¼‰ï¼Œå®ƒä»¬å…±åŒç»„æˆä¹å¯¹è¦åˆ†ç±»çš„è§¦å‘è¯å’Œäº‹ä»¶å±æ€§å€™é€‰ã€‚</p><p>S7ï¼šå…­èµ·<strong>è°‹æ€æ¡ˆ</strong>å‘ç”Ÿåœ¨<em>æ³•å›½</em>ï¼ŒåŒ…æ‹¬<em>Bob</em>çš„<strong>æš—æ€</strong>å’Œ<em>Joe</em>çš„<strong>æ€å®³</strong>ã€‚</p><p>æˆ‘ä»¬ä¿®æ”¹CNNå’ŒBiLSTMç½‘ç»œçš„è¾“å‡ºå±‚ä»¥é€‚åº”æ–°çš„ä»»åŠ¡ã€‚</p><p>å¯¹äºBiLSTMï¼Œæˆ‘ä»¬ä»ç„¶è¯•å›¾åˆ©ç”¨å…¶è®°å¿†é•¿åºåˆ—çš„èƒ½åŠ›ï¼Œæ‰€ä»¥æˆ‘ä»¬æŠŠæœ€åä¸€ä¸ªå•è¯hNçš„éšè—çŠ¶æ€è§†ä¸ºå¥å­ä¿¡æ¯ã€‚</p><p>å¯¹äºCNNï¼Œæˆ‘ä»¬æŠŠæ•´ä¸ªå¥å­çš„æ‰€æœ‰å•è¯ä½œä¸ºä¸Šä¸‹æ–‡ï¼Œè€Œä¸æ˜¯æ¯ä¸ªä¸­å¿ƒå•è¯çš„æµ…çª—å£ã€‚ æœ€åï¼Œæˆ‘ä»¬å°†æ¥è‡ªä¸¤ä¸ªç½‘ç»œçš„è¾“å‡ºå‘é‡çš„ä¸²è”è¾“å…¥åˆ°softmaxåˆ†ç±»å™¨ä¸­ï¼Œå°±åƒå¤„ç†ä¹‹å‰çš„è§¦å‘è¯æ ‡æ³¨ä»»åŠ¡ä¸€æ ·ã€‚</p><h3 id="4-Conclusion"><a href="#4-Conclusion" class="headerlink" title="4. Conclusion"></a>4. Conclusion</h3><p>è®ºæ–‡[1]ä¸»è¦æå‡ºäº†å·ç§¯åŒå‘LSTMç¥ç»ç½‘ç»œï¼Œç”¨ä»¥å®Œæˆä¸­æ–‡äº‹ä»¶æŠ½å–ä»»åŠ¡ï¼Œåœ¨ACE 2005æ•°æ®é›†ä¸Šè·å¾—äº†ä¸é”™çš„ç»“æœã€‚æˆ‘åœ¨æš‘å‡æ—¶ï¼Œå°†äº‹ä»¶æŠ½å–è®¤ä¸ºä¸ºä¸€ä¸ªåºåˆ—æ ‡æ³¨ä»»åŠ¡ï¼Œä½¿ç”¨BiLSTM+CRFï¼›ç›¸æ¯”è€Œè¨€ï¼Œè®ºæ–‡[1]çš„æ¨¡å‹è€ƒè™‘æ›´å…¨é¢ï¼Œå¹¶å……åˆ†åˆ©ç”¨å·²çŸ¥çš„å®ä½“ä¿¡æ¯ã€‚ä¸è¿‡å¯¹äºç°å®é—®é¢˜è€Œè¨€ï¼Œæ ‡æ³¨å®ä½“ä¿¡æ¯çš„æˆæœ¬ä¹Ÿå¾ˆé«˜ï¼Œæ•…åœ¨æ²¡æœ‰å®ä½“æ ‡æ³¨çš„æƒ…å†µä¸‹ä¿æŒæ€§èƒ½ä¹Ÿæ˜¯ä¸€ä¸ªéš¾ç‚¹ã€‚</p><h2 id="Bibliography"><a href="#Bibliography" class="headerlink" title="Bibliography"></a>Bibliography</h2><p>[1] Zeng, Y., Yang, H., Feng, Y., Wang, Z., &amp; Zhao, D. (2016). A convolution BiLSTM neural network model for Chinese event extraction. In <em>Natural Language Understanding and Intelligent Applications</em> (pp. 275-287). Springer, Cham.</p><p>[2] Chen, C., Ng, V.: Joint modeling for Chinese event extraction with rich linguistic features. In: COLING, pp. 529â€“544. Citeseer (2012)</p><p>[3] Chen, Y., Xu, L., Liu, K., Zeng, D., Zhao, J.: Event extraction via dynamic multipooling convolutional neural networks. In: Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, vol. 1, pp. 167â€“176 (2015)</p><p>[4] Li, Q., Ji, H., Huang, L.: Joint event extraction via structured prediction with global features. In: ACL (1), pp. 73â€“82 (2013)</p><p>[5] Chen, Y., Xu, L., Liu, K., Zeng, D., Zhao, J.: Event extraction via dynamic multipooling convolutional neural networks. In: Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, vol. 1, pp. 167â€“176 (2015)</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h2 id=&quot;A-convolution-BiLSTM-neural-netwo
      
    
    </summary>
    
      <category term="research" scheme="https://juewang.me/categories/research/"/>
    
    
      <category term="convolution" scheme="https://juewang.me/tags/convolution/"/>
    
      <category term="BiLSTM" scheme="https://juewang.me/tags/BiLSTM/"/>
    
      <category term="event-extraction" scheme="https://juewang.me/tags/event-extraction/"/>
    
  </entry>
  
  <entry>
    <title>Event detection and co-reference with minimal supervision ç¬”è®°</title>
    <link href="https://juewang.me/posts/%5B2018.1.21%5DEvent-detection-and-co-referentce/"/>
    <id>https://juewang.me/posts/[2018.1.21]Event-detection-and-co-referentce/</id>
    <published>2018-01-21T00:00:00.000Z</published>
    <updated>2018-03-12T20:22:21.147Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2 id="Event-detection-and-co-reference-with-minimal-supervision-1"><a href="#Event-detection-and-co-reference-with-minimal-supervision-1" class="headerlink" title="Event detection and co-reference with minimal supervision [1]"></a>Event detection and co-reference with minimal supervision [1]</h2><p><strong>æ‘˜è¦ï¼š</strong>è¯¥è®ºæ–‡ä½¿ç”¨äº†ä¸€ç§å¼±ç›‘ç£çš„ç®—æ³•è§£å†³äº†äº‹ä»¶æ£€æµ‹ä¸å…±æŒ‡é—®é¢˜ã€‚äº‹ä»¶å…±æŒ‡é—®é¢˜å¯ä»¥çœ‹ä½œæ˜¯ä¸€ç§äº‹ä»¶ä¹‹é—´çš„ç›¸ä¼¼åº¦è®¡ç®—é—®é¢˜ï¼Œè€Œåœ¨è¯¥æ–‡ä¸­ï¼Œäº‹ä»¶æ£€æµ‹é—®é¢˜ä¹Ÿè¢«çœ‹ä½œæ˜¯ä¸€ç§ç›¸ä¼¼åº¦æ£€æµ‹é—®é¢˜ã€‚å¯¹äºACEæˆ–rich EREåˆ’åˆ†çš„æ‰€æœ‰äº‹ä»¶ç±»å‹ï¼Œä½¿ç”¨æ¯ä¸ªç±»å‹ä¸­çš„å‡ ä¸ªå®ä¾‹ä½œä¸ºè¯¥ç±»å‹äº‹ä»¶çš„å‘é‡ï¼Œç„¶åè®¡ç®—æ–°äº‹ä»¶å‘é‡ä¸æ¯ä¸ªç±»å‹äº‹ä»¶å‘é‡ä¹‹é—´çš„ç›¸ä¼¼åº¦ï¼Œæ ¹æ®è¿™ä¸€ç›¸ä¼¼åº¦å¯¹äº‹ä»¶è¿›è¡Œåˆ¤æ–­ã€‚è¯¥æ–‡çš„å¦ä¸€ä¸ªç‰¹ç‚¹åœ¨äºäº‹ä»¶ç‰¹å¾çš„é€‰æ‹©ï¼Œåœ¨å°†äº‹ä»¶è¡¨ç¤ºä¸ºå‘é‡çš„è¿‡ç¨‹ä¸­ï¼Œä½¿ç”¨äº†Freebaseä½œä¸ºç‰¹å¾æ¥å¯¹äº‹ä»¶è¿›è¡Œè¡¨ç¤ºã€‚</p><h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h3><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-03-12-202215.jpg" width="70%"></p><p>ä¸Šå›¾æ˜¯è®ºæ–‡æå‡ºçš„MSEPï¼ˆMinimally Supervised Event Pipelineï¼‰æ¡†æ¶ã€‚è¿™é‡Œ Event examples æ˜¯å”¯ä¸€çš„ç›‘ç£æ¥æºï¼Œç”¨äºäº§ç”Ÿ Example vectorsã€‚åœ¨MSEPæ¡†æ¶ä¸­ä¸éœ€è¦è®­ç»ƒã€‚</p><p>è¿™ç¯‡è®ºæ–‡ä¸»è¦æ˜¯é’ˆå¯¹ä¸¤ä¸ªé—®é¢˜ï¼š</p><ul><li>Event detection æŒ‡çš„æ˜¯å¯¹ä¸€æ®µæ–‡æœ¬å†…å®¹ï¼Œæ£€æµ‹æ˜¯å¦å­˜åœ¨ç¬¦åˆè¦æ±‚çš„äº‹ä»¶ã€‚</li><li>Co-reference problem. ä¸ºäº†æ›´å¥½çš„ç†è§£å’Œåˆ©ç”¨äº‹ä»¶çš„ä¿¡æ¯ï¼Œæˆ‘ä»¬éœ€è¦ä»æ–‡æœ¬ä¸­æå–å‡ºæ—¶é—´ã€åœ°ç‚¹ã€äººç‰©ã€è¡Œä¸ºç­‰ä¿¡æ¯ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜éœ€è¦äº†è§£ä¸¤ä¸ªäº‹ä»¶çš„å…³ç³»ï¼Œä¾‹å¦‚ï¼Œåˆ¤æ–­ä¸¤ä¸ªäº‹ä»¶æ˜¯å¦è¡¨ç¤ºåŒä¸€ä¸ªäº‹ä»¶ï¼Œè¿™å°±æ˜¯Co-reference problemã€‚</li></ul><p>åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§æ›´åŠ å¯è¡Œä¸”æ›´åŠ å¯æµ‹çš„æ–¹æ³•æ¥æè¿°äº‹ä»¶ã€‚å¯¹äºä¸€ä¸ªäº‹ä»¶eï¼Œevent detection æ‰€è¦åšçš„å°±æ˜¯åˆ¤æ–­æ˜¯å¦å­˜åœ¨ä¸€ä¸ªäº‹ä»¶é›†åˆï¼Œäº‹ä»¶eåœ¨è¯­ä¹‰ä¸Šæ˜¯å¦æœ‰å…³è”ï¼Œä»¥è‡³äºå¯ä»¥è¢«åˆ’åˆ†åˆ°è¯¥é›†åˆå†…ï¼›è€Œ co-reference problem åˆ™æ˜¯åˆ¤æ–­ä¸¤ä¸ªäº‹ä»¶e1ã€e2æ˜¯å¦åœ¨è¯­ä¹‰ä¸Šè¡¨è¿°è¶³å¤Ÿæ¥è¿‘ï¼Œä»¥è‡³äºæˆ‘ä»¬è®¤ä¸ºå®ƒä»¬æ‰€è¡¨ç¤ºçš„å®é™…ä¸Šæ˜¯åŒä¸€ä¸ªäº‹ä»¶ã€‚å¯ä»¥çœ‹åˆ°ä¸¤ä¸ªä»»åŠ¡å®é™…ä¸Šéƒ½éœ€è¦åˆ¤æ–­ç›¸ä¼¼æ€§ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠå®ƒä»¬è½¬åŒ–ä¸ºè¯­ä¹‰ç›¸ä¼¼æ€§é—®é¢˜ã€‚</p><p>ç°åœ¨ä¸»è¦é—®é¢˜æœ‰ï¼š1. å¦‚ä½•è¡¨ç¤ºä¸€ä¸ªäº‹ä»¶ï¼›2. å¦‚ä½•è¡¨è¾¾ç›¸ä¼¼æ€§ã€‚å‰è€…æˆ‘ä»¬é‡‡ç”¨äº†semantic role labeling  representationï¼ˆSRLï¼‰ï¼Œæ¥ç»“æ„åŒ–åœ°æè¿°ä¸€ä¸ªäº‹ä»¶ï¼›å¯¹äºåè€…ï¼Œæˆ‘ä»¬å°†å¯¹äº‹ä»¶åšä¸€ä¸ªembeddingï¼Œé€šè¿‡è®¡ç®—å…¶ä½™å¼¦è·ç¦»æ¥è¡¨è¾¾ç›¸ä¼¼æ€§ã€‚</p><p>æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªé€šç”¨äº‹ä»¶æ£€æµ‹å’ŒæŒ‡ä»£æ¶ˆè§£æ¡†æ¶ï¼Œå®ƒåŸºæœ¬ä¸Šä¸éœ€è¦æ ‡è®°æ•°æ®ã€‚åœ¨å®è·µä¸­ï¼Œä¸ºäº†å°†ä¸€ä¸ªäº‹ä»¶ææ³•ï¼ˆevent mentionï¼‰å’Œä¸€ä¸ªäº‹ä»¶æœ¬ä½“ï¼ˆevent ontologyï¼‰ç›¸è”ç³»èµ·æ¥ï¼Œæˆ‘ä»¬åªéœ€è¦ä¸€äº›äº‹ä»¶ç¤ºä¾‹ã€‚è¿™ç§å®šä¹‰ç±»å‹çš„æ–¹å¼æ˜¯éå¸¸åˆç†çš„ï¼Œå› ä¸ºç»™å‡ºä¾‹å­æ˜¯å®šä¹‰äº‹ä»¶ç±»å‹çš„æœ€ç®€å•çš„æ–¹æ³•ã€‚æˆ‘ä»¬çš„æ–¹æ³•æ¯”æ ‡å‡†çš„æ— ç›‘ç£æ–¹æ³•è¦æ±‚æ›´å°‘å‡è®¾ï¼Œåœ¨æˆ‘ä»¬çš„æ¨¡å‹ä¸­ï¼Œç»™å®šäº‹ä»¶ç±»å‹çš„å®šä¹‰ï¼ˆä»¥äº‹ä»¶ä¾‹å­çš„å½¢å¼ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥å°†å•ä¸ªäº‹ä»¶åˆ†ç±»åˆ°å·²çŸ¥æœ¬ä½“ï¼Œå¹¶ç¡®å®šä¸¤ä¸ªäº‹ä»¶æ˜¯å¦æ˜¯ co-reference çš„ã€‚</p><h3 id="2-The-MSEP-System"><a href="#2-The-MSEP-System" class="headerlink" title="2. The MSEP System"></a>2. The MSEP System</h3><h4 id="2-1-Structured-Vector-Representation"><a href="#2-1-Structured-Vector-Representation" class="headerlink" title="2.1 Structured Vector Representation"></a>2.1 Structured Vector Representation</h4><p>äº‹ä»¶ç»“æ„å’Œå¥å­ç»“æ„ä¹‹é—´æœ‰ä¸€ä¸ªå¹³è¡Œå…³ç³»ã€‚æˆ‘ä»¬å‘ç°ä¸€èˆ¬æ¥è¯´ï¼Œäº‹ä»¶çš„è§¦å‘è¯å¾€å¾€æ˜¯è°“è¯­ï¼Œæ‰€ä»¥å¯ä»¥é’ˆå¯¹è°“è¯­å¯¹å…¶åšä¸€äº›æ”¹è¿›ï¼š</p><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-03-12-202214.jpg" alt="basic"></p><p><strong>Basic event vector representation</strong>ã€‚åŸºæœ¬äº‹ä»¶å‘é‡ç”±å®ƒçš„å„ä¸ªç»„æˆéƒ¨åˆ†ç»„æˆã€‚</p><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-03-12-202217.jpg" alt="basic"></p><p><strong>Augmented event vector representation</strong>ã€‚åœ¨è¿™é‡Œï¼Œâ€œ+â€ è¡¨ç¤ºæˆ‘ä»¬é¦–å…ˆå°†æ–‡æœ¬ç‰‡æ®µæ”¾åœ¨ä¸€èµ·ï¼Œç„¶åå°†ç»„åˆçš„æ–‡æœ¬ç‰‡æ®µè½¬æ¢æˆESAå‘é‡ã€‚</p><h4 id="2-2-Event-Mention-Detection"><a href="#2-2-Event-Mention-Detection" class="headerlink" title="2.2 Event Mention Detection"></a>2.2 Event Mention Detection</h4><p>æˆ‘ä»¬å®šä¹‰ Event type representation ä¸ºè¯¥ç±»åˆ«ä¸‹çš„äº‹ä»¶å‘é‡çš„å¹³å‡å€¼ã€‚</p><p>æˆ‘ä»¬å®šä¹‰å®šä¹‰ç›¸ä¼¼åº¦å¦‚ä¸‹<br>$$<br>S(e_1, e_2) = \frac{vec(e_1) Â· vec(e_2)}{||vec(e_1)||Â·||vec(e_2)||} \\<br>= \frac{\sum_a{vec(a_1) Â· vec(a_2)}}{\sqrt{\sum_a{||vec(a_1)||^2} Â· \sum_a{||vec(a_2)||^2}}}<br>$$<br>å…¶ä¸­ e1 æ˜¯å¾…å¤„ç†äº‹ä»¶ï¼Œe2 æ˜¯äº‹ä»¶çš„ç±»åˆ«ã€‚a å°±æ˜¯äº‹ä»¶é‡Œçš„å„ä¸ªç»„ä»¶ã€‚è‹¥é‡åˆ° a ç¼ºå¤±çš„æƒ…å†µï¼ˆå¦‚åœ°ç‚¹ã€æ—¶é—´ç­‰ï¼‰ï¼Œæˆ‘ä»¬ç”¨éç¼ºå¤±çš„éƒ¨åˆ†çš„å¹³å‡å€¼æ¥ä»£æ›¿å®ƒã€‚å…·ä½“çš„æ“ä½œæ–¹æ³•å‚è§åŸæ–‡ã€‚</p><h4 id="2-3-Event-co-reference"><a href="#2-3-Event-co-reference" class="headerlink" title="2.3 Event co-reference"></a>2.3 Event co-reference</h4><p>è¿™é‡Œå¦‚ä¸Šä¸€èŠ‚çš„å†…å®¹æ‰€è¯´ï¼Œé€šè¿‡ä½™å¼¦è·ç¦»$S(e_1, e_2)$æ¥è®¡ç®—ä¸¤ä¸ªäº‹ä»¶çš„ç›¸ä¼¼åº¦ã€‚</p><p>å¯¹äºæ¯ä¸€ä¸ªäº‹ä»¶ï¼Œæˆ‘ä»¬åˆ†åˆ«æ¯”è¾ƒ$agnet_{sub}, agnet_{obj}$ï¼Œè‹¥éƒ½ä¸ç›¸åŒï¼Œæˆ‘ä»¬è®¤ä¸ºå®ƒä»¬æ˜¯ç‹¬ç«‹çš„ï¼›å¦‚æœæœ‰ç¼ºå¤±ï¼Œæˆ‘ä»¬è®¤ä¸ºå®ƒå’Œä»»æ„å€¼åŒ¹é…ã€‚è¿™æ ·ï¼Œæˆ‘ä»¬å¯ä»¥å¾—åˆ°ä¸€ä¸ªä¸é‡å¤çš„äº‹ä»¶é›†åˆï¼Œ$Set_{conflict}$ã€‚</p><p>æ¥ä¸‹æ¥éå†æ‰€æœ‰äº‹ä»¶ï¼Œå¯¹äºäº‹ä»¶k+1ï¼Œ<br>$$<br>e_p = argmax_{e\in {e_1,â€¦,e_k} e \notin Set_{conflit}} {S(e_p, e_{k+1})}<br>$$<br>å¦‚æœ$S(e_p, e_{k+1})$çš„å€¼å¤§äºæˆ‘ä»¬è®¾å®šçš„é˜ˆå€¼ï¼Œæˆ‘ä»¬å°±è®¤ä¸ºå®ƒæ˜¯åŒä¸€ä¸ªäº‹ä»¶ï¼›å¦åˆ™ï¼Œæˆ‘ä»¬æŠŠä»–åˆ†ä¸ºä¸€ä¸ªæ–°çš„ç±»ã€‚</p><h3 id="3-Vector-Representation"><a href="#3-Vector-Representation" class="headerlink" title="3. Vector Representation"></a>3. Vector Representation</h3><p>æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå…¶å®æ–‡ç« ä¹‹å‰çš„å†…å®¹éƒ½ä¸ä¾èµ–äº embedding çš„å…·ä½“é€‰æ‹©ï¼Œäº‹å®ä¸Šï¼Œä½œè€…ä¹Ÿæµ‹è¯•äº†å¾ˆå¤šçš„æ–¹æ³•ï¼Œå¯ä»¥æ ¹æ®å®é™…æƒ…å†µæ¥é€‰æ‹©ã€‚</p><ul><li>Explicit Semantic Analysis</li><li>Brown Cluster</li><li>Word2Vec</li><li>Dependency-Based Embedding</li></ul><h3 id="4-Semantic-Role-Labeling"><a href="#4-Semantic-Role-Labeling" class="headerlink" title="4. Semantic Role Labeling"></a>4. Semantic Role Labeling</h3><p>ä¸Šé¢å·¥ä½œå»ºç«‹åœ¨å·²ç»å®Œæˆäº† Semantic Role Labeling çš„æƒ…å†µä¸‹ï¼Œè¿™é‡Œæˆ‘ä»¬åœ¨è®¨è®ºä¸€ä¸‹å¦‚ä½•è¿›è¡Œ Semantic Role Labelingã€‚</p><p>å¯¹äºæ ‡æ³¨ä»»åŠ¡æ¥è¯´å¤§åŒå°å¼‚ï¼Œç°åœ¨å¾€å¾€ä½¿ç”¨ç¥ç»ç½‘ç»œæ¨¡å‹æ¥è¿›è¡Œæ ‡æ³¨ï¼Œä¾‹å¦‚[2]ï¼Œç¼ºç‚¹æ˜¯éœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®ã€‚ç›®å‰ä¸šå†…æ¯”è¾ƒä¸»æµçš„è§£å†³æ–¹æ¡ˆæ˜¯RNN-CRFæ¨¡å‹ï¼Œä¸€èˆ¬æ¥è¯´åˆ†ä¸ºï¼š</p><ul><li>Embedding layer</li><li>Bi-directional RNN (usually LSTM) layer</li><li>Tanh hidden layer</li><li>CRF layer</li></ul><p>åœ¨å®é™…åº”ç”¨ä¸Šï¼Œå¯èƒ½è¿˜ä¼šå¢åŠ Attentionæœºåˆ¶ç­‰æ¥è¿›ä¸€æ­¥æé«˜å®ƒçš„æ•ˆæœã€‚</p><p>ç›®å‰å·²æœ‰çš„ç³»ç»Ÿå¦‚å“ˆå·¥å¤§çš„è¯­è¨€æŠ€æœ¯å¹³å°LTPï¼Œèƒ½å¤Ÿç”¨äº Semantic Role Labeling ç­‰ã€‚</p><h3 id="5-Conclusion"><a href="#5-Conclusion" class="headerlink" title="5. Conclusion"></a>5. Conclusion</h3><p>è¿™ä¸€ç¯‡æ–‡ç« æå‡ºäº†ä¸€ç§æ–°é¢–çš„äº‹ä»¶æ£€æµ‹å’ŒæŒ‡ä»£æ¶ˆè§£æ–¹æ³•ã€‚å…¶æœ€é‡è¦çš„éƒ¨åˆ†å°±æ˜¯æå‡ºäº†ä¸€ç§ç»“æ„åŒ–çš„å‘é‡ï¼Œèƒ½å¤Ÿæ›´å¥½åœ°è¡¨ç¤ºeventï¼Œç”¨ä»¥è¿›è¡Œäº‹ä»¶åˆ†ç±»ã€æŒ‡ä»£æ¶ˆè§£ç­‰å·¥ä½œã€‚è¿™ä¸ªæ–¹æ³•åœ¨ä¸€äº›å…³é”®æŒ‡æ ‡ä¸Šç”šè‡³èƒ½ä¼˜äºæœ€æ–°çš„ç›‘ç£æ–¹æ³•ï¼Œå¹¶ä¸”èƒ½å¤Ÿæ›´å¥½åœ°é€‚åº”æ–°çš„é¢†åŸŸã€‚</p><h2 id="Bibliography"><a href="#Bibliography" class="headerlink" title="Bibliography"></a>Bibliography</h2><p>[1] Peng, H., Song, Y., &amp; Roth, D. (2016). Event Detection and Co-reference with Minimal Supervision. In <em>EMNLP</em> (pp. 392-402).</p><p>[2] Zhou, J., &amp; Xu, W. (2015). End-to-end learning of semantic role labeling using recurrent neural networks. In <em>ACL (1)</em> (pp. 1127-1137).</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h2 id=&quot;Event-detection-and-co-reference-
      
    
    </summary>
    
      <category term="research" scheme="https://juewang.me/categories/research/"/>
    
    
      <category term="event-detection" scheme="https://juewang.me/tags/event-detection/"/>
    
      <category term="co-reference" scheme="https://juewang.me/tags/co-reference/"/>
    
  </entry>
  
  <entry>
    <title>å‡ ä¸ª relation extraction è¿œç¨‹ç›‘ç£æ¨¡å‹</title>
    <link href="https://juewang.me/posts/%5B2018.1.14%5DModels-for-relation-extraction/"/>
    <id>https://juewang.me/posts/[2018.1.14]Models-for-relation-extraction/</id>
    <published>2018-01-14T00:00:00.000Z</published>
    <updated>2018-03-12T20:21:58.365Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2 id="å‡ ä¸ª-relation-extraction-è¿œç¨‹ç›‘ç£æ¨¡å‹"><a href="#å‡ ä¸ª-relation-extraction-è¿œç¨‹ç›‘ç£æ¨¡å‹" class="headerlink" title="å‡ ä¸ª relation extraction è¿œç¨‹ç›‘ç£æ¨¡å‹"></a>å‡ ä¸ª relation extraction è¿œç¨‹ç›‘ç£æ¨¡å‹</h2><p><strong>æ‘˜è¦ï¼š</strong>è¿œç¨‹ç›‘ç£ï¼ˆDistant supervisionï¼‰æ˜¾è‘—åœ°å‡å°‘äº†å»ºç«‹ç”¨äºåˆ†ç±»ä»»åŠ¡çš„è®­ç»ƒé›†æ‰€éœ€è¦çš„äººå·¥ã€‚ä½†æ˜¯è¿™ä¸€é¡¹æŠ€æœ¯ä¹Ÿä¼šå¸¦æ¥å¾ˆå¤§çš„å™ªéŸ³ï¼Œå¹¶å¯èƒ½å› æ­¤è€Œå¤§å¤§åœ°å½±å“äº†æ¨¡å‹çš„æ€§èƒ½è¡¨ç°ã€‚è¿™é‡Œï¼Œæˆ‘ä»¬ä»¥ relation extraction è¿™é¡¹ä»»åŠ¡ä¸ºä¾‹ï¼Œæ·±å…¥è®¨è®ºåˆ†æè¯¥å™ªå£°çš„åˆ†å¸ƒã€‚æ–‡çŒ®[1]æå‡ºäº† dynamic-transition matrixï¼Œå¹¶è¯æ˜äº†å®ƒèƒ½å¾ˆå¥½åœ°ä»£è¡¨äº†ç”± distant supervision æ‰€å¸¦æ¥çš„å™ªå£°ã€‚é€šè¿‡è¯¥çŸ©é˜µï¼Œæˆ‘ä»¬èƒ½å¤Ÿå¤§å¤§æé«˜ relation extraction çš„æ•ˆæœã€‚æ–‡çŒ®[2]åˆ™æ˜¯ä¸€ç§ç»å…¸çš„æ–¹æ³•ï¼Œé€šè¿‡å®šä¹‰è§„åˆ™ï¼Œå®šä¹‰å¦å®šæ¨¡å¼ï¼ˆnegative patternï¼‰è¿‡æ»¤æ‰ä¸€äº›å™ªéŸ³æ•°æ®ï¼Œå¯ä»¥å¾ˆå¤§ç¨‹åº¦æé«˜æ€§èƒ½ã€‚ç¼ºç‚¹æ˜¯è§„åˆ™ä¾èµ–äººå·¥å®šä¹‰ï¼Œä½†æ˜¯æ–¹æ³•æœ¬èº«ç®€å•æœ‰æ•ˆã€‚æ–‡çŒ®[3]å°† relation extraction å®šä¹‰ä¸ºä¸€ä¸ª Multi-instance Multi-label å­¦ä¹ é—®é¢˜ï¼Œä¸€å®šç¨‹åº¦ä¸Šè§£å†³äº†é”™è¯¯æ ‡ç­¾çš„é—®é¢˜ã€‚</p><h3 id="1-Problem-of-distant-supervision"><a href="#1-Problem-of-distant-supervision" class="headerlink" title="1. Problem of distant supervision"></a>1. Problem of distant supervision</h3><p>Distant supervision æ˜¯ä¸€ç§ç”Ÿæˆå…³ç³»æŠ½å–è®­ç»ƒé›†çš„å¸¸ç”¨æ–¹æ³•ã€‚å®ƒæŠŠç°æœ‰çŸ¥è¯†åº“ä¸­çš„ä¸‰å…ƒç»„ \&lt;e1, r, e2> ï¼ˆæˆ–å†™æˆ\&lt;subj, r, obj>ï¼‰ä½œä¸ºç§å­ï¼ŒåŒ¹é…åŒæ—¶å«æœ‰ e1 å’Œ e2 çš„æ–‡æœ¬ï¼Œå¾—åˆ°çš„æ–‡æœ¬ç”¨ä½œå…³ç³» r çš„æ ‡æ³¨æ•°æ®ã€‚è¿™æ ·å¯ä»¥çœå»å¤§é‡äººå·¥æ ‡è®°çš„å·¥ä½œã€‚</p><p>ä½†æ˜¯ï¼Œç›¸æ¯”äºäººå·¥æ ‡æ³¨æ–¹æ³•ï¼Œè¿™ç§åŒ¹é…æ–¹å¼ä¼šäº§ç”Ÿå¾ˆå¤šå™ªéŸ³ï¼šæ¯”å¦‚ä¸‰å…ƒç»„\&lt;DonaldTrump, born-in, New York>ï¼Œå¯èƒ½å¯¹é½åˆ°â€œDonald Trump was born in New Yorkâ€ï¼Œä¹Ÿå¯èƒ½å¯¹é½åˆ°â€œDonaldTrump worked in New Yorkâ€ã€‚å…¶ä¸­å‰ä¸€å¥æ˜¯æˆ‘ä»¬æƒ³è¦çš„æ ‡æ³¨æ•°æ®ï¼Œåä¸€å¥åˆ™æ˜¯å™ªéŸ³æ•°æ®ï¼Œå®ƒå¹¶ä¸è¡¨ç¤ºborn-inå…³ç³»ã€‚å¦‚ä½•å»é™¤è¿™äº›å™ªéŸ³æ•°æ®ï¼Œæ˜¯ä¸€ä¸ªé‡è¦çš„ç ”ç©¶è¯¾é¢˜ã€‚</p><h3 id="2-Approaches-to-this-problems"><a href="#2-Approaches-to-this-problems" class="headerlink" title="2. Approaches to this problems"></a>2. Approaches to this problems</h3><ul><li>æ‹Ÿåˆå™ªéŸ³<ul><li>dynamic-transition matrix [1]</li></ul></li><li>å»é™¤å™ªéŸ³<ul><li>é€šè¿‡å®šä¹‰è§„åˆ™è¿‡æ»¤æ‰ä¸€äº›å™ªéŸ³æ•°æ®[2]ï¼Œç¼ºç‚¹æ˜¯ä¾èµ–äººå·¥å®šä¹‰ï¼Œå¹¶ä¸”è¢«å…³ç³»ç§ç±»æ‰€é™åˆ¶ã€‚</li><li>Multi-instance learning[3], æŠŠè®­ç»ƒè¯­å¥åˆ†åŒ…å­¦ä¹ ï¼ŒåŒ…å†…å–å¹³å‡å€¼ï¼Œæˆ–è€…ç”¨ attention åŠ æƒï¼Œå¯ä»¥ä¸­å’Œæ‰åŒ…å†…çš„å™ªéŸ³æ•°æ®ã€‚ç¼ºç‚¹æ˜¯å—é™äº at-least-one-assumptionï¼šæ¯ä¸ªåŒ…å†…è‡³å°‘æœ‰ä¸€ä¸ªæ­£ç¡®çš„æ•°æ®ã€‚</li></ul></li></ul><p>ä¸‹é¢æˆ‘ä»¬ç®€å•ä»‹ç»è¿™å‡ ä¸ªæ¨¡å‹ã€‚</p><h4 id="2-1-Learning-with-dynamic-transition-matrix-1"><a href="#2-1-Learning-with-dynamic-transition-matrix-1" class="headerlink" title="2.1 Learning with dynamic-transition matrix [1]"></a>2.1 Learning with dynamic-transition matrix [1]</h4><p>æ–‡çŒ®[1] æå‡ºäº† dynamic-transition matrixï¼Œç”¨äºè¡¨è¾¾ Distant supervision æ‰€äº§ç”Ÿçš„å™ªå£°ã€‚dynamic-transition matrix å¯ä»¥é€šè¿‡åŸºäº curriculum learning çš„æ–¹æ³•è®­ç»ƒå¾—åˆ°ã€‚é€šè¿‡è¯¥çŸ©é˜µï¼Œæˆ‘ä»¬èƒ½å¤Ÿå¤§å¤§æé«˜ relation extraction çš„æ•ˆæœï¼Œèƒ½å¤Ÿè¾¾åˆ°ç›®å‰è¯¥é¢†åŸŸçš„ state-of-the-artã€‚</p><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-03-12-202153.jpg" alt="overview"></p><p>Transition matrix æ˜¯ä¸€ä¸ªè½¬ç§»çŸ©é˜µï¼Œè®°ä¸ºTï¼Œå¤§å°ä¸º n*nï¼Œnæ˜¯å…³ç³»ç§ç±»çš„æ•°ç›®ã€‚T çš„å…ƒç´ ï¼Œ$T_{ij}$çš„å€¼æ˜¯ p( j| i )ï¼Œå³è¯¥å¥å­ä»£è¡¨å…³ç³»ä¸º iï¼Œä½†è¢«è¯¯åˆ¤ä¸º j çš„æ¦‚ç‡ã€‚</p><p>è¿™æ ·æˆ‘ä»¬å°±å¯ä»¥å¾—åˆ°ï¼šğ‘ƒğ‘Ÿğ‘’ğ‘‘ğ‘–ğ‘ğ‘¡ğ‘’ğ‘‘ ğ‘‘ğ‘–ğ‘ ğ‘¡ğ‘Ÿğ‘–ğ‘ğ‘¢ğ‘¡ğ‘–ğ‘œğ‘› Ã— ğ‘‡ğ‘Ÿğ‘ğ‘ ğ‘–ğ‘¡ğ‘–ğ‘œğ‘› ğ‘šğ‘ğ‘¡ğ‘Ÿğ‘–ğ‘¥=ğ‘‚ğ‘ğ‘ ğ‘’ğ‘Ÿğ‘£ğ‘’ğ‘‘ ğ‘‘ğ‘–ğ‘ ğ‘¡ğ‘Ÿğ‘–ğ‘ğ‘¢ğ‘¡ğ‘–ğ‘œğ‘›</p><p>å…¶ä¸­ï¼Œpredicted æ˜¯æˆ‘ä»¬æƒ³è¦çš„çœŸå®åˆ†å¸ƒï¼Œobserved æ˜¯æˆ‘ä»¬è§‚æµ‹åˆ°çš„å™ªéŸ³åˆ†å¸ƒï¼Œè¿™æ ·å°±å¯ä»¥ç”¨å™ªéŸ³æ•°æ®è¿›è¡Œè”åˆè®­ç»ƒäº†ã€‚ä½œè€…åœ¨ timeRE å’Œ entityRE(NYT) ä¸Šå‡è¿›è¡Œäº†è®­ç»ƒï¼Œå–å¾—äº†é™å™ªçš„ state-of-artã€‚å…·ä½“åˆ†æç»“æœå¯ä»¥å‚ç…§è®ºæ–‡ã€‚</p><h4 id="2-2-Reducing-Wrong-Labels-2"><a href="#2-2-Reducing-Wrong-Labels-2" class="headerlink" title="2.2 Reducing Wrong Labels [2]"></a>2.2 Reducing Wrong Labels [2]</h4><p>åœ¨å…³ç³»æå–æ–¹é¢ï¼Œè¿œç¨‹ç›‘ç£è¯•å›¾é€šè¿‡ä½¿ç”¨çŸ¥è¯†åº“ï¼ˆå¦‚Freebaseï¼‰ä½œä¸ºç›‘ç£æ¥æºï¼Œä»æ–‡æœ¬ä¸­æå–å®ä½“ä¹‹é—´çš„å…³ç³»ã€‚ å½“ä¸€ä¸ªå¥å­å’Œä¸€ä¸ªçŸ¥è¯†åº“å¼•ç”¨åŒä¸€ä¸ªå®ä½“å¯¹æ—¶ï¼Œè¿™ç§æ–¹æ³•è¯•å›¾ç”¨çŸ¥è¯†åº“ä¸­çš„å¯¹åº”å…³ç³»æ¥å¯å‘å¼åœ°æ ‡æ³¨å¥å­ã€‚ ç„¶è€Œï¼Œè¿™ç§å¯å‘å¼å¯èƒ½ä¼šå¯¼è‡´ä¸€äº›å¥å­è¢«é”™è¯¯åœ°æ ‡è®°ã€‚ è¿™ç§å˜ˆæ‚çš„æ ‡è®°æ•°æ®å¯¼è‡´è¾ƒå·®çš„æŠ½å–æ€§èƒ½ã€‚ åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§å‡å°‘é”™è¯¯æ ‡ç­¾æ•°é‡çš„æ–¹æ³•ã€‚ æˆ‘ä»¬æå‡ºäº†ä¸€ä¸ªæ–°çš„ç”Ÿæˆæ¨¡å‹ï¼Œç›´æ¥æ¨¡æ‹Ÿè¿œç¨‹ç›‘ç£çš„å¯å‘å¼æ ‡ç­¾è¿‡ç¨‹ã€‚ è¯¥æ¨¡å‹é€šè¿‡å…¶éšè—å˜é‡æ¥é¢„æµ‹åˆ†é…çš„æ ‡ç­¾æ˜¯æ­£ç¡®çš„è¿˜æ˜¯é”™è¯¯çš„ã€‚åœ¨å®éªŒä¸­ï¼Œæˆ‘ä»¬ä¹Ÿå‘ç°é”™è¯¯çš„æ ‡ç­¾å‡å°‘æé«˜äº†å…³ç³»æŠ½å–çš„æ€§èƒ½ã€‚</p><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-03-12-202150.jpg" width="70%"></p><p>NegPat(r)å³ä¸ºäº‹å…ˆå®šä¹‰çš„å¯¹äºrçš„å¦å®šæ¨¡å¼ï¼ˆnegative patternï¼‰ã€‚åœ¨æˆ‘ä»¬çš„æ–¹æ³•ä¸­ï¼Œæˆ‘ä»¬æŒ‰å¦‚ä¸‹æ‰€ç¤ºå»é™¤é”™è¯¯æ ‡ç­¾ï¼šï¼ˆiï¼‰ç»™å®šä¸€ä¸ªå·²æ ‡æ³¨çš„è¯­æ–™åº“ï¼Œæˆ‘ä»¬é¦–å…ˆéªŒè¯å…¶ä¸­çš„æ¨¡å¼æ˜¯å¦è¡¨è¾¾ä¸€ç§relationï¼Œç„¶åï¼ˆiiï¼‰ä½¿ç”¨å¦å®šæ¨¡å¼åˆ—è¡¨ï¼ˆNegPatï¼‰å»é™¤é”™è¯¯çš„æ ‡ç­¾ï¼Œ å³è¯¥æ¨¡å¼è¢«å®šä¹‰ä¸ºä¸è¡¨ç¤ºrelationçš„æ¨¡å¼ã€‚ ç¬¬ä¸€æ­¥ï¼Œæˆ‘ä»¬å¼•å…¥æ–°çš„ç”Ÿæˆæ¨¡å‹ï¼Œç›´æ¥æ¨¡æ‹ŸDSçš„æ ‡æ³¨è¿‡ç¨‹å¹¶è¿›è¡Œé¢„æµ‹ã€‚ ç¬¬äºŒæ­¥åœ¨ç®—æ³•1ä¸­æè¿°ï¼Œè§ä¸Šå›¾ã€‚å¯¹äºå…³ç³»æå–ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸Šè¿°å¾—åˆ°çš„æ ‡æ³¨æ•°æ®æ¥è®­ç»ƒåˆ†ç±»å™¨ï¼ˆç»™å®šå®ä½“å¯¹ï¼Œè¯¥åˆ†ç±»å™¨é¢„æµ‹æ‰€å±å…³ç³»ï¼‰ã€‚</p><p>####2.3 Multi-instance Multi-label Learning [3]</p><p>å¾ˆå¤šçš„å…±ç° entities éƒ½æ²¡æœ‰ä»€ä¹ˆå…³ç³»ï¼Œä»…ä»…æ˜¯å‡ºç°åœ¨åŒä¸€ä¸ªå¥å­ä¸­ï¼›è€Œæœ‰çš„ entities ä¹‹é—´çš„å…³ç³»å…¶å®å¹¶ä¸ä»…ä»…åªæœ‰ä¸€ç§ï¼Œå¯èƒ½æœ‰å¤šç§ï¼Œæ¯”å¦‚å¥¥å·´é©¬å’Œç¾å›½çš„å…³ç³»ï¼Œå¯èƒ½æ˜¯ born inï¼Œä¹Ÿå¯èƒ½æ˜¯ is the president of çš„å…³ç³»ã€‚</p><p>å› æ­¤è®­ç»ƒé›†ä¼šäº§ç”Ÿå¤§é‡çš„é”™è¯¯æ ‡è®°ï¼Œæ¯”å¦‚ä¸¤ä¸ªå®ä½“æœ‰å¤šç§å…³ç³»æˆ–è€…æ ¹æœ¬åœ¨è¿™å¥è¯ä¸­æ²¡æœ‰ä»»ä½•å…³ç³»ï¼Œè¿™æ ·çš„è®­ç»ƒæ•°æ®ä¼šå¯¹å…³ç³»æŠ½å–å™¨äº§ç”Ÿå½±å“ã€‚æ­£å› ä¸ºå¦‚æ­¤ï¼Œä¼ ç»Ÿçš„ç›‘ç£å¼å­¦ä¹ ï¼Œå‡è®¾æ¯ä¸ªå®ä¾‹æ˜ç¡®åœ°æ˜ å°„åˆ°ä¸€ä¸ªæ ‡ç­¾ï¼Œæ˜¯ä¸åˆé€‚çš„ã€‚</p><p>å¯¹äºè¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å°†å…³ç³»æŠ½å–å®šä¹‰ä¸ºä¸€ä¸ª Multi-instance Multi-label å­¦ä¹ é—®é¢˜ï¼Œå®ƒä½¿ç”¨å¸¦æœ‰æ½œåœ¨å˜é‡çš„å›¾æ¨¡å‹ï¼Œå¯¹æ–‡æœ¬ä¸­ä¸€å¯¹å®ä½“çš„æ‰€æœ‰å®ä¾‹ä»¥åŠå®ƒä»¬çš„æ‰€æœ‰æ ‡ç­¾è¿›è¡Œè”åˆå»ºæ¨¡ã€‚ è¯¥æ¨¡å‹åœ¨ relation extraction é¢†åŸŸè¡¨ç°å‡ºè‰²ã€‚</p><h3 id="3-Conclusion"><a href="#3-Conclusion" class="headerlink" title="3. Conclusion"></a>3. Conclusion</h3><p>ä¸Šé¢æåˆ°çš„å‡ ä¸ªæ¨¡å‹éƒ½æœ‰å…¶æ–°é¢–çš„åœ°æ–¹ï¼Œå…¶ä¸­[1]è¿™ç§æ‹Ÿåˆå™ªéŸ³çš„æ€æƒ³å¾ˆæœ‰åˆ›æ–°ç‚¹ï¼Œå®é™…çš„æ•ˆæœä¹Ÿå¾ˆç†æƒ³ï¼›è€Œåä¸¤ä¸ªæ¨¡å‹ä¸»è¦éƒ½æ˜¯åœ¨æ•°æ®é¢„å¤„ç†é˜¶æ®µè¿›è¡Œï¼Œå› æ­¤å¯ä»¥å’Œå…¶ä»– relation extraction æ¨¡å‹å¾ˆå¥½çš„ç»“åˆã€‚</p><h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><p>*ç¬”è®°éƒ¨åˆ†å‚è€ƒ<a href="https://mp.weixin.qq.com/s/O9JaalDhoX97DMoUBFxmtg" target="_blank" rel="noopener">è®ºæ–‡æµ…å° | Learning with Noise: Supervised Relation Extraction</a></p><p>[1] Luo, Bingfeng, et al. â€œLearning with noise: enhance distantly supervised relation extraction with dynamic transition matrix.â€ <em>arXiv preprint arXiv:1705.03995</em> (2017).</p><p>[2] Takamatsu, Shingo, Issei Sato, and Hiroshi Nakagawa. â€œReducing wrong labels in distant supervision for relation extraction.â€ <em>Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1</em>. Association for Computational Linguistics, 2012.</p><p>[3] Surdeanu, Mihai, et al. â€œMulti-instance multi-label learning for relation extraction.â€ <em>Proceedings of the 2012 joint conference on empirical methods in natural language processing and computational natural language learning</em>. Association for Computational Linguistics, 2012.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h2 id=&quot;å‡ ä¸ª-relation-extraction-è¿œç¨‹ç›‘ç£æ¨¡å‹&quot;&gt;&lt;a
      
    
    </summary>
    
      <category term="research" scheme="https://juewang.me/categories/research/"/>
    
    
      <category term="relation-extraction" scheme="https://juewang.me/tags/relation-extraction/"/>
    
      <category term="distant-supervision" scheme="https://juewang.me/tags/distant-supervision/"/>
    
  </entry>
  
  <entry>
    <title>Overcoming Limited Supervision in Relation Extraction ç¬”è®°</title>
    <link href="https://juewang.me/posts/%5B2018.1.4%5DOvercoming-Limited-Supervision-in-Relation-Extraction/"/>
    <id>https://juewang.me/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/</id>
    <published>2018-01-04T00:00:00.000Z</published>
    <updated>2018-03-12T20:21:27.342Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>è¿™æ¬¡ä¸»è¦é˜…è¯»çš„è®ºæ–‡æ˜¯ã€ŠOvercoming Limited Supervision in Relation Extraction: A Pattern-enhanced Distributional Representation Approachã€‹[1]ã€‚è¯¥æ–‡ä¸»è¦é’ˆå¯¹äº†ç°æœ‰æ¨¡å‹å¯¹æ ‡æ³¨æ•°æ®çš„ä¾èµ–ï¼Œæå‡ºä¸€ç§æ¯”è¾ƒæœ‰æ„æ€çš„æ€è·¯ã€‚åŸºäºåˆ†å¸ƒçš„æ–¹æ³•ï¼ˆdistributional approachï¼‰åˆ©ç”¨ä¸¤ä¸ªå®ä½“å…±åŒå‡ºç°çš„ç»Ÿè®¡é¢‘ç‡æ¥é¢„æµ‹ä»–ä»¬çš„å…³ç³»ï¼Œéœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®ï¼Œè€ŒåŸºäºæ¨¡å¼çš„æ–¹æ³•ï¼ˆpattern-based approachï¼‰ä¸€èˆ¬ä½¿ç”¨ç¥ç»ç½‘ç»œå»ºæ¨¡ï¼Œä½†è¿™ç§æ–¹æ³•éœ€è¦æ›´å¤šçš„æ ‡æ³¨æ•°æ®ã€‚æœ¬æ–‡åŒæ—¶å»ºç«‹ä¸¤ä¸ªæ¨¡å‹ï¼Œäº’ç›¸ä¸ºå¯¹æ–¹æä¾›ç›‘ç£ã€‚ä»¥åˆ†å¸ƒæ¨¡å‹ä½œä¸ºåˆ¤åˆ«æ¨¡å‹ï¼Œæ¨¡å¼æ¨¡å‹ä½œä¸ºç”Ÿæˆæ¨¡å‹ã€‚è®­ç»ƒè¿‡ç¨‹ä¸­ä¸æ–­è¿­ä»£ï¼Œä»è€Œæå‡ä¸¤ä¸ªæ¨¡å‹çš„æ€§èƒ½ã€‚</p><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-03-12-201441.jpg" alt="illustration"></p><h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h3><h4 id="1-1-Weakly-Supervised-Learning"><a href="#1-1-Weakly-Supervised-Learning" class="headerlink" title="1.1 Weakly Supervised Learning"></a>1.1 Weakly Supervised Learning</h4><p>å¼±ç›‘ç£å­¦ä¹ ä»‹äºç›‘ç£å­¦ä¹ å’Œæ— ç›‘ç£å­¦ä¹ ä¹‹é—´ï¼Œå®ƒæä¾›çš„æ ‡æ³¨æ•°æ®å¸¦æœ‰è¾ƒå¤§çš„å™ªéŸ³ï¼Œæˆ–æ ‡æ³¨çš„ç›¸å¯¹ç²—ç³™ï¼Œæ ‡æ³¨ç»“æœå¯èƒ½å‡ºé”™ã€‚å¯¹äºå…³ç³»æŠ½å–è€Œè¨€ï¼Œå°±æ˜¯å°†ä¸€äº›å…³ç³»å®ä¾‹ä½œä¸ºseedï¼Œç”¨å®ƒä»¬ä»å¤§å‹è¯­æ–™åº“ä¸­å»é™¤å†—ä½™ä¿¡æ¯å¹¶æå–æ›´å¤šçš„å®ä¾‹ã€‚</p><p>å¼±ç›‘ç£å­¦ä¹ çš„åŸºæœ¬æ€è·¯ï¼š</p><ol><li>ç”¨å®¹æ˜“è·å¾—çš„æ ‡æ³¨æ›¿ä»£è¾ƒéš¾è·å¾—çš„æ ‡æ³¨</li><li>é€‰æ‹©æœ€éœ€è¦åšç²¾ç»†æ ‡æ³¨çš„æ ·ä¾‹</li><li>æ¨¡å‹è®­ç»ƒå’Œè‡ªåŠ¨æ ‡æ³¨äº¤æ›¿è¿›è¡Œ</li></ol><h4 id="1-2-Co-training-strategy"><a href="#1-2-Co-training-strategy" class="headerlink" title="1.2 Co-training strategy"></a>1.2 Co-training strategy</h4><p>ä»¥å¾€çš„å·¥ä½œä¸»è¦æ˜¯å•ä¸ªæ¨¡å‹ï¼Œè¯¥æ–‡é‡‡ç”¨äº†co-trainingç­–ç•¥[2]ï¼Œå°†ä¸¤ä¸ªæ¨¡å‹äº’ç›¸åä½œï¼Œå–å¾—äº†æ¯”è¾ƒå¥½çš„æ•ˆæœã€‚</p><p>co-trainingç­–ç•¥æ˜¯ä¸€ç§åŠç›‘ç£æ–¹æ³•ï¼Œæ ¸å¿ƒå°±æ˜¯åˆ©ç”¨å°‘é‡å·²æ ‡è®°æ ·æœ¬ï¼Œé€šè¿‡ä¸¤ä¸ªï¼ˆæˆ–å¤šä¸ªï¼‰æ¨¡å‹å»å­¦ä¹ ï¼Œå¯¹æœªæ ‡è®°æ ·æœ¬è¿›è¡Œæ ‡è®°ï¼ŒæŒ‘é€‰ç½®ä¿¡åº¦æœ€é«˜çš„æ ·æœ¬åŠ å…¥å·²æ ‡è®°æ ·æœ¬é˜µè¥ã€‚</p><h4 id="1-3-REPEL-Relation-Extraction-with-pattern-enhanced-Embedding"><a href="#1-3-REPEL-Relation-Extraction-with-pattern-enhanced-Embedding" class="headerlink" title="1.3 REPEL (Relation Extraction with pattern-enhanced Embedding)"></a>1.3 REPEL (Relation Extraction with pattern-enhanced Embedding)</h4><p>REPELæ˜¯æœ¬æ–‡æå‡ºçš„ä¸€ä¸ªæ¨¡å‹ã€‚åŸºäºæ¨¡å¼çš„æ¨¡å‹å­¦ä¹ ç”¨äºå…³ç³»æŠ½å–æ–‡æœ¬çš„æ¨¡å¼ï¼ŒåŸºäºåˆ†å¸ƒçš„æ¨¡å‹ä½œä¸ºåˆ†ç±»å™¨ï¼Œä¸¤è€…äº’è¡¥ï¼Œäº’ç›¸æä¾›ç›‘ç£ã€‚å‰è€…ç›¸å½“äºä¸€ä¸ªç”Ÿæˆå™¨ï¼ŒåŸºäºæ¨¡å¼ç”Ÿæˆå€™é€‰å®ä¾‹ï¼›è€Œåè€…ä½œä¸ºåˆ¤åˆ«å™¨ï¼Œä»ä¸­é€‰æ‹©æœ€ä¼˜å®ä¾‹ï¼Œå¹¶å°†é€‰æ‹©ç»“æœåé¦ˆç»™å‰è€…ã€‚è®­ç»ƒå®Œæˆç›¸å½“äºå¾—åˆ°äº†ä¸¤ä¸ªå…³ç³»æŠ½å–æ¨¡å‹ã€‚</p><h3 id="2-Problem-definition"><a href="#2-Problem-definition" class="headerlink" title="2. Problem definition"></a>2. Problem definition</h3><p>å®ä½“è¯†åˆ«ï¼šä½¿ç”¨ç°æˆçš„å·¥å…·æ ‡æ³¨ã€‚</p><p>å…³ç³»è¯†åˆ«ï¼šå®ä½“å¯¹ $(e_h, e_t)$ï¼Œä¸‰å…ƒç»„$(e_h, e_t, r)$</p><p>ç»™å®šè¯­æ–™åº“Dï¼Œå…³ç³»é›†åˆRã€‚ç»™å®šå°‘é‡seedå®ä¾‹$ {(e_h^{r(k)}, e_t^{r(k)}, r)} _{k=1}^{N_r} $ï¼Œæå–å°½å¯èƒ½å¤šçš„$ {(e_h^{r(i)}, e_t^{r(i)}, r)} _{i=1}^M $ï¼›æ¢è¨€ä¹‹ï¼Œå¯¹äºæ¯ä¸ª$ r \in R $ï¼Œæˆ‘ä»¬è¦æå–å°½å¯èƒ½å¤šçš„$ {(e_h^{r(i)}, e_t^{r(i)})} _{i=1}^{M_r} $ã€‚</p><h3 id="3-REPEL-Framework"><a href="#3-REPEL-Framework" class="headerlink" title="3. REPEL Framework"></a>3. REPEL Framework</h3><p>æ¨¡å¼æ¨¡å‹ï¼šæ‰¾åˆ°æ–‡æœ¬ä¸­çš„æ¨¡å¼é›†åˆ</p><p>åˆ†å¸ƒæ¨¡å‹ï¼šå­¦ä¹ å®ä½“è¡¨ç¤ºï¼Œä»¥åŠæ‰“åˆ†å‡½æ•°</p><p>ç›®æ ‡å‡½æ•°ï¼š<br>$$<br>max_{P,D}O = max_{P,D}{O_p + O_d + \lambda O_i}<br>$$<br>ä¸Šé¢å…¬å¼ä¸­ï¼ŒPè¡¨ç¤ºæ¨¡å¼æ¨¡å‹çš„å‚æ•°ï¼Œç»™å®šå…³ç³»çš„å…¨éƒ¨æ¨¡å¼é›†åˆã€‚Dè¡¨ç¤ºåˆ†å¸ƒæ¨¡å‹çš„å‚æ•°ï¼Œå®ä½“è¡¨ç¤ºå’Œæ‰“åˆ†å‡½æ•°ã€‚Opå’ŒOdåˆ†åˆ«è¡¨ç¤ºä¸¤ä¸ªç›®æ ‡å‡½æ•°ï¼ŒOiè¡¨ç¤ºä¸¤ä¸ªæ¨¡å‹äº¤äº’çš„ç›®æ ‡ã€‚</p><p>æ³¨æ„è¿™é‡Œåªè€ƒè™‘å…³ç³»æŠ½å–ï¼Œå®ä½“è¯†åˆ«ä½¿ç”¨ç°æœ‰çš„å·¥å…·æˆ–æ¨¡å‹ã€‚</p><h4 id="3-1-Pattern-Module"><a href="#3-1-Pattern-Module" class="headerlink" title="3.1 Pattern Module"></a>3.1 Pattern Module</h4><p>å¯¹äºä¸€ä¸ªæŒ‡å®šçš„å…³ç³»rï¼Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯æ‰¾åˆ°Kä¸ªæœ€å¯é çš„æ¨¡å¼ï¼Œç„¶åè¿›ä¸€æ­¥ä½¿ç”¨å®ƒä»¬æ¥å‘ç°æ›´å¤šçš„å…³ç³»å®ä¾‹ã€‚</p><p>åŸºäºæ¨¡å¼å…³ç³»æŠ½å–ä¸»è¦åˆ†ä¸ºä¸¤ç§ï¼špath-based patternã€meta patternã€‚å¯¹äºä¸€å¥è¯ä¸­çš„å®ä½“å¯¹ï¼Œå‰è€…å®šä¹‰ä¸ºä¸¤ä¸ªå®ä½“é€šè¿‡ä¾å­˜ä¿¡æ¯è·³è½¬çš„æœ€çŸ­è·¯å¾„ï¼›åè€…åˆ™æ˜¯ä¸¤ä¸ªå®ä½“é™„è¿‘çš„æ–‡å­—åºåˆ—ã€‚åˆ©ç”¨è¿™ä¸¤ç§æ¨¡å¼ä»è¯­æ–™åº“ä¸­å¯»æ‰¾åŒ¹é…çš„å®ä½“å¯¹ã€‚è¿™æ ·å°±å¾—åˆ°äº†å¾ˆå¤šå€™é€‰æ¨¡å¼ï¼Œæ¯ä¸ªæ¨¡å¼åˆèƒ½åˆ†åˆ«æ‰¾åˆ°è®¸å¤šåŒ¹é…çš„å®ä½“å¯¹ã€‚</p><p>å¯¹äºä¸€ä¸ªæ¨¡å¼$\pi$ï¼Œæˆ‘ä»¬é€šè¿‡ä»¥ä¸‹å¼å­è®¡ç®—å®ƒçš„ç½®ä¿¡åº¦ï¼š<br>$$<br>R(\pi)=\frac{|G(\pi)\cap S_{pair}|}{|G(\pi)|}<br>$$<br>$G(\pi)$è¡¨ç¤ºè¢«æ¨¡å¼$\pi$æ‰€åŒ¹é…çš„æ‰€æœ‰å®ä½“å¯¹ï¼Œ$S_{pair}$è¡¨ç¤ºseedå®ä½“å¯¹ã€‚å¯ä»¥çœ‹åˆ°ï¼ŒRå®é™…è¡¨ç¤ºçš„æ˜¯ï¼Œåœ¨æ»¡è¶³$\pi$æ¨¡å¼çš„å®ä½“å¯¹ä¸­ï¼Œseedå®ä½“å¯¹æ‰€å çš„æ¯”ä¾‹ã€‚æ˜¾ç„¶ï¼Œè¯¥æ¯”å€¼è¶Šé«˜ï¼Œè¯¥æ¨¡å¼è¶Šç¬¦åˆseedçš„åˆ†å¸ƒã€‚ç”±æ­¤ï¼Œæˆ‘ä»¬å®šä¹‰ï¼š<br>$$<br>O_p = \sum_{\pi \in P}R(\pi)<br>$$<br>ä¸‹é¢è¯´æ˜ä¸€ä¸‹æ•´ä¸ªè¿›è¡Œçš„è¿‡ç¨‹ï¼š</p><ul><li>ç»™å®šseedå®ä½“å¯¹ï¼Œæˆ‘ä»¬é€šè¿‡æ¨¡å¼å…³ç³»æŠ½å–çš„æ–¹æ³•è·å¾—ä¸€ç³»åˆ—å€™é€‰æ¨¡å¼ã€‚</li><li>è®¡ç®—æ¯ä¸ªå€™é€‰æ¨¡å¼çš„Rå€¼ï¼Œå–æœ€é«˜çš„Kä¸ª</li></ul><h4 id="3-2-Distributional-Module"><a href="#3-2-Distributional-Module" class="headerlink" title="3.2 Distributional Module"></a>3.2 Distributional Module</h4><p>è¯¥æ¨¡å—å­¦ä¹ è¯­æ–™ä¸­çš„å®ä½“å…¨å±€åˆ†å¸ƒä¿¡æ¯ã€‚æˆ‘ä»¬åˆ©ç”¨ç»™å®šçš„å…³ç³»å®ä¾‹ä½œä¸ºæ‰“åˆ†å‡½æ•°ã€‚</p><p>å¯¹äºä¸€ä¸ªå®ä½“eï¼Œå’Œä¸€ä¸ªè¯w<br>$$<br>P(w|e) =\frac{exp(x_e*c_w)}{Z}<br>$$<br>$x_e$è¡¨ç¤ºéœ€è¦è®­ç»ƒçš„å®ä½“è¡¨ç¤ºå‘é‡ï¼Œ $c_w$æ˜¯é¢„è®­ç»ƒçš„word embeddingï¼ŒZæ˜¯å½’ä¸€åŒ–é¡¹ã€‚<br>$$<br>O_{text} = \sum_{w,e}n_{w,e}log(P(w|e))<br>$$<br>$n_{w,e}$æ˜¯å­—ä¸å®ä½“ä¹‹é—´è¾¹çš„æƒé‡ï¼Œä¹Ÿå°±æ˜¯å®ä½“å’Œè¿™ä¸ªå­—åŒæ—¶å‡ºç°çš„ç»Ÿè®¡é¢‘ç‡ã€‚æˆ‘ä»¬å¸Œæœ›åˆ†å¸ƒæ¦‚ç‡èƒ½å¤Ÿæ‹Ÿåˆç»éªŒåˆ†å¸ƒæ¦‚ç‡ã€‚</p><p>å®šä¹‰æ‰“åˆ†å‡½æ•°ï¼š<br>$$<br>L_D(f|r)=1-||x_{e_h} + y_r- x_{e_t} ||^2_2<br>$$<br>å®ä½“å‘é‡$(x_{e_h} - x_{e_t})$å’Œ$y_r$ï¼ˆå…³ç³»rçš„è¡¨ç¤ºï¼Œä¹Ÿæ˜¯è¦å­¦ä¹ çš„å‚æ•°ï¼‰è¶Šæ¥è¿‘ï¼Œ$L_D$å°±è¶Šæ¥è¿‘1ï¼›åä¹‹åˆ™ä¼šéå¸¸å°ã€‚<br>$$<br>O_{seed} = \sum_{f\in S_{pair}} \sum_{fâ€™\in(eâ€™_h,eâ€™_t)} {min{1, L_D(f|r) - L_D(fâ€™|r)}}<br>$$<br>$(eâ€™_h,eâ€™_t)$æ˜¯éšæœºé€‰å–çš„å®ä½“å¯¹ã€‚æœ€å°å€¼å‡½æ•°æ˜¯ä¸ºäº†é˜²æ­¢ä¸¤ä¸ªåˆ†æ•°å·®è·å¤ªå¤šï¼Œå› ä¸ºå¾€å¾€$L_D(fâ€™|r)$ä¼šæ˜¯ä¸€ä¸ªå¾ˆå°çš„è´Ÿæ•°ã€‚</p><p>æœ€åæœ‰æ€»ç›®æ ‡å‡½æ•°ä¸­çš„Odï¼š<br>$$<br>O_d = O_{text} + \eta O_{seed}<br>$$<br>$\eta$ç”¨äºè°ƒæ•´ä¸¤éƒ¨åˆ†çš„æ¯”å€¼ã€‚</p><h4 id="3-3-Modeling-the-Module-Interaction"><a href="#3-3-Modeling-the-Module-Interaction" class="headerlink" title="3.3 Modeling the Module Interaction"></a>3.3 Modeling the Module Interaction</h4><p>$$<br>O_i = E_{f\in G(P)}[L_D(f|r)]<br>$$</p><p>è¿™é‡ŒEæŒ‡çš„æ˜¯æœŸæœ›ã€‚</p><p>æˆ‘ä»¬ç»™æ¨¡å¼æ¨¡å‹ç”Ÿæˆçš„å®ä½“å¯¹ä¹Ÿæ‰“åˆ†ã€‚Oiä½œä¸ºç›®æ ‡å‡½æ•°ï¼Œä¸ºäº†æœ€å¤§åŒ–å®ƒï¼Œæ¨¡å¼é›†åˆPåº”è¯¥å°½å¯èƒ½åŒ…å«é‚£äº›å¯é æœ‰æ•ˆçš„æ¨¡å¼ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæ¨¡å¼æ¨¡å‹ç”Ÿæˆçš„å®ä½“å¯¹åº”è¯¥å¾—åˆ°çš„æ‰“åˆ†è¶Šå¤§è¶Šå¥½ã€‚è¿™æ ·ä¸€æ¥åˆ†å¸ƒæ¨¡å‹å°±èƒ½ä¸ºæ¨¡å¼æ¨¡å‹æä¾›ç›‘ç£ï¼ˆæ‰“åˆ†ï¼‰ã€‚å¹¶ä¸”ï¼Œå¯¹äºåˆ†å¸ƒæ¨¡å‹æ¥è¯´ï¼Œæœ€å¤§åŒ–è¯¥ç›®æ ‡å‡½æ•°èƒ½å¤Ÿç»™å®ä½“å¯¹åˆ†é…æ›´é«˜çš„æ‰“åˆ†ï¼ˆä¹Ÿå°±æ˜¯è¯´ï¼Œè¦ä»¤Oiæœ€å¤§åŒ–ï¼ŒG(P)å’ŒLDéƒ½è¦åˆé€‚ï¼‰ã€‚é€šè¿‡è¿™ç§æ–¹å¼ä¸¤ä¸ªæ¨¡å‹èƒ½å¤Ÿäº’ç›¸æä¾›ç›‘ç£ã€‚</p><h3 id="4-The-Joint-Optimization-Problem"><a href="#4-The-Joint-Optimization-Problem" class="headerlink" title="4. The Joint Optimization Problem"></a>4. The Joint Optimization Problem</h3><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-03-12-201444.jpg" alt="algo"></p><p>å…·ä½“ç®—æ³•å¦‚ä¸Šå›¾åŸæ–‡ï¼Œä¸ºäº†ä¼˜åŒ–æ€»ç›®æ ‡å‡½æ•°ï¼Œé‡‡ç”¨åæ¢¯åº¦ä¸‹é™ç®—æ³•ã€‚</p><p>å…ˆå›ºå®šæ¨¡å¼æ¨¡å‹ï¼Œå°†seedå®ä½“å¯¹$S_{pair}$å’Œæ¨¡å¼æ¨¡å‹ç”Ÿæˆçš„å®ä½“å¯¹$G(P)$è®­ç»ƒåˆ†å¸ƒæ¨¡å‹ã€‚å›¾ä¸­çš„Eqn.11å°±æ˜¯ä¸‹å¼ï¼š<br>$$<br>max_D { O_d + \lambda O_i } = max_D { O_d + \lambda E_{f \in G(P)}[L_D(f|r)] }<br>$$<br>ç„¶åå†å›ºå®šåˆ†å¸ƒæ¨¡å‹ï¼Œå¯¹å®ä½“å¯¹ç­›é€‰åå¾—åˆ°çš„$S_{pair}$è®­ç»ƒæ¨¡å¼æ¨¡å‹ã€‚å›¾ä¸­çš„Eqn.12å°±æ˜¯ä¸‹å¼ï¼š<br>$$<br>max_P { O_p + \lambda O_i } = max_P { \sum_{\pi \in P}(R(\pi) + \lambda E_{f \in G(\pi)}[L_D(f|r)]) }<br>$$<br>å¾€å¤è¿­ä»£ã€‚</p><h3 id="5-Conclusion"><a href="#5-Conclusion" class="headerlink" title="5. Conclusion"></a>5. Conclusion</h3><p>åˆ©ç”¨ä¸¤ä¸ªæ¨¡å‹è¿›è¡Œäº’è¡¥çš„æ€è·¯å¾ˆæ–°é¢–ï¼Œä»è®ºæ–‡çš„æµ‹è¯•ç»“æœä¸Šæ¥çœ‹ï¼Œæœ¬æ–‡æå‡ºçš„æ¨¡å‹å¹¶ä¸é€Šè‰²äºç¥ç»ç½‘ç»œï¼Œå¯è§ä¸¤ä¸ªæ¨¡å‹äº’è¡¥çš„æ•ˆæœæ˜¯ç›¸å½“ä¸é”™çš„ã€‚ä½†æ˜¯è¿™ç§å¼±ç›‘ç£å­¦ä¹ éœ€è¦çš„äººå·¥æ ‡æ³¨æ•°æ®éå¸¸å°‘ï¼Œé™ä½äº†å¯¹æ ‡æ³¨æ•°æ®çš„ä¾èµ–æ€§ã€‚</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>*ç¬”è®°éƒ¨åˆ†å‚è€ƒ<a href="https://zhuanlan.zhihu.com/p/32364723" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/32364723</a></p><p>[1] Qu, M., Ren, X., Zhang, Y., &amp; Han, J. (2017). Overcoming Limited Supervision in Relation Extraction: A Pattern-enhanced Distributional Representation Approach. <em>arXiv preprint arXiv:1711.03226</em>.</p><p>[2] Blum, Avrim, and Tom Mitchell. â€œCombining labeled and unlabeled data with co-training.â€ <em>Proceedings of the eleventh annual conference on Computational learning theory</em>. ACM, 1998.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;è¿™æ¬¡ä¸»è¦é˜…è¯»çš„è®ºæ–‡æ˜¯ã€ŠOvercoming Limited Supervis
      
    
    </summary>
    
      <category term="research" scheme="https://juewang.me/categories/research/"/>
    
    
      <category term="relation-extraction" scheme="https://juewang.me/tags/relation-extraction/"/>
    
      <category term="limited-supervision" scheme="https://juewang.me/tags/limited-supervision/"/>
    
      <category term="weak-supervision" scheme="https://juewang.me/tags/weak-supervision/"/>
    
  </entry>
  
  <entry>
    <title>Relation Classification via Attention Model ç¬”è®°</title>
    <link href="https://juewang.me/posts/%5B2017.12.17%5DRelation-Classification-via-Attention-Model/"/>
    <id>https://juewang.me/posts/[2017.12.17]Relation-Classification-via-Attention-Model/</id>
    <published>2017-12-17T00:00:00.000Z</published>
    <updated>2018-03-16T19:57:06.520Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2 id="Relation-Classification-via-Attention-Model"><a href="#Relation-Classification-via-Attention-Model" class="headerlink" title="Relation Classification via Attention Model"></a>Relation Classification via Attention Model</h2><p>è¿™ä¸ªç¬”è®°ä¸»è¦æ˜¯é˜…è¯»è®ºæ–‡[1]ï¼Œå®ƒçš„å·¥ä½œé‡ç‚¹æ˜¯åœ¨ç¥ç»ç½‘ç»œæ„æˆçš„ç«¯åˆ°ç«¯å­¦ä¹ çš„å…³ç³»æŠ½å–ä»»åŠ¡ä¸­åŠ å…¥Attentionæœºåˆ¶ã€‚ä½œè€…ä¸»è¦é€šè¿‡è‡ªåŠ¨å­¦ä¹ å…³ç³»å¥ä¸­æ³¨æ„åŠ›è¾ƒé«˜çš„éƒ¨åˆ†ï¼Œè€Œå¼•å…¥attentionæœºåˆ¶ï¼Œå¯¹åæ˜ å®ä½“å…³ç³»æ›´åŠ é‡è¦çš„è¯è¯­ç»™äºˆæ›´å¤§çš„attentionï¼Œè¾ƒå¥½åœ°æé«˜äº†å…³ç³»æŠ½å–çš„æ•ˆæœã€‚</p><p><img src="https://github.com/lawlietAi/relation-classification-via-attention-model/raw/master/acnn_structure.png" width="50%"></p><h3 id="1-Attention"><a href="#1-Attention" class="headerlink" title="1. Attention"></a>1. Attention</h3><h4 id="1-1-æ¦‚è¿°"><a href="#1-1-æ¦‚è¿°" class="headerlink" title="1.1 æ¦‚è¿°"></a>1.1 æ¦‚è¿°</h4><p>Attentionæœºåˆ¶æœ€æ—©æ˜¯åœ¨è§†è§‰å›¾åƒé¢†åŸŸè¢«æå‡ºæ¥çš„ã€‚åœ¨NLPä»»åŠ¡ä¸Šï¼ŒBahdanau[2]ç­‰äººä½¿ç”¨ç±»ä¼¼attentionçš„æœºåˆ¶åœ¨æœºå™¨ç¿»è¯‘ä»»åŠ¡ä¸Šå°†ç¿»è¯‘å’Œå¯¹é½åŒæ—¶è¿›è¡Œã€‚æ¥ç€ç±»ä¼¼çš„åŸºäºattentionæœºåˆ¶çš„æ·±åº¦å­¦ä¹ æ¨¡å‹å¼€å§‹å¹¿æ³›åº”ç”¨åˆ°å„ç§NLPä»»åŠ¡ä¸­ã€‚</p><h4 id="1-2-Recurrent-Models-of-Visual-Attention"><a href="#1-2-Recurrent-Models-of-Visual-Attention" class="headerlink" title="1.2 Recurrent Models of Visual Attention"></a>1.2 Recurrent Models of Visual Attention</h4><p>äººä»¬åœ¨è¿›è¡Œè§‚å¯Ÿå›¾åƒçš„æ—¶å€™ï¼Œå…¶å®å¹¶ä¸æ˜¯ä¸€æ¬¡å°±æŠŠæ•´å¹…å›¾åƒçš„æ¯ä¸ªä½ç½®åƒç´ éƒ½çœ‹è¿‡ï¼Œå¤§å¤šæ˜¯æ ¹æ®éœ€æ±‚å°†æ³¨æ„åŠ›é›†ä¸­åˆ°å›¾åƒçš„ç‰¹å®šéƒ¨åˆ†ã€‚ç”±æ­¤ï¼Œåœ¨ä¼ ç»Ÿçš„RNNä¸ŠåŠ å…¥äº†attentionæœºåˆ¶ï¼Œæ¯æ¬¡å½“å‰çŠ¶æ€ï¼Œéƒ½ä¼šæ ¹æ®å‰ä¸€ä¸ªçŠ¶æ€å­¦ä¹ å¾—åˆ°çš„è¦å…³æ³¨çš„ä½ç½®å’Œå½“å‰è¾“å…¥çš„å›¾åƒï¼Œå»å¤„ç†æ³¨æ„åŠ›éƒ¨åˆ†åƒç´ ã€‚å¯ä»¥çœ‹åˆ°åº”ç”¨Attentionæœºåˆ¶åï¼Œä»»åŠ¡çš„å¤æ‚åº¦è¢«é™ä½äº†å¾ˆå¤šã€‚</p><h4 id="1-3-Attention-based-RNN-in-NLP"><a href="#1-3-Attention-based-RNN-in-NLP" class="headerlink" title="1.3 Attention-based RNN in NLP"></a>1.3 Attention-based RNN in NLP</h4><p>[1]çš„æˆæœæ˜¯åœ¨æœºå™¨ç¿»è¯‘ä»»åŠ¡ï¼Œä¸€èˆ¬æœºå™¨ç¿»è¯‘å·¥ä½œç”±ä¸€ä¸ªEncoderå’Œä¸€ä¸ªDecoderæ„æˆï¼Œä¸€ä¸ªå…¸å‹çš„Seq2seqä»»åŠ¡ã€‚Encoderå°†æºå¥å­è¿›è¡Œç¼–ç ï¼Œå†åˆ©ç”¨Decoderå°†ç¼–ç åçš„å‘é‡è§£ç æˆç›®æ ‡è¯­è¨€ã€‚</p><p>æˆ‘ä»¬åœ¨æ±‚æ³¨æ„åŠ›åˆ†é…æ¦‚ç‡åˆ†å¸ƒçš„æ—¶å€™ï¼Œå¯¹äºè¾“å…¥å¥å­ä¸­ä»»æ„ä¸€ä¸ªå•è¯éƒ½ç»™å‡ºä¸ªæ¦‚ç‡ï¼Œä»è€Œå¾—åˆ°ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒï¼Œå†å¯¹è¾“å…¥å¥å­æ‰€æœ‰å•è¯çš„æ¦‚ç‡è¿›è¡ŒåŠ æƒæ±‚å’Œï¼Œå¾—åˆ°Decoderçš„æ³¨æ„åŠ›åˆ†é…ã€‚å¦‚ä¸‹å›¾ã€‚</p><p><img src="http://oi4yiqiop.bkt.clouddn.com/2018-03-12-201155.jpg" width="30%"></p><p>å¦ä¸€ä¸ªæ‰©å±•æ€§æ›´å¥½çš„è®ºæ–‡æ˜¯[3]ï¼Œä»–ä»¬çš„å·¥ä½œå‘Šè¯‰äº†å¤§å®¶attentionåœ¨RNNä¸­å¯ä»¥å¦‚ä½•è¿›è¡Œæ‰©å±•ã€‚</p><h4 id="1-4-Attention-based-CNN-in-NLP"><a href="#1-4-Attention-based-CNN-in-NLP" class="headerlink" title="1.4 Attention-based CNN in NLP"></a>1.4 Attention-based CNN in NLP</h4><p>[4]è¿™ç¯‡è®ºæ–‡ç ”ç©¶çš„æ˜¯ä¸¤ä¸ªCNNç½‘ç»œï¼Œåˆ†åˆ«å¤„ç†ä¸¤ä¸ªå¥å­ï¼Œæœ€åè¾“å…¥åˆ°åˆ†ç±»å™¨ä¸­å¤„ç†ã€‚ä½†æ˜¯è¿™æ ·çš„æ¨¡å‹åœ¨è¾“å…¥åˆ†ç±»å™¨å‰å¥å¯¹é—´æ˜¯æ²¡æœ‰ç›¸äº’è”ç³»çš„ï¼Œä½œè€…å°±æƒ³é€šè¿‡è®¾è®¡attentionæœºåˆ¶å°†ä¸åŒcnné€šé“çš„å¥å¯¹è”ç³»èµ·æ¥ã€‚äºæ˜¯æå‡ºäº†3ä¸­åœ¨CNNä¸­ä½¿ç”¨attentionçš„æ–¹æ³•ã€‚</p><ul><li>ABCNN-1: åœ¨å·ç§¯å‰è¿›è¡Œattentionï¼Œé€šè¿‡attentionçŸ©é˜µè®¡ç®—å‡ºç›¸åº”å¥å¯¹çš„attention feature mapï¼Œç„¶åè¿åŒåŸæ¥çš„feature mapä¸€èµ·è¾“å…¥åˆ°å·ç§¯å±‚ã€‚</li><li>ABCNN-2: åœ¨æ± åŒ–æ—¶è¿›è¡Œattentionï¼Œé€šè¿‡attentionå¯¹å·ç§¯åçš„è¡¨è¾¾é‡æ–°åŠ æƒï¼Œç„¶åå†è¿›è¡Œæ± åŒ–.</li><li>ABCNN-3: ABCNN-1 + ABCNN-2</li></ul><h3 id="2-Relation-Classification"><a href="#2-Relation-Classification" class="headerlink" title="2. Relation Classification"></a>2. Relation Classification</h3><p><img src="https://github.com/lawlietAi/relation-classification-via-attention-model/raw/master/acnn_structure.png" width="50%"></p><h4 id="2-1-Classification-Objective"><a href="#2-1-Classification-Objective" class="headerlink" title="2.1 Classification Objective"></a>2.1 Classification Objective</h4><p>ä½œè€…æå‡ºäº†ä¸€ç§è·ç¦»å‡½æ•°ï¼Œå³æ­£åˆ™åŒ–å‘é‡å·®çš„L2èŒƒæ•°ï¼š<br>$$<br>\delta_{\theta}(S,y) = ||\frac{w^O}{|w^O|} - W_y^L||_{L^2} \\<br>S:\text{Sentence}, y:\text{Output relation}, w^O: \text{Network output}, W^L:\text{Relation embedding}<br>$$<br>åŸºäºæ­¤ï¼Œä½œè€…å®šä¹‰äº†ç›®æ ‡å‡½æ•°ï¼š<br>$$<br>\mathcal{L} = [\delta_\theta(S,y) + (1-\delta_\theta(S, \hat{y}^-))] + \beta||\theta||^2 \\<br>\hat{y}^- : \text{A selected incorrect relation label chosen as the one with the highest score among all i.e.} \\<br>\hat{y}^- = argmax_{yâ€™\in \mathcal{Y},yâ€™\ne y}(\delta(S, yâ€™))<br>$$<br>ç›®æ ‡ä¸­çš„ä¸¤ä¸ªè·ç¦»åˆ†åˆ«ä¸ºç½‘ç»œè¾“å‡ºå‘é‡ä¸æ­£ä¾‹å’Œä¸æŸè´Ÿä¾‹çš„è·ç¦»ï¼Œè¯¥è´Ÿä¾‹æ˜¯æ‰€æœ‰é”™è¯¯ç±»åˆ«ä¸­ä¸è¯¥è¾“å‡ºæœ€æ¥è¿‘çš„ã€‚æœ€ååŠ ä¸Šä¸€ä¸ªæ­£åˆ™é¡¹ï¼Œé€šè¿‡ä½¿è¯¥ç›®æ ‡å‡½æ•°æœ€å°åŒ–æ¥è®­ç»ƒç½‘ç»œä¸­çš„å„å‚æ•°ï¼Œ$\beta$ç”¨äºæ§åˆ¶å…¶æ¯”é‡ã€‚</p><h4 id="2-2-Input-Representation"><a href="#2-2-Input-Representation" class="headerlink" title="2.2 Input Representation"></a>2.2 Input Representation</h4><p>ç°æœ‰å¥å­ï¼Œä»¥åŠä¸¤ä¸ªå·²çŸ¥çš„å®ä½“e1,e2ï¼š<br>$$<br>S = (w_1,w_2,â€¦,w_n) \\<br>e_1 := w_p, e_2 := w_t . p,t\in [1,n], p\ne t<br>$$<br>ä¸ºäº†å¾—åˆ°å®ƒä»¬çš„å…³ç³»ï¼Œæˆ‘ä»¬æŠŠæ‰€æœ‰è¯è½¬ä¸ºè¯å‘é‡ï¼›å¹¶ä¸”æ ¹æ®æ¯ä¸ªè¯ä¸å®ä½“çš„ç›¸å¯¹ä½ç½®ï¼Œä¹Ÿè½¬ä¸ºword position embeddingsï¼Œæ¯ä¸ªè¯ä¸ä¸¤ä¸ªå®ä½“æœ‰ä¸¤ä¸ªç›¸å¯¹ä½ç½®ï¼Œæ‰€ä»¥å¾—åˆ°ç¬¬iä¸ªè¯çš„Embeddingï¼š<br>$$<br>w_i^M = [(w_i^d)^T, (w_{i,2}^p)^T,(w_{i,2}^p)^T]^T<br>$$<br>ä¸ºäº†å……åˆ†å¾—åˆ°ä¸Šä¸‹æ–‡çš„ä¿¡æ¯ï¼Œå†è€ƒè™‘å¤§å°ä¸ºkçš„æ»‘çª—ï¼Œå¾—åˆ°æœ€ç»ˆçš„input representation<br>$$<br>z_i = [(w_{i - (k-1)/2}^M)^T,â€¦,(w_{i + (k-1)/2}^M)^T]^T<br>$$</p><h4 id="2-3-Input-Attention-Mechanism"><a href="#2-3-Input-Attention-Mechanism" class="headerlink" title="2.3 Input Attention Mechanism"></a>2.3 Input Attention Mechanism</h4><p><img src="https://pic3.zhimg.com/50/v2-2399a406ad0960c422702728b6418fa3_hd.jpg" width="70%"></p><p>è¾“å…¥çº§çš„attentionæœºåˆ¶æ˜¯è®¾è®¡ä¸¤ä¸ªå…³äºå®ä½“å¯¹ä¸Šä¸‹æ–‡ç›¸å…³çš„å¯¹è§’çŸ©é˜µï¼Œè¯¥çŸ©é˜µä¸­å„å…ƒç´ åæ˜ è¯¥è¯è¯­ä¸ç»™å®šå®ä½“é—´è”ç³»çš„å¼ºå¼±ï¼Œå¦‚$A_{i,i}^j=f(e_j,w_i)$åæ˜ äº†wiå’Œejä¹‹é—´çš„è”ç³»å¼ºå¼±ï¼Œè¿™é‡Œä½œè€…ç»™çš„ f å°±æ˜¯å†…ç§¯ã€‚æˆ‘ä»¬å®šä¹‰ï¼š<br>$$<br>\alpha_i^j = \frac{exp(A_{i,i}^j)}{\sum_{iâ€™=1}^{n}{exp(A_{iâ€™,i}^j)}}<br>$$<br>å¯¹äºj=1,2 ä¸¤ä¸ªç›¸å…³å› å­ï¼Œä½œè€…æå‡ºäº†ä¸‰ç§å¤„ç†æ–¹å¼:</p><ul><li><p>å¹³å‡<br>$$<br>r_i = z_i \frac{\alpha_i^1 + \alpha_i^2}{2}<br>$$</p></li><li><p>ä¸²è”<br>$$<br>r_i = [(z_i \alpha_i^1)^T, (z_i \alpha_i^2)^T]^T<br>$$</p></li><li><p>è·ç¦»<br>$$<br>r_i = z_i \frac{\alpha_i^1 - \alpha_i^2}{2}<br>$$</p></li></ul><p>æœ€ç»ˆå¾—åˆ°$R = [r_1, r_2,â€¦,r_n]$</p><h4 id="2-4-Convolutional-Max-Pooling-with-Secondary-Attention"><a href="#2-4-Convolutional-Max-Pooling-with-Secondary-Attention" class="headerlink" title="2.4 Convolutional Max-Pooling with Secondary Attention"></a>2.4 Convolutional Max-Pooling with Secondary Attention</h4><p>å°†å‰é¢å¾—åˆ°çš„çŸ©é˜µRé€å…¥å·ç§¯æ ¸å¤§å°ä¸ºdcçš„å·ç§¯å±‚ï¼Œå·ç§¯æ“ä½œå¯å½¢å¼åŒ–è¡¨ç¤ºä¸º:<br>$$<br>R^\star = tanh(W_fR+B_f), \text{where the siaze of Wf is } d^c \times k(d^w+2d^p)<br>$$<br>ç„¶åæ„å»ºä¸€ä¸ªç›¸å…³æ€§çŸ©é˜µæ¥æ•è·å·ç§¯å±‚è¾“å‡ºR*ä¸å®ä½“å…³ç³»WLä¹‹é—´çš„è”ç³»<br>$$<br>G = R^{\star T}UW^L, \\U :\text{weighting matrix learnt by the network}<br>$$</p><p>å†ç”¨softmaxå‡½æ•°æ¥å¤„ç†ç›¸å…³æ€§çŸ©é˜µGï¼Œè·å¾—attention pooling matrix Ap:<br>$$<br>A_{i,j}^p = \frac{exp(G_{i,j})}{\sum_{iâ€™=1}^n{exp(G_{iâ€™,j})}}<br>$$<br>æœ€åç”¨Apä¸å·ç§¯å±‚è¾“å‡ºR*ç›¸ä¹˜ï¼Œä¹Ÿå°±æ˜¯åŠ å…¥æ··åˆä¸­çš„attentionï¼Œç„¶åå–å‡ºæ¯ä¸€ç»´åº¦çš„æœ€å¤§å€¼ï¼Œå¾—åˆ°ç½‘ç»œçš„è¾“å‡º<br>$$<br>w_i^O = max_j(R^\star A^p)_{i,j}<br>$$</p><h3 id="3-æ€»ç»“"><a href="#3-æ€»ç»“" class="headerlink" title="3. æ€»ç»“"></a>3. æ€»ç»“</h3><p>ä»[1]ä¸­æåˆ°çš„ç»“æœä¸Šçœ‹ï¼Œattentionçš„è¡¨ç°ç¡®å®æ˜¯åœ¨é‡è¦çš„è¯ä¸Šæœ‰æ›´å¥½çš„æƒé‡ï¼Œåœ¨Sem-Eval-2010 Task 8æ•°æ®é›†ä¸Šå–å¾—äº†æ˜¾è‘—çš„æ•ˆæœæå‡ã€‚å¯¹äºå…³ç³»æŠ½å–æ¥è¯´æ— ç–‘æ˜¯éå¸¸å¤§çš„ä¸€ä¸ªè¿›æ­¥ã€‚</p><p>ä½†æ˜¯è¿˜æ˜¯æœ‰ä¸€äº›ä¸è¶³ï¼š</p><ul><li>å®ƒè¦æ±‚å®ä½“å·²çŸ¥ï¼Œå› æ­¤éœ€è¦å…¶ä»–å·¥ä½œæ¥å®Œæˆå®ä½“çš„è¯†åˆ«ï¼Œä½¿å¾—ä¸€äº›ä¿¡æ¯çš„ä¸¢å¤±ä»¥åŠé”™è¯¯ç´¯åŠ ã€‚æ­¤æ—¶å¹¶è¡Œæ¨¡å‹æˆ–ç«¯åˆ°ç«¯æ¨¡å‹ï¼ŒåŒæ—¶å®Œæˆå®ä½“è¯†åˆ«å¯èƒ½æ•ˆæœä¼šæ›´å¥½ï¼›</li><li>å…³ç³»æ˜¯äº‹å…ˆå®šä¹‰çš„é›†åˆï¼Œå› æ­¤æ›´å¤šçš„æ˜¯å¯¹å…³ç³»çš„åˆ†ç±»ï¼Œè‹¥èƒ½å¯å‘å¼åœ°æŠ½å–å…³ç³»å¯èƒ½ä¼šæœ‰æ›´å¹¿çš„åº”ç”¨ç©ºé—´ï¼›</li><li>å¯¹äºä¸€äº›ä¸Šä¸‹æ–‡æ²¡æœ‰æ˜æ˜¾å¸®åŠ©çš„éšå¼å…³ç³»æˆ–æ˜¯ä½¿ç”¨äº†æ¯”å–»ä¹‹ç±»çš„ä¿®è¾ï¼Œè¾ƒä¸ºå®¹æ˜“å‡ºé”™ã€‚</li></ul><p>è¿™æ¬¡é€‰æ‹©è¯»è¿™ç¯‡æ–‡ç« ä¹Ÿæ˜¯æƒ³æ›´å…·ä½“åœ°äº†è§£Attentionæœºåˆ¶ï¼ŒåŒæ—¶äº†è§£ä¸€äº›å…³ç³»æŠ½å–çš„æ–¹æ¡ˆï¼Œå®ƒä¹Ÿæœ‰ä¸€ä¸ªpytorchç‰ˆæœ¬çš„<a href="https://github.com/lawlietAi/relation-classification-via-attention-model" target="_blank" rel="noopener">å®ç°</a>ï¼Œå¯ä»¥è¾…ä»¥å‚è€ƒã€‚</p><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>ç¬”è®°éƒ¨åˆ†å‚è€ƒ<a href="https://zhuanlan.zhihu.com/p/22867750" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/22867750</a></p><p>[1] Wang, L., Cao, Z., Melo, G. D., &amp; Liu, Z. (2016). Relation Classification via Multi-Level Attention CNNs. <em>Meeting of the Association for Computational Linguistics</em> (pp.1298-1307).</p><p>[2] Bahdanau, D., Cho, K., &amp; Bengio, Y. (2014). Neural machine translation by jointly learning to align and translate. <em>Computer Science</em>.</p><p>[3] Luong, M. T., Pham, H., &amp; Manning, C. D. (2015). Effective approaches to attention-based neural machine translation. <em>Computer Science</em>.</p><p>[4] Yin, W., SchÃ¼tze, H., Xiang, B., &amp; Zhou, B. (2015). Abcnn: attention-based convolutional neural network for modeling sentence pairs. <em>Computer Science</em>.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h2 id=&quot;Relation-Classification-via-Atten
      
    
    </summary>
    
      <category term="research" scheme="https://juewang.me/categories/research/"/>
    
    
      <category term="relation-extraction" scheme="https://juewang.me/tags/relation-extraction/"/>
    
      <category term="relation-classification" scheme="https://juewang.me/tags/relation-classification/"/>
    
      <category term="attention" scheme="https://juewang.me/tags/attention/"/>
    
  </entry>
  
  <entry>
    <title>å®ä½“è§£æ Entity resolution</title>
    <link href="https://juewang.me/posts/%5B2017.12.10%5DEntity-resolution/"/>
    <id>https://juewang.me/posts/[2017.12.10]Entity-resolution/</id>
    <published>2017-12-10T00:00:00.000Z</published>
    <updated>2018-01-27T11:07:30.140Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2 id="1-Entity-resolution"><a href="#1-Entity-resolution" class="headerlink" title="1. Entity resolution"></a>1. Entity resolution</h2><p>###1.1 Sequence labeling</p><p>æˆ‘ä»¬é€šå¸¸åœ¨MLä¸­æŠŠNamed Entity Recognitionä»»åŠ¡è®¤ä¸ºæ˜¯ä¸€ä¸ªSequence labelingä»»åŠ¡ï¼Œäº‹å®ä¸Šå¾ˆå¤šnlpä»»åŠ¡éƒ½å¯ä»¥è¢«è½¬åŒ–ä¸ºsequence labelingã€‚æš‘å‡å®ä¹ çš„æ—¶å€™ä¹Ÿåœ¨è¿™æ–¹é¢çœ‹äº†ä¸€äº›æ–‡çŒ®ã€‚ç›®å‰ä¸šå†…æ¯”è¾ƒä¸»æµçš„è§£å†³æ–¹æ¡ˆæ˜¯RNN-CRFæ¨¡å‹ï¼Œä¸€èˆ¬æ¥è¯´åˆ†ä¸ºï¼š</p><ul><li>Embedding layer</li><li>Bi-directional RNN (usually LSTM) layer</li><li>Tanh hidden layer</li><li>CRF layer</li></ul><p>ä»ç»“æœä¸Šæ¥çœ‹ï¼Œè¯¥æ¨¡å‹å¯¹å¤§å¤šæ•°sequence labelingä»»åŠ¡æœ‰è¾ƒå¥½çš„æ•ˆæœï¼Œå¦‚named entity recognitionç­‰ã€‚ä½†æ˜¯å¯¹äºä¸€äº›æ›´çµæ´»çš„æ ‡æ³¨ä»»åŠ¡ï¼ˆå¦‚æš‘å‡å®ä¹ æ—¶ï¼Œæˆ‘æ›¾è¯•å›¾å°†event recognitionè½¬åŒ–ä¸ºseq labelingä»»åŠ¡ï¼‰ï¼Œå°¤å…¶æ˜¯åœ¨è®­ç»ƒé›†ä¸è¶³çš„æƒ…å†µä¸‹ï¼Œå¾€å¾€æ•ˆæœè¿˜æ˜¯ä¸èƒ½ä»¤äººæ»¡æ„ã€‚</p><h4 id="1-1-1-åº”ç”¨Attention"><a href="#1-1-1-åº”ç”¨Attention" class="headerlink" title="1.1.1 åº”ç”¨Attention"></a>1.1.1 åº”ç”¨Attention</h4><blockquote><p>[1]åœ¨ RNN-CRF æ¨¡å‹ç»“æ„åŸºç¡€ä¸Šï¼Œé‡ç‚¹æ”¹è¿›äº†è¯å‘é‡ä¸å­—ç¬¦å‘é‡çš„æ‹¼æ¥ã€‚ä½¿ç”¨ attention æœºåˆ¶å°†åŸå§‹çš„å­—ç¬¦å‘é‡å’Œè¯å‘é‡æ‹¼æ¥æ”¹è¿›ä¸ºäº†æƒé‡æ±‚å’Œï¼Œä½¿ç”¨ä¸¤å±‚ä¼ ç»Ÿç¥ç»ç½‘ç»œéšå±‚æ¥å­¦ä¹  attention çš„æƒå€¼ï¼Œè¿™æ ·å°±ä½¿å¾—æ¨¡å‹å¯ä»¥åŠ¨æ€åœ°åˆ©ç”¨è¯å‘é‡å’Œå­—ç¬¦å‘é‡ä¿¡æ¯ã€‚å®éªŒç»“æœè¡¨æ˜æ¯”åŸå§‹çš„æ‹¼æ¥æ–¹æ³•æ•ˆæœæ›´å¥½ã€‚</p><p>[2]åœ¨åŸå§‹ BiLSTM-CRF æ¨¡å‹ä¸Šï¼ŒåŠ å…¥äº†éŸ³éŸµç‰¹å¾ï¼Œå¹¶åœ¨å­—ç¬¦å‘é‡ä¸Šä½¿ç”¨ attention æœºåˆ¶æ¥å­¦ä¹ å…³æ³¨æ›´æœ‰æ•ˆçš„å­—ç¬¦ã€‚</p><p>â€‹                      â€” from paperweekly</p></blockquote><h4 id="1-1-2-ä½¿ç”¨å°‘é‡æ ‡æ³¨æ•°æ®"><a href="#1-1-2-ä½¿ç”¨å°‘é‡æ ‡æ³¨æ•°æ®" class="headerlink" title="1.1.2 ä½¿ç”¨å°‘é‡æ ‡æ³¨æ•°æ®"></a>1.1.2 ä½¿ç”¨å°‘é‡æ ‡æ³¨æ•°æ®</h4><p>æ·±åº¦å­¦ä¹ æ–¹æ³•ä¸€èˆ¬éœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®ï¼Œä½†æ˜¯åœ¨ä¸€äº›é¢†åŸŸå¾ˆéš¾æœ‰æµ·é‡çš„æ ‡æ³¨æ•°æ®ã€‚æ‰€ä»¥åœ¨åŸºäºç¥ç»ç½‘ç»œç»“æ„æ–¹æ³•ä¸­å¦‚ä½•ä½¿ç”¨å°‘é‡æ ‡æ³¨æ•°æ®ä¹Ÿæ˜¯ä¸€ä¸ªé‡ç‚¹ã€‚</p><ul><li><p><a href="https://openreview.net/forum?id=ry018WZAZ" target="_blank" rel="noopener">Deep Active Learning for Named Entity Recognition</a>[7]</p><p>ICLR 2018çœ‹åˆ°çš„paperã€‚è¿™ç‰‡æ–‡ç« æŠŠactive learningåº”ç”¨åˆ°äº†CNN-CNN-LSTMæ¨¡å‹ï¼Œç”¨äºå¤„ç†NERé—®é¢˜ï¼Œä¹Ÿå°±æ˜¯seq labelingé—®é¢˜ã€‚å®ƒèƒ½å¤Ÿä»…ä½¿ç”¨25%çš„æ•°æ®ï¼Œè¾¾åˆ°state-of-the-artçš„æ°´å¹³ã€‚</p><p>è¿™ç¯‡paperæ€»ç»“äº†å¾ˆå¤šåšseq labelingçš„æ–¹æ³•ï¼Œæœ¬èº«çš„æ€è·¯ä¹Ÿæ·±å…¥ç®€å‡ºã€‚decoderä½¿ç”¨äº†LSTMè€Œä¸æ˜¯å¸¸ç”¨çš„CRFï¼Œå‘ç°LSTMæ¯”CRFæœ‰ä¸€äº›çš„ä¼˜åŠ¿ã€‚åŒæ—¶è¯¥æ–‡ä¹Ÿè¯æ˜äº†active learningèƒ½æé«˜seq labelingçš„è¡¨ç°ã€‚</p></li><li><p>Semi-supervised sequence tagging with bidirectional language models[4]</p><p>è¯¥è®ºæ–‡ä½¿ç”¨æµ·é‡æ— æ ‡æ³¨è¯­æ–™åº“è®­ç»ƒäº†ä¸€ä¸ªåŒå‘ç¥ç»ç½‘ç»œè¯­è¨€æ¨¡å‹ï¼Œç„¶åä½¿ç”¨è¿™ä¸ªè®­ç»ƒå¥½çš„è¯­è¨€æ¨¡å‹æ¥è·å–å½“å‰è¦æ ‡æ³¨è¯çš„è¯­è¨€æ¨¡å‹å‘é‡ï¼ˆLM embeddingï¼‰ï¼Œç„¶åå°†è¯¥å‘é‡ä½œä¸ºç‰¹å¾åŠ å…¥åˆ°åŸå§‹çš„åŒå‘ RNN-CRF æ¨¡å‹ä¸­ã€‚</p><p>å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨å°‘é‡æ ‡æ³¨æ•°æ®ä¸Šï¼ŒåŠ å…¥è¿™ä¸ªè¯­è¨€æ¨¡å‹å‘é‡èƒ½å¤Ÿå¤§å¹…åº¦æé«˜ NER æ•ˆæœï¼Œå³ä½¿åœ¨å¤§é‡çš„æ ‡æ³¨è®­ç»ƒæ•°æ®ä¸Šï¼ŒåŠ å…¥è¿™ä¸ªè¯­è¨€æ¨¡å‹å‘é‡ä»èƒ½æä¾›åŸå§‹ RNN-CRF æ¨¡å‹çš„æ•ˆæœã€‚</p></li></ul><h3 id="1-2-Relation-extraction"><a href="#1-2-Relation-extraction" class="headerlink" title="1.2 Relation extraction"></a>1.2 Relation extraction</h3><p>å®ä½“çš„å…³ç³»çš„æŠ½å–æ–¹æ³•å¯ä»¥ç®€å•åˆ†ä¸ºä¸¤ç±»ï¼šä¸€ç±»æ˜¯pipelineæŠ½å–æ–¹æ³•ã€‚å¦ä¸€ç±»æ˜¯å¹¶è¡Œæˆ–è”åˆæŠ½å–æ–¹æ³•ã€‚</p><p>pipelineæ–¹æ³•éœ€è¦å…ˆè¯†åˆ«entityï¼Œç„¶åé‡‡ç”¨å…³ç³»æŠ½å–æ¨¡å‹å¾—åˆ°å®ä½“å¯¹ä¹‹é—´çš„å…³ç³»ã€‚ç¼ºç‚¹æ˜¯å®ä½“è¯†åˆ«çš„ç»“æœä¼šè¿›ä¸€æ­¥å½±å“å…³ç³»æŠ½å–çš„ç»“æœï¼Œå¯¼è‡´è¯¯å·®ç´¯ç§¯ï¼Œä¹Ÿé™ä½ä¿¡æ¯ä½¿ç”¨ç‡ï¼Œåˆ†å¼€æŠ½å–ä¹Ÿé€ æˆäº†ä¿¡æ¯å†—ä½™ã€‚</p><p>[9]æå‡ºäº†ä¸€ç§è”åˆå®ä½“æ£€æµ‹å‚æ•°å…±äº«çš„å…³ç³»æŠ½å–æ¨¡å‹ï¼Œæ¨¡å‹ä¸­æœ‰ä¸¤ä¸ªåŒå‘çš„LSTM-RNNï¼Œä¸€ä¸ªæ˜¯åŸºäºword sequenceï¼ˆbidirectional sequential LSTM-RNNsï¼‰ï¼Œä¸»è¦ç”¨äºå®ä½“æ£€æµ‹ï¼›ä¸€ä¸ªåŸºäºTree Structures ï¼ˆbidirectional tree- structured LSTM-RNNsï¼‰ï¼Œä¸»è¦ç”¨äºå…³ç³»æŠ½å–ï¼›åè€…å †åœ¨å‰è€…ä¸Šï¼Œå‰è€…çš„è¾“å‡ºå’Œéšå«å±‚ä½œä¸ºåè€…è¾“å…¥çš„ä¸€éƒ¨åˆ†ã€‚ä¸‹å›¾ä¸ºæ•´ä¸ªæ¨¡å‹çš„ç»“æ„å›¾ï¼š</p><p><img src="https://pic3.zhimg.com/v2-8a44b362fb60fff951dbfaa2bc4469f3_r.jpg" alt="LSTM-RNNs"></p><p>è¯¥paperç”¨äº†å‚æ•°å…±äº«ï¼Œå®ä½“çš„è¯†åˆ«è¿‡ç¨‹å’Œå…³ç³»çš„åˆ¤æ–­è¿‡ç¨‹å¹¶æ²¡æœ‰äº¤äº’çš„è¿‡ç¨‹ï¼Œè¿˜æ— æ³•ç§°å…¶ä¸ºçœŸæ­£æ„ä¹‰ä¸Šçš„jointã€‚</p><p>[7]æå‡ºäº†ä¸€ç§ç«¯åˆ°ç«¯çš„åŸºäºåºåˆ—æ ‡æ³¨çš„çš„æ–¹æ³•è¿›è¡Œå…³ç³»æŠ½å–ï¼Œå®ƒå°†å®ä½“å‘ç°ä»»åŠ¡å’Œå…³ç³»æŠ½å–ä»»åŠ¡è½¬åŒ–ä¸ºä¸€ä¸ªæ ‡æ³¨ä»»åŠ¡ã€‚åœ¨ encoder-decoder æ¡†æ¶ä¸‹ï¼Œé‡‡ç”¨ä¸»æµçš„ bi-lstm ä¸º encoderï¼Œlstm ä¸º decoderã€‚å¯¹æ¯ä¸ªè¯æ ‡æ³¨ä¸Š BIEM+å…³ç³»ç±»å‹+å®ä½“çš„åºå·ã€‚ç›®å‰è¿™ç§æ€è·¯æœ‰äººæµ‹è¯•ä¸‹æ¥å‘ç°ï¼Œæ€»çš„æ¥è¯´ï¼Œè”åˆæŠ½å–æ¯”pipelineçš„æ–¹æ³•å¥½ï¼Œåºåˆ—æ ‡æ³¨è”åˆæŠ½å–è¦æ¯”å…¶ä»–è”åˆæŠ½å–æ–¹æ³•å¥½ï¼Œç„¶è€Œç›®å‰å®ä½“å…³ç³»æŠ½å–ä»»åŠ¡çš„ F1 å€¼ä»ç„¶ä¸åˆ° 0.5ã€‚å› æ­¤è™½ç„¶æ•ˆæœè¿˜å¯ä»¥ï¼Œä½†æ˜¯å°±å®é™…ä½¿ç”¨è¿˜æœ‰ä¸€æ®µè·ç¦»ã€‚</p><p>æ­¤å¤–ï¼Œè¯¥æ¨¡å‹è¿˜æ— æ³•å¤„ç†ä¸€ä¸ªå¥å­æœ‰å¤šä¸ªå…³ç³»ä¸‰å…ƒç»„ï¼Œå’Œä¸€ä¸ªå®ä½“åœ¨å¤šä¸ªå…³ç³»ä¸­å‡ºç°çš„ä¸€å¯¹å¤šçš„é—®é¢˜ã€‚ä¸€ä¸ªæ”¹è¿›æ–¹å‘æ˜¯æŠŠæœ€åçš„softmaxæ”¹æˆå¤šåˆ†ç±»å™¨ä»¥å®ç°å¤šæ ‡ç­¾ï¼Œè¿™æ ·å°±èƒ½å®ç°ä¸€ä¸ªå®ä½“çš„å¤šå…³ç³»æŠ½å–ã€‚å…¶æ¬¡ï¼Œè¯¥æ–¹æ³•æ˜¯éå¼€æ”¾åŸŸçš„å…³ç³»æŠ½å–ï¼Œå…³ç³»è¯æ˜¯ä»é¢„å®šä¹‰çš„å…³ç³»é›†é‡ŒæŠ½å–çš„ã€‚</p><h2 id="2-Others"><a href="#2-Others" class="headerlink" title="2. Others"></a>2. Others</h2><p>è¿™é‡Œä¸»è¦æ˜¯æœ‰ç›¸å…³æ€§ä¸å¼ºä½†æŒºæœ‰æ„æ€ï¼Œæˆ–æ³›ç”¨æ€§å¾ˆå¼ºçš„ä¸€äº›æ–‡ç« ã€‚</p><ol><li><p>Ngram2vec[5]</p><p>ä¸€ä¸ªè¯å‘é‡ç”Ÿæˆçš„æ–¹æ³•ï¼ŒåŸºäºç»å…¸çš„ word2vec çš„æ€æƒ³ï¼Œåœ¨å…¶ä¹‹ä¸ŠåŠ å…¥äº† ngram çš„å…±ç°ä¿¡æ¯ï¼Œå–å¾—äº†æ›´å¥½çš„ç»“æœã€‚ä»£ç å®ç°ï¼š<a href="http://link.zhihu.com/?target=https%3A//github.com/zhezhaoa/ngram2vec/" target="_blank" rel="noopener">https://github.com/zhezhaoa/ngram2vec/</a></p></li><li><p><a href="https://research.googleblog.com/2017/05/using-machine-learning-to-explore.html" target="_blank" rel="noopener">AutoML</a></p><p>googleåœ¨äº”æœˆä»½å‘å¸ƒçš„æ¨¡å‹ï¼Œä¸»è¦æ€æƒ³æ˜¯å°†reinforcement learningåº”ç”¨åœ¨ç¥ç»ç½‘ç»œçš„æ„å»ºã€å‚æ•°ç¡®å®šä¸Šã€‚æˆ‘ä»¬å¯¹ç½‘ç»œè¿›è¡Œæµ‹è¯•ï¼Œå°†åé¦ˆçš„ç»“æœè¿”å›åˆ°æ§åˆ¶å™¨ä¸­ï¼Œä»¥æ­¤æ¥å¸®åŠ©æå‡ä¸‹ä¸€æ¬¡å¾ªç¯ä¸­çš„è®­ç»ƒè®¾å®šã€‚ç”Ÿæˆæ–°çš„æ¶æ„ã€æµ‹è¯•ã€æŠŠåé¦ˆä¼ é€ç»™æ§åˆ¶å™¨ä»¥å¸å–ç»éªŒã€‚ä»¥æ­¤å¾€å¤ä»¥å¾—åˆ°æ›´ä¼˜çš„ç»“æ„ã€‚</p></li><li><p>Introspection:Accelerating Neural Network Training By Learning Weight Evolution[6]</p><p>è¿™ä¸ªæœ¬è´¨ä¸Šæ˜¯meta learningçš„é—®é¢˜ã€‚ä»–ä»¬è®­ç»ƒäº†ä¸€ä¸ªç½‘ç»œï¼Œç½‘ç»œçš„è¾“å…¥æ˜¯æŸä¸ªæ—¶é—´ç‚¹ä¹‹å‰éšæœºé€‰å–çš„4ä¸ªæ—§å‚æ•°çš„å€¼ï¼Œè¾“å‡ºå°±æ˜¯æ–°çš„å‚æ•°ã€‚å› æ­¤å¯ä»¥å°†è®­ç»ƒå…¶ä»–æ¨¡å‹æ—¶å¾—åˆ°çš„è¿™ä¸ªç½‘ç»œï¼Œç”¨äºåŠ é€Ÿå…¶ä»–æ¨¡å‹ã€‚ä»–ä»¬è®­ç»ƒäº†mnistçš„ä¸¤å±‚conv netï¼Œç”¨è¯¥ä»»åŠ¡çš„å‚æ•°æ›´æ–°å†å²è®­ç»ƒç½‘ç»œã€‚ä»–ä»¬æœ€åå°†pretrainedå¥½çš„è¿™ä¸ªç½‘ç»œç”¨äºæ›´æ–°å¤§ç½‘ç»œï¼Œç»“æœéƒ½èƒ½æ›´å¥½ã€‚</p></li></ol><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p>[1] Rei, M., Crichton, G. K., &amp; Pyysalo, S. (2016). Attending to Characters in Neural Sequence Labeling Models. <em>arXiv preprint arXiv:1611.04361</em>.</p><p>[2] Mortensen, A. B. D., &amp; Carbonell, C. D. J. G. (2016). Phonologically aware neural model for named entity recognition in low resource transfer settings.</p><p>[3] Yang, Z., Salakhutdinov, R., &amp; Cohen, W. W. (2017). Transfer learning for sequence tagging with hierarchical recurrent networks. <em>arXiv preprint arXiv:1703.06345</em>.</p><p>[4] Peters, M. E., Ammar, W., Bhagavatula, C., &amp; Power, R. (2017). Semi-supervised sequence tagging with bidirectional language models. <em>arXiv preprint arXiv:1705.00108</em>.</p><p>[5] Zhao, Z., Liu, T., Li, S., Li, B., &amp; Du, X. (2017). Ngram2vec: Learning Improved Word Representations from Ngram Co-occurrence Statistics. In <em>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</em> (pp. 244-253).</p><p>[6] Sinha, A., Sarkar, M., Mukherjee, A., &amp; Krishnamurthy, B. (2017). Introspection: Accelerating Neural Network Training By Learning Weight Evolution. <em>arXiv preprint arXiv:1704.04959</em>.</p><p>[7] Shen, Yanyao, Yun, Hyokun, Lipton, Zachary C, Kronrod, Yakov, &amp; Anandkumar, Animashree. (2017). Deep active learning for named entity recognition.</p><p>[8] Zheng, S., Wang, F., Bao, H., Hao, Y., Zhou, P., &amp; Xu, B. (2017). Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme. <em>arXiv preprint arXiv:1706.05075</em>.</p><p>[9] Miwa, M., &amp; Bansal, M. (2016). End-to-end relation extraction using lstms on sequences and tree structures. <em>arXiv preprint arXiv:1601.00770</em>.</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h2 id=&quot;1-Entity-resolution&quot;&gt;&lt;a href=&quot;#1-
      
    
    </summary>
    
      <category term="research" scheme="https://juewang.me/categories/research/"/>
    
    
      <category term="entity-resolution" scheme="https://juewang.me/tags/entity-resolution/"/>
    
      <category term="sequence-labeling" scheme="https://juewang.me/tags/sequence-labeling/"/>
    
      <category term="relation-extraction" scheme="https://juewang.me/tags/relation-extraction/"/>
    
      <category term="LSTM" scheme="https://juewang.me/tags/LSTM/"/>
    
      <category term="RNN" scheme="https://juewang.me/tags/RNN/"/>
    
  </entry>
  
  <entry>
    <title>Note of NLP</title>
    <link href="https://juewang.me/posts/Note-of-NLP/"/>
    <id>https://juewang.me/posts/Note-of-NLP/</id>
    <published>2017-06-26T12:52:45.000Z</published>
    <updated>2017-06-28T09:13:58.000Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h1 id="NLP"><a href="#NLP" class="headerlink" title="NLP"></a>NLP</h1><ol><li><p>â€œOne-hotâ€ representation</p><p>æ¯ä¸€ä¸ªè¯éƒ½ä½œä¸ºä¸€ä¸ªç‰¹å¾ï¼Œç”¨ä¸€ä¸ªå¾ˆå¤§çš„å‘é‡æ¥æè¿°æ–‡ç« ã€‚<br>$$<br>[0,0,0,0,0,0,0,0,0,1,0,0,0]<br>$$</p></li><li><p>Main idea of word2vec</p><p>Two algorithms</p><ol><li>Skip-grams</li><li>Continuous bag of words (CBOW)</li></ol><p>Two training methods</p><ol><li>Hierarchical softmax</li><li>Negative sampling</li></ol></li></ol><h2 id="åŸºäºæ·±åº¦å­¦ä¹ çš„å…³ç³»æå–"><a href="#åŸºäºæ·±åº¦å­¦ä¹ çš„å…³ç³»æå–" class="headerlink" title="åŸºäºæ·±åº¦å­¦ä¹ çš„å…³ç³»æå–"></a>åŸºäºæ·±åº¦å­¦ä¹ çš„å…³ç³»æå–</h2><blockquote><p>[Zeng et al. 2014] æå‡ºé‡‡ç”¨å·ç§¯ç¥ç»ç½‘ç»œè¿›è¡Œå…³ç³»æŠ½å–ã€‚ä»–ä»¬é‡‡ç”¨è¯æ±‡å‘é‡å’Œè¯çš„ä½ç½®å‘é‡ä½œä¸ºå·ç§¯ç¥ç»ç½‘ç»œçš„è¾“å…¥ï¼Œé€šè¿‡å·ç§¯å±‚ã€æ± åŒ–å±‚å’Œéçº¿æ€§å±‚å¾—åˆ°å¥å­è¡¨ç¤ºã€‚é€šè¿‡è€ƒè™‘å®ä½“çš„ä½ç½®å‘é‡å’Œå…¶ä»–ç›¸å…³çš„è¯æ±‡ç‰¹å¾ï¼Œå¥å­ä¸­çš„å®ä½“ä¿¡æ¯èƒ½å¤Ÿè¢«è¾ƒå¥½åœ°è€ƒè™‘åˆ°å…³ç³»æŠ½å–ä¸­ã€‚åæ¥ï¼Œ[Santos et al. 2015]è¿˜æå‡ºäº†ä¸€ç§æ–°çš„å·ç§¯ç¥ç»ç½‘ç»œè¿›è¡Œå…³ç³»æŠ½å–ï¼Œå…¶ä¸­é‡‡ç”¨äº†æ–°çš„æŸå¤±å‡½æ•°ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°æé«˜ä¸åŒå…³ç³»ç±»åˆ«ä¹‹é—´çš„åŒºåˆ†æ€§ã€‚</p><p>[Miwa et al. 2016] æå‡ºäº†ä¸€ç§åŸºäºç«¯åˆ°ç«¯ç¥ç»ç½‘ç»œçš„å…³ç³»æŠ½å–æ¨¡å‹ã€‚è¯¥æ¨¡å‹ä½¿ç”¨åŒå‘ LSTMï¼ˆLong-Short Term Memoryï¼Œé•¿çŸ­æ—¶è®°å¿†æ¨¡å‹ï¼‰å’Œæ ‘å½¢ LSTM åŒæ—¶å¯¹å®ä½“å’Œå¥å­è¿›è¡Œå»ºæ¨¡ã€‚ç›®å‰ï¼ŒåŸºäºå·ç§¯ç¥ç»ç½‘ç»œçš„æ–¹æ³•åœ¨å…³ç³»æŠ½å–çš„æ ‡å‡†æ•°æ®é›† SemEval-2010 Task 8 ä¸Šå–å¾—äº†æœ€å¥½çš„æ•ˆæœã€‚</p><p>â€“åŸºäºæ·±åº¦å­¦ä¹ çš„å…³ç³»æŠ½å–æŠ€æœ¯è¿›å±•_åˆ˜çŸ¥è¿œ_ç†Šå¾·æ„</p></blockquote><p>RNNåœ¨NLPä¸­åº”ç”¨è¾ƒå¤šï¼Œæœ‰å…³å®ƒçš„æ–‡ç« ï¼š<a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" target="_blank" rel="noopener">The Unreasonable Effectiveness of Recurrent Neural Networks</a> è¯‘æ–‡<a href="http://www.csdn.net/article/2015-08-28/2825569" target="_blank" rel="noopener">é€’å½’ç¥ç»ç½‘ç»œä¸å¯æ€è®®çš„æœ‰æ•ˆæ€§</a></p><p>å…¶ä¸­ç›®å‰æ¯”è¾ƒæµè¡Œçš„æ˜¯LSTMï¼Œæœ‰å…³å®ƒçš„æ–‡ç« ï¼š<a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank" rel="noopener">Understanding LSTM Networks</a> è¯‘æ–‡ <a href="http://blog.csdn.net/jerr__y/article/details/58598296" target="_blank" rel="noopener">ç†è§£LSTMç½‘ç»œ</a></p><p><a href="http://blog.csdn.net/jerr__y/article/details/61195257" target="_blank" rel="noopener">LSTMçš„tensorflowç®€å•å®ç°</a></p><h3 id="GAN"><a href="#GAN" class="headerlink" title="GAN ?"></a>GAN ?</h3><p>ACGANå¯ç”¨äºåˆ†ç±»é—®é¢˜ï¼ŒDiscriminatorè¾“å‡ºæ­£ä¼ªçš„åŒæ—¶è¿˜ä¼šè¾“å‡ºç±»åˆ«ã€‚é€‚åˆç±»åˆ«æ•°é‡å·²ç»™å®šçš„æƒ…å†µã€‚</p><p>InfoGANã€‚</p><p>åŠç›‘ç£GANã€‚</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h1 id=&quot;NLP&quot;&gt;&lt;a href=&quot;#NLP&quot; class=&quot;header
      
    
    </summary>
    
      <category term="programming" scheme="https://juewang.me/categories/programming/"/>
    
    
      <category term="machine-learning" scheme="https://juewang.me/tags/machine-learning/"/>
    
      <category term="deep-learning" scheme="https://juewang.me/tags/deep-learning/"/>
    
      <category term="nlp" scheme="https://juewang.me/tags/nlp/"/>
    
  </entry>
  
</feed>
